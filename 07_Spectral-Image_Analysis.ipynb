{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f8c782",
   "metadata": {},
   "source": [
    "# labelmeの結果可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2430386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "json_path = main_dir / (file_stem + \".json\")\n",
    "image_path = main_dir / (file_stem + \".tiff\")\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ラベル名と数値の対応辞書を作成\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# マスクを生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 各ラベルごとに画素値を抽出し、統計量を算出\n",
    "results = {}\n",
    "for label_name, value in label_name_to_value.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    \n",
    "    # ラベルに対応するマスクを作成\n",
    "    label_mask = (lbl == value)\n",
    "    pixel_values = img[label_mask]\n",
    "    \n",
    "    if len(pixel_values) > 0:\n",
    "        results[label_name] = {\n",
    "            'pixel_count': len(pixel_values),\n",
    "            'mean': np.mean(pixel_values),\n",
    "            'std_dev': np.std(pixel_values),\n",
    "            'max_value': np.max(pixel_values),\n",
    "            'min_value': np.min(pixel_values)\n",
    "        }\n",
    "    else:\n",
    "        results[label_name] = \"No pixels found for this label.\"\n",
    "\n",
    "# 結果を整形して表示\n",
    "for label, stats in results.items():\n",
    "    print(f'--- ラベル: {label} ---')\n",
    "    if isinstance(stats, str):\n",
    "        print(stats)\n",
    "    else:\n",
    "        print(f'画素数: {stats[\"pixel_count\"]}')\n",
    "        print(f'平均値: {stats[\"mean\"]}')\n",
    "        print(f'標準偏差: {stats[\"std_dev\"]}')\n",
    "        print(f'最大値: {stats[\"max_value\"]}')\n",
    "        print(f'最小値: {stats[\"min_value\"]}')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68da0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# # プロジェクトのメインディレクトリ\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "\n",
    "# # 画像とJSONファイルのパス\n",
    "# json_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.json\"\n",
    "# image_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(image_path)\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# label_name_to_value を作成\n",
    "label_name_to_value = {\"_background_\": 0}  # 背景は0\n",
    "for shape in data[\"shapes\"]:\n",
    "    label_name = shape[\"label\"]\n",
    "    if label_name not in label_name_to_value:\n",
    "        label_name_to_value[label_name] = len(label_name_to_value)\n",
    "\n",
    "# マスクを生成（新しいAPI）\n",
    "lbl, _ = labelme.utils.shapes_to_label(\n",
    "    img_shape=img.shape,\n",
    "    shapes=data[\"shapes\"],\n",
    "    label_name_to_value=label_name_to_value\n",
    ")\n",
    "\n",
    "# マスクを可視化\n",
    "mask = (lbl > 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Mask Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# 画像ファイルのパスを指定してください\n",
    "# 基準画像のパス\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2/MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# 比較したい分光画像のパス（例）\n",
    "spectral_image_path = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}/{folder_name}_Ex360_Em480_ET10000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 画像を重ねて表示\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.imshow(ref_img, cmap='gray', alpha=1.0) # 基準画像を背景に表示\n",
    "ax.imshow(spec_img, cmap='jet', alpha=0.5) # 分光画像を半透明で重ねて表示\n",
    "ax.set_title('Image Alignment Check')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "# # 画像ファイルのパスを指定\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# spectral_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex260_Em280_ET20000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 位相相関法でずれを計算\n",
    "# output: ずれの量 (y, x), 誤差, 位相相関のピーク\n",
    "shift, error, phase = phase_cross_correlation(ref_img, spec_img)\n",
    "\n",
    "# ずれの量（ピクセル単位）を表示\n",
    "print(f'基準画像に対する分光画像のずれ:')\n",
    "print(f'  y方向 (縦): {shift[0]:.2f} ピクセル')\n",
    "print(f'  x方向 (横): {shift[1]:.2f} ピクセル')\n",
    "print(f'  誤差: {error:.4f}')\n",
    "\n",
    "# ずれが非常に小さい（0に近い）ことを確認し、問題ないと判断\n",
    "if np.sqrt(shift[0]**2 + shift[1]**2) < 1.0:\n",
    "    print(\"\\n画像間のずれは1ピクセル未満です。位置合わせは正確であると考えられます。\")\n",
    "else:\n",
    "    print(\"\\n画像間にずれがある可能性があります。再撮影または画像補正を検討してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f122874",
   "metadata": {},
   "source": [
    "# ピクセル単位での分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8fa9b",
   "metadata": {},
   "source": [
    "## ラベリング結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # 凡例用\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\") # ラベリングに使用した元の画像パス\n",
    "\n",
    "print(f\"Loading JSON file: {json_path}\")\n",
    "print(f\"Loading original image: {image_path}\")\n",
    "\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: JSONファイル '{json_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    original_img = np.asarray(Image.open(image_path))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: 元画像ファイル '{image_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# ラベル名と数値の対応付け\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0 # 背景には0を割り当てる\n",
    "\n",
    "# ラベルマップ（数値）を生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(original_img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 可視化用のカラーマップを生成\n",
    "# ラベル数に応じて色を割り当てる\n",
    "unique_labels = np.unique(lbl)\n",
    "colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "colored_mask = np.zeros((*lbl.shape, 3), dtype=np.uint8)\n",
    "legend_patches = []\n",
    "label_value_to_color = {}\n",
    "\n",
    "for i, label_value in enumerate(unique_labels):\n",
    "    if label_value == 0:\n",
    "        color = np.array([0, 0, 0])\n",
    "        label_name = 'background'\n",
    "    else:\n",
    "        # 修正: np.array()で一度配列に変換してからastype()を適用\n",
    "        color = (np.array(colors(i)[:3]) * 255).astype(np.uint8)\n",
    "        label_name = list(label_name_to_value.keys())[list(label_name_to_value.values()).index(label_value)]\n",
    "        legend_patches.append(mpatches.Patch(color=color/255., label=label_name))\n",
    "    \n",
    "    colored_mask[lbl == label_value] = color\n",
    "\n",
    "# 元画像とカラーマスクを並べて表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(colored_mask)\n",
    "axes[1].set_title('Labeled Mask (Pixel-wise Labels)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化されたラベリング結果を確認しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b2aeb",
   "metadata": {},
   "source": [
    "---\n",
    "# 2つのデータセットを用いた交差検証\n",
    "## 学習・テスト対象：背景とプラスチックラベル域のピクセル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcf5a7",
   "metadata": {},
   "source": [
    "### データセットの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83470f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# main_dir や reference_file_stem はご自身の環境に合わせて設定してください\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準となるJSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: JSONファイルが見つかりません。パスを確認してください: {json_path}\")\n",
    "    exit()\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出 (この部分は変更なし)\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\"))\n",
    "if not image_files:\n",
    "    print(\"エラー: TIFF画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "image_size = (data['imageHeight'], data['imageWidth'])\n",
    "print(f\"画像サイズを検出しました: {image_size}\")\n",
    "\n",
    "for image_path in image_files:\n",
    "    if '-1_Em-1' in image_path.stem:\n",
    "        continue\n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    ex_wavelength = int(match.group(1))\n",
    "    em_wavelength = int(match.group(2))\n",
    "    if ex_wavelength == em_wavelength:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        if img.shape[:2] != image_size:\n",
    "            print(f\"警告: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"警告: {image_path.name} の処理に失敗しました。理由: {e}\")\n",
    "        continue\n",
    "\n",
    "# (スクリプト前半は変更なし)\n",
    "# ...\n",
    "\n",
    "# 3. ★★★ ラベル情報の処理方法を修正 ★★★\n",
    "print(\"\\nスペクトルデータの抽出が完了しました。ラベル情報を結合・整形します...\")\n",
    "\n",
    "# 3-0. ★★★ 元の位置情報をインデックスとして保存 ★★★\n",
    "pixel_features_df.reset_index(inplace=True)\n",
    "pixel_features_df.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "# 3-1. JSON内のラベルにのみ数値を割り当て\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "# (以下、pixel_label_maskの作成までは変更なし)\n",
    "# ...\n",
    "pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "# 3-2. ラベル名を対応付け\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "value_to_label_name[0] = '_unlabeled_'\n",
    "pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map(value_to_label_name)\n",
    "\n",
    "# 3-3. 不要なラベルを持つピクセルを除外\n",
    "labels_to_exclude = ['other', '_unlabeled_']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "# (以降の処理は変更なし)\n",
    "\n",
    "# 3-4. 不要なラベルを持つピクセルを除外\n",
    "initial_rows = len(pixel_features_df)\n",
    "labels_to_exclude = ['other', '_unlabeled_']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "# 3-5. 'background_ref' を 'background' に名称変更\n",
    "if 'background_ref' in pixel_features_df['label_name'].unique():\n",
    "    pixel_features_df['label_name'] = pixel_features_df['label_name'].replace({'background_ref': 'background'})\n",
    "    print(\"'background_ref' を 'background' に名称変更しました。\")\n",
    "\n",
    "final_rows = len(pixel_features_df)\n",
    "print(f\"除外対象 {labels_to_exclude} を持つピクセルを削除しました。\")\n",
    "print(f\"処理後の総ピクセル数: {final_rows} (削除されたピクセル数: {initial_rows - final_rows})\")\n",
    "\n",
    "# 4. データセットをCSVとして保存\n",
    "output_dir = main_dir / \"csv\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_csv_path = output_dir / \"pixel_features_with_background.csv\"\n",
    "pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'\\n新しいデータセットが作成されました: {output_csv_path}')\n",
    "print('\\nデータセットのプレビュー:')\n",
    "print(pixel_features_df.head())\n",
    "print('\\n含まれるラベル一覧:')\n",
    "print(pixel_features_df['label_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254660df",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899f79",
   "metadata": {},
   "source": [
    "### t-SNE データセットの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc54f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250911\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# ★★★ 変更点1: プロット用に'_background_'を'background'に名称変更 ★★★\n",
    "df_tsne['label'] = df_tsne['label'].replace({'_background_': 'background'})\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4e567",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa48a7d",
   "metadata": {},
   "source": [
    "### データセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# ------------------------------\n",
    "\n",
    "# データセットのパスを定義\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# データセット1を読み込む\n",
    "try:\n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    print(f\"データセット1を正常に読み込みました: {dataset1_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset1_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# データセット2を読み込む\n",
    "try:\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "    print(f\"データセット2を正常に読み込みました: {dataset2_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset2_csv_path} が見つかりません。\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_save(X_train, y_train, model_save_path):\n",
    "    print(f\"\\n--- モデルの学習を開始: {model_save_path.name} ---\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_save_path)\n",
    "    print(\"学習済みモデルを保存しました。\")\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\")\n",
    "    df2 = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# モデル1を学習・保存\n",
    "train_and_save(X1, y1, main_dir / \"model_trained_on_dataset1.joblib\")\n",
    "print(f\"データセット1（{dataset1_folder_name}）学習完了\")\n",
    "\n",
    "# モデル2を学習・保存\n",
    "train_and_save(X2, y2, main_dir / \"model_trained_on_dataset2.joblib\")\n",
    "print(f\"データセット2（{dataset2_folder_name}）学習完了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60af4b0",
   "metadata": {},
   "source": [
    "### 分類モデルの交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c899c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# ★★★ ここを修正 ★★★\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    # 'original_index' も特徴量ではないため、存在すれば除外\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    # 'label_value' はもう存在しないが、念のためチェック\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "# ★★★ ここまで ★★★\n",
    "\n",
    "def evaluate_model(model_path, X_test, y_test, model_name):\n",
    "    print(f\"\\n--- {model_name}の評価を開始 ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"評価が完了しました。実行時間: {elapsed_time:.2f}秒\")\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, model\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "    dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "    \n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# 交差検証1: モデル1を評価\n",
    "importance1, model1 = evaluate_model(main_dir / \"model_trained_on_dataset1.joblib\", X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: モデル2を評価\n",
    "importance2, model2 = evaluate_model(main_dir / \"model_trained_on_dataset2.joblib\", X1, y1, \"モデル2 (Dataset2で学習)\")\n",
    "\n",
    "# --- 結果を保存するコードブロック ---\n",
    "data1_output_dir = main_dir / dataset1_folder_name\n",
    "data2_output_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "# 交差検証1の結果\n",
    "with open(data1_output_dir / \"classification_report_model1.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# 交差検証2の結果\n",
    "with open(data2_output_dir / \"classification_report_model2.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# 特徴量重要度をCSVファイルとして保存\n",
    "importance1.to_csv(data1_output_dir / \"csv\" / \"importance_from_dataset1.csv\", index=False)\n",
    "importance2.to_csv(data2_output_dir / \"csv\" / \"importance_from_dataset2.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "print(f\"精度レポートと重要度ランキングは各データセットフォルダに保存されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41020d3",
   "metadata": {},
   "source": [
    "### 分類結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d76904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_trained_on_dataset1.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ 色とラベルの対応をここで一元管理 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"background\": \"gray\",\n",
    "    \"background_ref\": \"gray\" # 念のため_refも同じ色に\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスクを作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # 'background_ref' を 'background' として扱う\n",
    "    display_label = 'background' if label_name == 'background_ref' else label_name\n",
    "    \n",
    "    if display_label in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[display_label])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Annotation)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "# backgroundを除いた凡例を作成\n",
    "plot_labels = {k: v for k, v in label_to_color_map.items() if k not in ['background_ref']}\n",
    "\n",
    "for label_name, color in sorted(plot_labels.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_trained_on_dataset2.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ 色とラベルの対応をここで一元管理 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"background\": \"gray\",\n",
    "    \"background_ref\": \"gray\" # 念のため_refも同じ色に\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスクを作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # 'background_ref' を 'background' として扱う\n",
    "    display_label = 'background' if label_name == 'background_ref' else label_name\n",
    "    \n",
    "    if display_label in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[display_label])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Annotation)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "# backgroundを除いた凡例を作成\n",
    "plot_labels = {k: v for k, v in label_to_color_map.items() if k not in ['background_ref']}\n",
    "\n",
    "for label_name, color in sorted(plot_labels.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb4b14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ded58",
   "metadata": {},
   "source": [
    "## 学習・テスト対象：プラスチックのピクセル域のみ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f465110",
   "metadata": {},
   "source": [
    "### データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d317bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# main_dir や reference_file_stem はご自身の環境に合わせて設定してください\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準となるJSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: JSONファイルが見つかりません。パスを確認してください: {json_path}\")\n",
    "    exit()\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\"))\n",
    "if not image_files:\n",
    "    print(\"エラー: TIFF画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "image_size = (data['imageHeight'], data['imageWidth'])\n",
    "print(f\"画像サイズを検出しました: {image_size}\")\n",
    "\n",
    "for image_path in image_files:\n",
    "    if '-1_Em-1' in image_path.stem:\n",
    "        continue\n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    ex_wavelength = int(match.group(1))\n",
    "    em_wavelength = int(match.group(2))\n",
    "    if ex_wavelength == em_wavelength:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        if img.shape[:2] != image_size:\n",
    "            print(f\"警告: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"警告: {image_path.name} の処理に失敗しました。理由: {e}\")\n",
    "        continue\n",
    "\n",
    "# 3. ラベル情報の結合と整形\n",
    "print(\"\\nスペクトルデータの抽出が完了しました。ラベル情報を結合・整形します...\")\n",
    "pixel_features_df.reset_index(inplace=True)\n",
    "pixel_features_df.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "\n",
    "pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "value_to_label_name[0] = '_unlabeled_'\n",
    "pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map(value_to_label_name)\n",
    "\n",
    "# ★★★ ここからが変更点 ★★★\n",
    "# 3-1. 'background_ref' を 'background' に名称変更 (除外処理の前に行う)\n",
    "if 'background_ref' in pixel_features_df['label_name'].unique():\n",
    "    pixel_features_df['label_name'] = pixel_features_df['label_name'].replace({'background_ref': 'background'})\n",
    "    print(\"'background_ref' を 'background' に名称変更しました。\")\n",
    "\n",
    "# 3-2. 不要なラベルを持つピクセルを除外 (backgroundも除外対象に追加)\n",
    "initial_rows = len(pixel_features_df)\n",
    "labels_to_exclude = ['other', '_unlabeled_', 'background']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "final_rows = len(pixel_features_df)\n",
    "print(f\"除外対象 {labels_to_exclude} を持つピクセルを削除しました。\")\n",
    "print(f\"処理後の総ピクセル数: {final_rows} (削除されたピクセル数: {initial_rows - final_rows})\")\n",
    "# ★★★ ここまでが変更点 ★★★\n",
    "\n",
    "# 4. データセットをCSVとして保存\n",
    "output_dir = main_dir / \"csv\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# ★★★ 出力ファイル名を変更 ★★★\n",
    "output_csv_path = output_dir / \"pixel_features_plastics_only.csv\"\n",
    "pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'\\n新しい「プラスチックのみ」のデータセットが作成されました: {output_csv_path}')\n",
    "print('\\nデータセットのプレビュー:')\n",
    "print(pixel_features_df.head())\n",
    "print('\\n含まれるラベル一覧:')\n",
    "print(pixel_features_df['label_name'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74187b",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250911\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d812f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001e115",
   "metadata": {},
   "source": [
    "### データセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52104e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# ------------------------------\n",
    "\n",
    "# データセットのパスを定義\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# データセット1を読み込む\n",
    "try:\n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    print(f\"データセット1を正常に読み込みました: {dataset1_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset1_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# データセット2を読み込む\n",
    "try:\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "    print(f\"データセット2を正常に読み込みました: {dataset2_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset2_csv_path} が見つかりません。\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e64429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_save(X_train, y_train, model_save_path):\n",
    "    print(f\"\\n--- モデルの学習を開始: {model_save_path.name} ---\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_save_path)\n",
    "    print(\"学習済みモデルを保存しました。\")\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    # ★★★ 読み込むCSVファイル名を変更 ★★★\n",
    "    df1 = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\")\n",
    "    df2 = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    print(\"先に「データセット作成（プラスチックのみ）」スクリプトを実行してください。\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# ★★★ 保存するモデルファイル名を変更 ★★★\n",
    "# モデル1を学習・保存\n",
    "train_and_save(X1, y1, main_dir / \"model_plastics_only_dataset1.joblib\")\n",
    "print(f\"データセット1（{dataset1_folder_name}）学習完了\")\n",
    "\n",
    "# モデル2を学習・保存\n",
    "train_and_save(X2, y2, main_dir / \"model_plastics_only_dataset2.joblib\")\n",
    "print(f\"データセット2（{dataset2_folder_name}）学習完了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50516387",
   "metadata": {},
   "source": [
    "### 分類モデルの交差検証・特徴量重要度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f638533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model_path, X_test, y_test, model_name):\n",
    "    print(f\"\\n--- {model_name}の評価を開始 ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"評価が完了しました。実行時間: {elapsed_time:.2f}秒\")\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, model\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    # ★★★ 読み込むCSVファイル名を変更 ★★★\n",
    "    dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "    dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "    \n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# ★★★ 読み込むモデルファイル名を変更 ★★★\n",
    "# 交差検証1: モデル1を評価\n",
    "importance1, model1 = evaluate_model(main_dir / \"model_plastics_only_dataset1.joblib\", X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: モデル2を評価\n",
    "importance2, model2 = evaluate_model(main_dir / \"model_plastics_only_dataset2.joblib\", X1, y1, \"モデル2 (Dataset2で学習)\")\n",
    "\n",
    "# --- 結果を保存するコードブロック ---\n",
    "data1_output_dir = main_dir / dataset1_folder_name\n",
    "data2_output_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "# ★★★ 保存するレポートファイル名を変更 ★★★\n",
    "# 交差検証1の結果\n",
    "with open(data1_output_dir / \"classification_report_plastics_only_model1.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# 交差検証2の結果\n",
    "with open(data2_output_dir / \"classification_report_plastics_only_model2.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# ★★★ 保存する重要度ファイル名を変更 ★★★\n",
    "# 特徴量重要度をCSVファイルとして保存\n",
    "importance1.to_csv(data1_output_dir / \"csv\" / \"importance_plastics_only_from_dataset1.csv\", index=False)\n",
    "importance2.to_csv(data2_output_dir / \"csv\" / \"importance_plastics_only_from_dataset2.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "print(f\"精度レポートと重要度ランキングは各データセットフォルダに保存されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4bf36",
   "metadata": {},
   "source": [
    "### 分類結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088975ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 使用する学習済みモデル (プラスチックのみで学習させたモデル)\n",
    "model_path = main_dir / \"model_plastics_only_dataset1.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ プラスチックの色のみを定義 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\"\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "# ★★★ プラスチックのみのCSVを読み込む ★★★\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスク（プラスチックのみ）を作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換 (★★★ 背景は描画しない ★★★)\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # プラスチックラベルのみを色付けする\n",
    "    if label_name in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[label_name])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Plastics Only)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction (Plastics Only)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "for label_name, color in sorted(label_to_color_map.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "# 使用する学習済みモデル (プラスチックのみで学習させたモデル)\n",
    "model_path = main_dir / \"model_plastics_only_dataset2.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ プラスチックの色のみを定義 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\"\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "# ★★★ プラスチックのみのCSVを読み込む ★★★\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスク（プラスチックのみ）を作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換 (★★★ 背景は描画しない ★★★)\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # プラスチックラベルのみを色付けする\n",
    "    if label_name in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[label_name])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Plastics Only)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction (Plastics Only)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "for label_name, color in sorted(label_to_color_map.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83abe17",
   "metadata": {},
   "source": [
    "### 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ff664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- ユーザー設定 (ここを編集してください) ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "\n",
    "# --- 検証パターンを選択 ---\n",
    "# A: 背景ありデータセット / B: プラスチックのみデータセット\n",
    "# -----------------------------\n",
    "# ★★★ 今回は「B: プラスチックのみ」の交差検証を可視化 ★★★\n",
    "# -----------------------------\n",
    "# 評価に使用するデータセット\n",
    "evaluation_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_plastics_only_dataset1.joblib\"\n",
    "# 使用するCSVファイル\n",
    "csv_filename = \"pixel_features_plastics_only.csv\"\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "test_data_path = main_dir / evaluation_dataset_folder_name / \"csv\" / csv_filename\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量 (X_test) と正解ラベル (y_true) を準備\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_true = df_test['label_name']\n",
    "\n",
    "# 2. モデルによる予測\n",
    "print(\"\\n--- ラベルを予測 ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. 混同行列の計算\n",
    "# ラベルの順序をアルファベット順で固定\n",
    "labels = sorted(y_true.unique())\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# 4. 混同行列の可視化 (生データ)\n",
    "print(\"\\n--- 混同行列の可視化 ---\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix (Plastics Only - Raw Counts)', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 5. 正規化された混同行列の可視化 (行の合計が1になるように正規化)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix (Plastics Only - Recall)', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74012a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- ユーザー設定 (ここを編集してください) ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "\n",
    "# --- 検証パターンを選択 ---\n",
    "# A: 背景ありデータセット / B: プラスチックのみデータセット\n",
    "# -----------------------------\n",
    "# ★★★ 今回は「B: プラスチックのみ」の交差検証を可視化 ★★★\n",
    "# -----------------------------\n",
    "# 評価に使用するデータセット\n",
    "evaluation_dataset_folder_name = \"MPs_20250911\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_plastics_only_dataset2.joblib\"\n",
    "# 使用するCSVファイル\n",
    "csv_filename = \"pixel_features_plastics_only.csv\"\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "test_data_path = main_dir / evaluation_dataset_folder_name / \"csv\" / csv_filename\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量 (X_test) と正解ラベル (y_true) を準備\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_true = df_test['label_name']\n",
    "\n",
    "# 2. モデルによる予測\n",
    "print(\"\\n--- ラベルを予測 ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. 混同行列の計算\n",
    "# ラベルの順序をアルファベット順で固定\n",
    "labels = sorted(y_true.unique())\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# 4. 混同行列の可視化 (生データ)\n",
    "print(\"\\n--- 混同行列の可視化 ---\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix (Plastics Only - Raw Counts)', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 5. 正規化された混同行列の可視化 (行の合計が1になるように正規化)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Normalized Confusion Matrix (Plastics Only - Recall)', fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403fad1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2089b",
   "metadata": {},
   "source": [
    "# 特徴量重要度から分類に必要な計測時間と精度を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# プラスチックのみのデータセットを使用\n",
    "csv_filename = \"pixel_features_plastics_only.csv\"\n",
    "importance_filename1 = \"importance_plastics_only_from_dataset1.csv\"\n",
    "importance_filename2 = \"importance_plastics_only_from_dataset2.csv\"\n",
    "# --------------------\n",
    "\n",
    "# 1. 2つの特徴量重要度ランキングのファイルを読み込み、統合する\n",
    "print(\"--- ステップ1: 共通重要度ランキングの作成 ---\")\n",
    "try:\n",
    "    imp1_df = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / importance_filename1)\n",
    "    imp2_df = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / importance_filename2)\n",
    "\n",
    "    # 2つのランキングを特徴量名で結合し、平均重要度を計算\n",
    "    merged_imp = pd.merge(imp1_df, imp2_df, on='feature', suffixes=('_d1', '_d2'))\n",
    "    merged_imp['average_importance'] = (merged_imp['importance_d1'] + merged_imp['importance_d2']) / 2\n",
    "\n",
    "    # 平均重要度でソートし、最終的なランキングを作成\n",
    "    final_importances = merged_imp.sort_values('average_importance', ascending=False)\n",
    "    sorted_features = final_importances['feature'].tolist()\n",
    "    \n",
    "    print(\"2つのモデルの平均重要度に基づき、特徴量ランキングを再計算しました。\")\n",
    "    print(\"重要度トップ5の分光画像:\")\n",
    "    print(sorted_features[:5])\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: 特徴量重要度ファイルが見つかりません: {e.filename}\")\n",
    "    print(\"先に「交差検証（プラスチックのみ）」スクリプトを実行して、重要度ファイルを作成してください。\")\n",
    "    exit()\n",
    "\n",
    "# 2. 検証に使用するデータセットを読み込む\n",
    "df1 = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / csv_filename)\n",
    "df2 = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / csv_filename)\n",
    "print(\"\\n検証用データセットの読み込みが完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "# 検証する特徴量の枚数のリスト\n",
    "# num_features_steps = [1, 5, 10, 20, 30, 50, 100, 150, 200]\n",
    "num_features_steps = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# 結果を保存するためのリスト\n",
    "results_log = []\n",
    "\n",
    "def prepare_data(df, features_to_use):\n",
    "    \"\"\"指定された特徴量だけを使ってX, yを準備する関数\"\"\"\n",
    "    # label_nameと指定された特徴量だけを抽出\n",
    "    subset_df = df[['label_name'] + features_to_use]\n",
    "    X = subset_df.drop(columns=['label_name'])\n",
    "    y = subset_df['label_name']\n",
    "    return X, y\n",
    "\n",
    "# ステップごとにループ\n",
    "for n_features in num_features_steps:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 使用する特徴量を上位から選択\n",
    "    selected_features = sorted_features[:n_features]\n",
    "    \n",
    "    print(f\"\\n--- 特徴量 {n_features} 枚で交差検証中... ---\")\n",
    "    \n",
    "    # 1. データセット1で学習 -> データセット2で評価\n",
    "    X1, y1 = prepare_data(df1, selected_features)\n",
    "    X2, y2 = prepare_data(df2, selected_features)\n",
    "    \n",
    "    model1 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model1.fit(X1, y1)\n",
    "    y_pred1 = model1.predict(X2)\n",
    "    report1 = classification_report(y2, y_pred1, output_dict=True, zero_division=0)\n",
    "\n",
    "    # 2. データセット2で学習 -> データセット1で評価\n",
    "    model2 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model2.fit(X2, y2)\n",
    "    y_pred2 = model2.predict(X1)\n",
    "    report2 = classification_report(y1, y_pred2, output_dict=True, zero_division=0)\n",
    "    \n",
    "    # 3. 両方向のF1スコアの平均を記録\n",
    "    result_row = {'num_features': n_features}\n",
    "    all_labels = sorted(list(set(y1) | set(y2))) # 全ラベルのリストを作成\n",
    "    for label in all_labels:\n",
    "        f1_1 = report1.get(label, {}).get('f1-score', 0)\n",
    "        f1_2 = report2.get(label, {}).get('f1-score', 0)\n",
    "        result_row[label] = (f1_1 + f1_2) / 2.0\n",
    "    results_log.append(result_row)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"完了。処理時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 結果をDataFrameに変換\n",
    "results_df = pd.DataFrame(results_log)\n",
    "results_df.to_csv(main_dir / \"crossval_performance_vs_num_features.csv\", index=False)\n",
    "print(\"\\n--- 全ステップの評価が完了しました ---\")\n",
    "print(\"結果を crossval_performance_vs_num_features.csv に保存しました。\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ステップ2で作成したDataFrame (results_df) を使用\n",
    "df_melted = results_df.melt(id_vars='num_features', var_name='plastic_type', value_name='f1_score')\n",
    "\n",
    "# グラフの描画\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "sns.lineplot(data=df_melted, x='num_features', y='f1_score', hue='plastic_type', marker='o', palette='tab10')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.title('Cross-Validation Performance vs. Number of Top Features', fontsize=20)\n",
    "plt.xlabel('Number of Spectral Images Used (by importance)', fontsize=14)\n",
    "plt.ylabel('Average F1-Score (Cross-Validation)', fontsize=14)\n",
    "plt.xticks(results_df['num_features'].unique(), rotation=45)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(title='Plastic Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc645d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7ad50",
   "metadata": {},
   "source": [
    "### 分光画像の平均画素値から、EEMを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54627c",
   "metadata": {},
   "source": [
    "平均スペクトルデータの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "folder_name = \"MPs_20250911\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "# --------------------\n",
    "\n",
    "# 1. JSONファイルを読み込み、ラベルマスクを作成\n",
    "print(\"--- ステップ1: 平均スペクトルデータの作成 ---\")\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "image_size = (data['imageHeight'], data['imageWidth'])\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "class_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 2. 各分光画像を読み込み、プラスチックごとに画素値の平均を計算\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\"))\n",
    "\n",
    "# 結果を格納する辞書を初期化\n",
    "mean_spectra = {label: {} for label in labels_in_json}\n",
    "\n",
    "for image_path in image_files:\n",
    "    if '-1_Em-1' in image_path.stem: continue\n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match: continue\n",
    "    \n",
    "    ex_wave = int(match.group(1))\n",
    "    em_wave = int(match.group(2))\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to process {image_path.name}. Reason: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 各プラスチック領域の平均値を計算\n",
    "    for label_name, label_value in label_name_to_value.items():\n",
    "        mean_intensity = np.mean(img[class_label_mask == label_value])\n",
    "        mean_spectra[label_name][(ex_wave, em_wave)] = mean_intensity\n",
    "\n",
    "print(\"平均スペクトルデータの作成が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70413ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "# EEMの軸範囲と刻み幅\n",
    "EX_MIN, EX_MAX, EX_STEP = 260, 600, 20\n",
    "EM_MIN, EM_MAX, EM_STEP = 260, 600, 20\n",
    "\n",
    "# ★★★ プロットする順番をここで指定 ★★★\n",
    "plastics_to_plot = [\n",
    "    'PP', 'PC', 'ABS',\n",
    "    'PS', 'PET', 'HDPE',\n",
    "    'PVC', 'PMMA', 'LDPE'\n",
    "]\n",
    "# --------------------\n",
    "\n",
    "# EEMの軸を定義\n",
    "excitation_axis = np.arange(EX_MIN, EX_MAX + EX_STEP, EX_STEP)\n",
    "emission_axis = np.arange(EM_MIN, EM_MAX + EM_STEP, EM_STEP)\n",
    "\n",
    "# 各プラスチックについてEEMを作成・描画\n",
    "num_plastics = len(plastics_to_plot)\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(num_plastics / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 5, nrows * 5))\n",
    "if nrows == 1 or ncols == 1:\n",
    "    axes = np.array(axes).reshape(nrows, ncols)\n",
    "\n",
    "for i, plastic_name in enumerate(plastics_to_plot):\n",
    "    # check if the plastic name from the custom list exists in the data\n",
    "    if plastic_name not in mean_spectra:\n",
    "        print(f\"警告: 指定されたプラスチック '{plastic_name}' のデータが見つかりません。スキップします。\")\n",
    "        # Turn off the axis for the empty plot\n",
    "        ax = axes[i // ncols, i % ncols]\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "\n",
    "    ax = axes[i // ncols, i % ncols]\n",
    "    \n",
    "    # EEM行列の形を(励起, 放射)に入れ替え\n",
    "    eem_matrix = np.full((len(excitation_axis), len(emission_axis)), np.nan)\n",
    "    \n",
    "    # 平均スペクトルデータをEEM行列にマッピング\n",
    "    for (ex, em), intensity in mean_spectra[plastic_name].items():\n",
    "        try:\n",
    "            ex_idx = np.where(excitation_axis == ex)[0][0]\n",
    "            em_idx = np.where(emission_axis == em)[0][0]\n",
    "            # 行と列のインデックスを入れ替え\n",
    "            eem_matrix[ex_idx, em_idx] = intensity\n",
    "        except IndexError:\n",
    "            pass\n",
    "            \n",
    "    # 散乱光や無効領域をマスク\n",
    "    for ex_idx, ex in enumerate(excitation_axis):\n",
    "        for em_idx, em in enumerate(emission_axis):\n",
    "            if em <= ex:\n",
    "                 # 行と列のインデックスを入れ替え\n",
    "                eem_matrix[ex_idx, em_idx] = np.nan\n",
    "\n",
    "    # ヒートマップを描画\n",
    "    cmap = plt.get_cmap('viridis').copy()\n",
    "    cmap.set_bad(color='black')\n",
    "    \n",
    "    # extentの範囲を(放射, 励起)に入れ替え\n",
    "    im = ax.imshow(eem_matrix, cmap=cmap, origin='lower', \n",
    "                   extent=[EM_MIN, EM_MAX, EX_MIN, EX_MAX], aspect='auto')\n",
    "    \n",
    "    # 表示範囲の軸を入れ替え\n",
    "    ax.set_xlim(250, 600)\n",
    "    ax.set_ylim(250, 600)\n",
    "    \n",
    "    ax.set_title(plastic_name)\n",
    "    # X軸とY軸のラベルを入れ替え\n",
    "    ax.set_xlabel('Emission (nm)')\n",
    "    ax.set_ylabel('Excitation (nm)')\n",
    "\n",
    "    # グリッドを非表示にする\n",
    "    ax.grid(False)\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Intensity')\n",
    "\n",
    "# 使わないサブプロットを非表示\n",
    "for j in range(i + 1, nrows * ncols):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
