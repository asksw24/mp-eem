{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f8c782",
   "metadata": {},
   "source": [
    "# labelmeの結果可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2430386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "json_path = main_dir / (file_stem + \".json\")\n",
    "image_path = main_dir / (file_stem + \".tiff\")\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ラベル名と数値の対応辞書を作成\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# マスクを生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 各ラベルごとに画素値を抽出し、統計量を算出\n",
    "results = {}\n",
    "for label_name, value in label_name_to_value.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    \n",
    "    # ラベルに対応するマスクを作成\n",
    "    label_mask = (lbl == value)\n",
    "    pixel_values = img[label_mask]\n",
    "    \n",
    "    if len(pixel_values) > 0:\n",
    "        results[label_name] = {\n",
    "            'pixel_count': len(pixel_values),\n",
    "            'mean': np.mean(pixel_values),\n",
    "            'std_dev': np.std(pixel_values),\n",
    "            'max_value': np.max(pixel_values),\n",
    "            'min_value': np.min(pixel_values)\n",
    "        }\n",
    "    else:\n",
    "        results[label_name] = \"No pixels found for this label.\"\n",
    "\n",
    "# 結果を整形して表示\n",
    "for label, stats in results.items():\n",
    "    print(f'--- ラベル: {label} ---')\n",
    "    if isinstance(stats, str):\n",
    "        print(stats)\n",
    "    else:\n",
    "        print(f'画素数: {stats[\"pixel_count\"]}')\n",
    "        print(f'平均値: {stats[\"mean\"]}')\n",
    "        print(f'標準偏差: {stats[\"std_dev\"]}')\n",
    "        print(f'最大値: {stats[\"max_value\"]}')\n",
    "        print(f'最小値: {stats[\"min_value\"]}')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68da0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# # プロジェクトのメインディレクトリ\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "\n",
    "# # 画像とJSONファイルのパス\n",
    "# json_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.json\"\n",
    "# image_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(image_path)\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# label_name_to_value を作成\n",
    "label_name_to_value = {\"_background_\": 0}  # 背景は0\n",
    "for shape in data[\"shapes\"]:\n",
    "    label_name = shape[\"label\"]\n",
    "    if label_name not in label_name_to_value:\n",
    "        label_name_to_value[label_name] = len(label_name_to_value)\n",
    "\n",
    "# マスクを生成（新しいAPI）\n",
    "lbl, _ = labelme.utils.shapes_to_label(\n",
    "    img_shape=img.shape,\n",
    "    shapes=data[\"shapes\"],\n",
    "    label_name_to_value=label_name_to_value\n",
    ")\n",
    "\n",
    "# マスクを可視化\n",
    "mask = (lbl > 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Mask Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# 画像ファイルのパスを指定してください\n",
    "# 基準画像のパス\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2/MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# 比較したい分光画像のパス（例）\n",
    "spectral_image_path = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}/{folder_name}_Ex360_Em480_ET10000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 画像を重ねて表示\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.imshow(ref_img, cmap='gray', alpha=1.0) # 基準画像を背景に表示\n",
    "ax.imshow(spec_img, cmap='jet', alpha=0.5) # 分光画像を半透明で重ねて表示\n",
    "ax.set_title('Image Alignment Check')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "# # 画像ファイルのパスを指定\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# spectral_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex260_Em280_ET20000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 位相相関法でずれを計算\n",
    "# output: ずれの量 (y, x), 誤差, 位相相関のピーク\n",
    "shift, error, phase = phase_cross_correlation(ref_img, spec_img)\n",
    "\n",
    "# ずれの量（ピクセル単位）を表示\n",
    "print(f'基準画像に対する分光画像のずれ:')\n",
    "print(f'  y方向 (縦): {shift[0]:.2f} ピクセル')\n",
    "print(f'  x方向 (横): {shift[1]:.2f} ピクセル')\n",
    "print(f'  誤差: {error:.4f}')\n",
    "\n",
    "# ずれが非常に小さい（0に近い）ことを確認し、問題ないと判断\n",
    "if np.sqrt(shift[0]**2 + shift[1]**2) < 1.0:\n",
    "    print(\"\\n画像間のずれは1ピクセル未満です。位置合わせは正確であると考えられます。\")\n",
    "else:\n",
    "    print(\"\\n画像間にずれがある可能性があります。再撮影または画像補正を検討してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f122874",
   "metadata": {},
   "source": [
    "# ピクセル単位での分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8fa9b",
   "metadata": {},
   "source": [
    "## ラベリング結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # 凡例用\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\") # ラベリングに使用した元の画像パス\n",
    "\n",
    "print(f\"Loading JSON file: {json_path}\")\n",
    "print(f\"Loading original image: {image_path}\")\n",
    "\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: JSONファイル '{json_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    original_img = np.asarray(Image.open(image_path))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: 元画像ファイル '{image_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# ラベル名と数値の対応付け\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0 # 背景には0を割り当てる\n",
    "\n",
    "# ラベルマップ（数値）を生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(original_img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 可視化用のカラーマップを生成\n",
    "# ラベル数に応じて色を割り当てる\n",
    "unique_labels = np.unique(lbl)\n",
    "colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "colored_mask = np.zeros((*lbl.shape, 3), dtype=np.uint8)\n",
    "legend_patches = []\n",
    "label_value_to_color = {}\n",
    "\n",
    "for i, label_value in enumerate(unique_labels):\n",
    "    if label_value == 0:\n",
    "        color = np.array([0, 0, 0])\n",
    "        label_name = 'background'\n",
    "    else:\n",
    "        # 修正: np.array()で一度配列に変換してからastype()を適用\n",
    "        color = (np.array(colors(i)[:3]) * 255).astype(np.uint8)\n",
    "        label_name = list(label_name_to_value.keys())[list(label_name_to_value.values()).index(label_value)]\n",
    "        legend_patches.append(mpatches.Patch(color=color/255., label=label_name))\n",
    "    \n",
    "    colored_mask[lbl == label_value] = color\n",
    "\n",
    "# 元画像とカラーマスクを並べて表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(colored_mask)\n",
    "axes[1].set_title('Labeled Mask (Pixel-wise Labels)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化されたラベリング結果を確認しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b2aeb",
   "metadata": {},
   "source": [
    "---\n",
    "# 2つのデータセットを用いた交差検証\n",
    "## 学習・テスト対象：背景とプラスチックラベル域のピクセル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcf5a7",
   "metadata": {},
   "source": [
    "### データセットの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83470f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# main_dir や reference_file_stem はご自身の環境に合わせて設定してください\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準となるJSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: JSONファイルが見つかりません。パスを確認してください: {json_path}\")\n",
    "    exit()\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出 (この部分は変更なし)\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\"))\n",
    "if not image_files:\n",
    "    print(\"エラー: TIFF画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "image_size = (data['imageHeight'], data['imageWidth'])\n",
    "print(f\"画像サイズを検出しました: {image_size}\")\n",
    "\n",
    "for image_path in image_files:\n",
    "    if '-1_Em-1' in image_path.stem:\n",
    "        continue\n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    ex_wavelength = int(match.group(1))\n",
    "    em_wavelength = int(match.group(2))\n",
    "    if ex_wavelength == em_wavelength:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        if img.shape[:2] != image_size:\n",
    "            print(f\"警告: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"警告: {image_path.name} の処理に失敗しました。理由: {e}\")\n",
    "        continue\n",
    "\n",
    "# (スクリプト前半は変更なし)\n",
    "# ...\n",
    "\n",
    "# 3. ★★★ ラベル情報の処理方法を修正 ★★★\n",
    "print(\"\\nスペクトルデータの抽出が完了しました。ラベル情報を結合・整形します...\")\n",
    "\n",
    "# 3-0. ★★★ 元の位置情報をインデックスとして保存 ★★★\n",
    "pixel_features_df.reset_index(inplace=True)\n",
    "pixel_features_df.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "# 3-1. JSON内のラベルにのみ数値を割り当て\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "# (以下、pixel_label_maskの作成までは変更なし)\n",
    "# ...\n",
    "pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "# 3-2. ラベル名を対応付け\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "value_to_label_name[0] = '_unlabeled_'\n",
    "pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map(value_to_label_name)\n",
    "\n",
    "# 3-3. 不要なラベルを持つピクセルを除外\n",
    "labels_to_exclude = ['other', '_unlabeled_']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "# (以降の処理は変更なし)\n",
    "\n",
    "# 3-4. 不要なラベルを持つピクセルを除外\n",
    "initial_rows = len(pixel_features_df)\n",
    "labels_to_exclude = ['other', '_unlabeled_']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "# 3-5. 'background_ref' を 'background' に名称変更\n",
    "if 'background_ref' in pixel_features_df['label_name'].unique():\n",
    "    pixel_features_df['label_name'] = pixel_features_df['label_name'].replace({'background_ref': 'background'})\n",
    "    print(\"'background_ref' を 'background' に名称変更しました。\")\n",
    "\n",
    "final_rows = len(pixel_features_df)\n",
    "print(f\"除外対象 {labels_to_exclude} を持つピクセルを削除しました。\")\n",
    "print(f\"処理後の総ピクセル数: {final_rows} (削除されたピクセル数: {initial_rows - final_rows})\")\n",
    "\n",
    "# 4. データセットをCSVとして保存\n",
    "output_dir = main_dir / \"csv\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_csv_path = output_dir / \"pixel_features_with_background.csv\"\n",
    "pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'\\n新しいデータセットが作成されました: {output_csv_path}')\n",
    "print('\\nデータセットのプレビュー:')\n",
    "print(pixel_features_df.head())\n",
    "print('\\n含まれるラベル一覧:')\n",
    "print(pixel_features_df['label_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254660df",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899f79",
   "metadata": {},
   "source": [
    "### t-SNE データセットの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc54f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250911\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# ★★★ 変更点1: プロット用に'_background_'を'background'に名称変更 ★★★\n",
    "df_tsne['label'] = df_tsne['label'].replace({'_background_': 'background'})\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4e567",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa48a7d",
   "metadata": {},
   "source": [
    "### データセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# ------------------------------\n",
    "\n",
    "# データセットのパスを定義\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# データセット1を読み込む\n",
    "try:\n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    print(f\"データセット1を正常に読み込みました: {dataset1_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset1_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# データセット2を読み込む\n",
    "try:\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "    print(f\"データセット2を正常に読み込みました: {dataset2_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset2_csv_path} が見つかりません。\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_save(X_train, y_train, model_save_path):\n",
    "    print(f\"\\n--- モデルの学習を開始: {model_save_path.name} ---\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_save_path)\n",
    "    print(\"学習済みモデルを保存しました。\")\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\")\n",
    "    df2 = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# モデル1を学習・保存\n",
    "train_and_save(X1, y1, main_dir / \"model_trained_on_dataset1.joblib\")\n",
    "print(f\"データセット1（{dataset1_folder_name}）学習完了\")\n",
    "\n",
    "# モデル2を学習・保存\n",
    "train_and_save(X2, y2, main_dir / \"model_trained_on_dataset2.joblib\")\n",
    "print(f\"データセット2（{dataset2_folder_name}）学習完了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60af4b0",
   "metadata": {},
   "source": [
    "### 分類モデルの交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c899c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# ★★★ ここを修正 ★★★\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    # 'original_index' も特徴量ではないため、存在すれば除外\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    # 'label_value' はもう存在しないが、念のためチェック\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "# ★★★ ここまで ★★★\n",
    "\n",
    "def evaluate_model(model_path, X_test, y_test, model_name):\n",
    "    print(f\"\\n--- {model_name}の評価を開始 ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"評価が完了しました。実行時間: {elapsed_time:.2f}秒\")\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, model\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "    dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "    \n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# 交差検証1: モデル1を評価\n",
    "importance1, model1 = evaluate_model(main_dir / \"model_trained_on_dataset1.joblib\", X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: モデル2を評価\n",
    "importance2, model2 = evaluate_model(main_dir / \"model_trained_on_dataset2.joblib\", X1, y1, \"モデル2 (Dataset2で学習)\")\n",
    "\n",
    "# --- 結果を保存するコードブロック ---\n",
    "data1_output_dir = main_dir / dataset1_folder_name\n",
    "data2_output_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "# 交差検証1の結果\n",
    "with open(data1_output_dir / \"classification_report_model1.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# 交差検証2の結果\n",
    "with open(data2_output_dir / \"classification_report_model2.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# 特徴量重要度をCSVファイルとして保存\n",
    "importance1.to_csv(data1_output_dir / \"csv\" / \"importance_from_dataset1.csv\", index=False)\n",
    "importance2.to_csv(data2_output_dir / \"csv\" / \"importance_from_dataset2.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "print(f\"精度レポートと重要度ランキングは各データセットフォルダに保存されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41020d3",
   "metadata": {},
   "source": [
    "### 分類結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d76904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_trained_on_dataset1.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ 色とラベルの対応をここで一元管理 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"background\": \"gray\",\n",
    "    \"background_ref\": \"gray\" # 念のため_refも同じ色に\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスクを作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # 'background_ref' を 'background' として扱う\n",
    "    display_label = 'background' if label_name == 'background_ref' else label_name\n",
    "    \n",
    "    if display_label in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[display_label])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Annotation)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "# backgroundを除いた凡例を作成\n",
    "plot_labels = {k: v for k, v in label_to_color_map.items() if k not in ['background_ref']}\n",
    "\n",
    "for label_name, color in sorted(plot_labels.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "# 使用する学習済みモデル\n",
    "model_path = main_dir / \"model_trained_on_dataset2.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ 色とラベルの対応をここで一元管理 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"background\": \"gray\",\n",
    "    \"background_ref\": \"gray\" # 念のため_refも同じ色に\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスクを作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # 'background_ref' を 'background' として扱う\n",
    "    display_label = 'background' if label_name == 'background_ref' else label_name\n",
    "    \n",
    "    if display_label in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[display_label])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Annotation)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "# backgroundを除いた凡例を作成\n",
    "plot_labels = {k: v for k, v in label_to_color_map.items() if k not in ['background_ref']}\n",
    "\n",
    "for label_name, color in sorted(plot_labels.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb4b14",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ded58",
   "metadata": {},
   "source": [
    "## 学習・テスト対象：プラスチックのピクセル域のみ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f465110",
   "metadata": {},
   "source": [
    "### データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d317bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# main_dir や reference_file_stem はご自身の環境に合わせて設定してください\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準となるJSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: JSONファイルが見つかりません。パスを確認してください: {json_path}\")\n",
    "    exit()\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\"))\n",
    "if not image_files:\n",
    "    print(\"エラー: TIFF画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "image_size = (data['imageHeight'], data['imageWidth'])\n",
    "print(f\"画像サイズを検出しました: {image_size}\")\n",
    "\n",
    "for image_path in image_files:\n",
    "    if '-1_Em-1' in image_path.stem:\n",
    "        continue\n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    ex_wavelength = int(match.group(1))\n",
    "    em_wavelength = int(match.group(2))\n",
    "    if ex_wavelength == em_wavelength:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        if img.shape[:2] != image_size:\n",
    "            print(f\"警告: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"警告: {image_path.name} の処理に失敗しました。理由: {e}\")\n",
    "        continue\n",
    "\n",
    "# 3. ラベル情報の結合と整形\n",
    "print(\"\\nスペクトルデータの抽出が完了しました。ラベル情報を結合・整形します...\")\n",
    "pixel_features_df.reset_index(inplace=True)\n",
    "pixel_features_df.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "\n",
    "pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "value_to_label_name[0] = '_unlabeled_'\n",
    "pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map(value_to_label_name)\n",
    "\n",
    "# ★★★ ここからが変更点 ★★★\n",
    "# 3-1. 'background_ref' を 'background' に名称変更 (除外処理の前に行う)\n",
    "if 'background_ref' in pixel_features_df['label_name'].unique():\n",
    "    pixel_features_df['label_name'] = pixel_features_df['label_name'].replace({'background_ref': 'background'})\n",
    "    print(\"'background_ref' を 'background' に名称変更しました。\")\n",
    "\n",
    "# 3-2. 不要なラベルを持つピクセルを除外 (backgroundも除外対象に追加)\n",
    "initial_rows = len(pixel_features_df)\n",
    "labels_to_exclude = ['other', '_unlabeled_', 'background']\n",
    "pixel_features_df = pixel_features_df[~pixel_features_df['label_name'].isin(labels_to_exclude)].copy()\n",
    "\n",
    "final_rows = len(pixel_features_df)\n",
    "print(f\"除外対象 {labels_to_exclude} を持つピクセルを削除しました。\")\n",
    "print(f\"処理後の総ピクセル数: {final_rows} (削除されたピクセル数: {initial_rows - final_rows})\")\n",
    "# ★★★ ここまでが変更点 ★★★\n",
    "\n",
    "# 4. データセットをCSVとして保存\n",
    "output_dir = main_dir / \"csv\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# ★★★ 出力ファイル名を変更 ★★★\n",
    "output_csv_path = output_dir / \"pixel_features_plastics_only.csv\"\n",
    "pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'\\n新しい「プラスチックのみ」のデータセットが作成されました: {output_csv_path}')\n",
    "print('\\nデータセットのプレビュー:')\n",
    "print(pixel_features_df.head())\n",
    "print('\\n含まれるラベル一覧:')\n",
    "print(pixel_features_df['label_name'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d74187b",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaa674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250911\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d812f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001e115",
   "metadata": {},
   "source": [
    "### データセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52104e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# ------------------------------\n",
    "\n",
    "# データセットのパスを定義\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# データセット1を読み込む\n",
    "try:\n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    print(f\"データセット1を正常に読み込みました: {dataset1_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset1_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# データセット2を読み込む\n",
    "try:\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "    print(f\"データセット2を正常に読み込みました: {dataset2_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset2_csv_path} が見つかりません。\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e64429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_save(X_train, y_train, model_save_path):\n",
    "    print(f\"\\n--- モデルの学習を開始: {model_save_path.name} ---\")\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_save_path)\n",
    "    print(\"学習済みモデルを保存しました。\")\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    # ★★★ 読み込むCSVファイル名を変更 ★★★\n",
    "    df1 = pd.read_csv(main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\")\n",
    "    df2 = pd.read_csv(main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    print(\"先に「データセット作成（プラスチックのみ）」スクリプトを実行してください。\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# ★★★ 保存するモデルファイル名を変更 ★★★\n",
    "# モデル1を学習・保存\n",
    "train_and_save(X1, y1, main_dir / \"model_plastics_only_dataset1.joblib\")\n",
    "print(f\"データセット1（{dataset1_folder_name}）学習完了\")\n",
    "\n",
    "# モデル2を学習・保存\n",
    "train_and_save(X2, y2, main_dir / \"model_plastics_only_dataset2.joblib\")\n",
    "print(f\"データセット2（{dataset2_folder_name}）学習完了\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50516387",
   "metadata": {},
   "source": [
    "### 分類モデルの交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f638533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# original_indexを除外する、正しいprepare_data関数\n",
    "def prepare_data(df):\n",
    "    \"\"\"データフレームから特徴量とラベルを分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    \n",
    "    # 除外する列のリストを作成\n",
    "    columns_to_drop = ['label_name']\n",
    "    if 'original_index' in df.columns:\n",
    "        columns_to_drop.append('original_index')\n",
    "    if 'label_value' in df.columns:\n",
    "        columns_to_drop.append('label_value')\n",
    "    \n",
    "    X = df.drop(columns=columns_to_drop)\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model_path, X_test, y_test, model_name):\n",
    "    print(f\"\\n--- {model_name}の評価を開始 ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"評価が完了しました。実行時間: {elapsed_time:.2f}秒\")\n",
    "    \n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, model\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# --------------------\n",
    "\n",
    "try:\n",
    "    # ★★★ 読み込むCSVファイル名を変更 ★★★\n",
    "    dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "    dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "    \n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"エラー: CSVファイルが見つかりません。パスを確認してください。: {e.filename}\")\n",
    "    exit()\n",
    "\n",
    "# データの前処理\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# ★★★ 読み込むモデルファイル名を変更 ★★★\n",
    "# 交差検証1: モデル1を評価\n",
    "importance1, model1 = evaluate_model(main_dir / \"model_plastics_only_dataset1.joblib\", X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: モデル2を評価\n",
    "importance2, model2 = evaluate_model(main_dir / \"model_plastics_only_dataset2.joblib\", X1, y1, \"モデル2 (Dataset2で学習)\")\n",
    "\n",
    "# --- 結果を保存するコードブロック ---\n",
    "data1_output_dir = main_dir / dataset1_folder_name\n",
    "data2_output_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "# ★★★ 保存するレポートファイル名を変更 ★★★\n",
    "# 交差検証1の結果\n",
    "with open(data1_output_dir / \"classification_report_plastics_only_model1.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# 交差検証2の結果\n",
    "with open(data2_output_dir / \"classification_report_plastics_only_model2.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# ★★★ 保存する重要度ファイル名を変更 ★★★\n",
    "# 特徴量重要度をCSVファイルとして保存\n",
    "importance1.to_csv(data1_output_dir / \"csv\" / \"importance_plastics_only_from_dataset1.csv\", index=False)\n",
    "importance2.to_csv(data2_output_dir / \"csv\" / \"importance_plastics_only_from_dataset2.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "print(f\"精度レポートと重要度ランキングは各データセットフォルダに保存されました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4bf36",
   "metadata": {},
   "source": [
    "### 分類結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088975ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 使用する学習済みモデル (プラスチックのみで学習させたモデル)\n",
    "model_path = main_dir / \"model_plastics_only_dataset1.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ プラスチックの色のみを定義 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\"\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "# ★★★ プラスチックのみのCSVを読み込む ★★★\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスク（プラスチックのみ）を作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換 (★★★ 背景は描画しない ★★★)\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # プラスチックラベルのみを色付けする\n",
    "    if label_name in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[label_name])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Plastics Only)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction (Plastics Only)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "for label_name, color in sorted(label_to_color_map.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import labelme\n",
    "import json\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセット（正解ラベルを表示する側）\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "# 使用する学習済みモデル (プラスチックのみで学習させたモデル)\n",
    "model_path = main_dir / \"model_plastics_only_dataset2.joblib\"\n",
    "# --------------------\n",
    "\n",
    "# 1. データの準備\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ★★★ プラスチックの色のみを定義 ★★★\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\"\n",
    "}\n",
    "\n",
    "# 評価対象のJSONとCSVファイルのパスを定義\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "# ★★★ プラスチックのみのCSVを読み込む ★★★\n",
    "test_csv_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_plastics_only.csv\"\n",
    "\n",
    "# 2. 正解ラベルマスクの作成 (左側の画像)\n",
    "print(\"正解ラベルマスク（プラスチックのみ）を作成しています...\")\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "img_height = json_data['imageHeight']\n",
    "img_width = json_data['imageWidth']\n",
    "\n",
    "# labelme形式で数値マスクを生成\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in json_data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels_in_json, start=1)}\n",
    "numeric_ground_truth_mask, _ = labelme.utils.shapes_to_label((img_height, img_width), json_data['shapes'], label_name_to_value)\n",
    "\n",
    "# 数値マスクをカラーマスクに変換 (★★★ 背景は描画しない ★★★)\n",
    "ground_truth_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "for label_name, label_value in label_name_to_value.items():\n",
    "    # プラスチックラベルのみを色付けする\n",
    "    if label_name in label_to_color_map:\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(label_to_color_map[label_name])) * 255).astype(np.uint8)\n",
    "        ground_truth_mask[numeric_ground_truth_mask == label_value] = color_rgb\n",
    "\n",
    "# 3. 予測結果マスクの作成 (右側の画像)\n",
    "print(\"モデルによる予測とマスク作成を実行しています...\")\n",
    "model = joblib.load(model_path)\n",
    "feature_names_from_model = model.feature_names_in_\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "original_indices = df_test['original_index'].values\n",
    "X_test = df_test[feature_names_from_model]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "predicted_mask_flat = np.zeros((img_height * img_width, 3), dtype=np.uint8)\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    pred_indices_in_y = np.where(y_pred == label_name)[0]\n",
    "    if len(pred_indices_in_y) > 0:\n",
    "        img_indices_to_paint = original_indices[pred_indices_in_y]\n",
    "        color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "        predicted_mask_flat[img_indices_to_paint] = color_rgb\n",
    "\n",
    "predicted_mask = predicted_mask_flat.reshape(img_height, img_width, 3)\n",
    "\n",
    "# 4. 2つの画像を並べてプロット\n",
    "print(\"\\n--- 結果の比較表示 ---\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "# 左: 正解ラベル\n",
    "axes[0].imshow(ground_truth_mask)\n",
    "axes[0].set_title('Ground Truth (Plastics Only)', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 右: モデルの予測結果\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Model Prediction (Plastics Only)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 共通の凡例を作成\n",
    "legend_patches = []\n",
    "for label_name, color in sorted(label_to_color_map.items()):\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "fig.legend(handles=legend_patches, bbox_to_anchor=(1.0, 0.9), loc='upper left', fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403fad1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2089b",
   "metadata": {},
   "source": [
    "# 上位10個の分光画像のみを使用して交差検証\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23abd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "dataset1_dir = main_dir / dataset1_folder_name\n",
    "dataset2_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "n_features = 10  # 上位何個の波長を使うか指定\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# print(Path(data1_output_dir / \"importance_from_dataset.csv\"))\n",
    "\n",
    "def create_filtered_dataset(dataset_dir, n_features):\n",
    "    \"\"\"\n",
    "    指定されたフォルダの重要度ランキングから上位N波長を抽出し、\n",
    "    新しいデータセットを生成する関数\n",
    "    \"\"\"\n",
    "    importance_csv_path = dataset_dir / \"importance_from_dataset.csv\"\n",
    "    pixel_features_all_data_path = dataset_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "    # importance_csv_path = dataset_dir / \"csv\" / \"importance_from_dataset.csv\"\n",
    "    # pixel_features_all_data_path = dataset_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "    # 特徴量重要度ランキングを読み込み\n",
    "    importance_df = pd.read_csv(importance_csv_path)\n",
    "    # 上位 n_features の波長名を取得\n",
    "    top_features = importance_df['feature'].head(n_features).tolist()\n",
    "\n",
    "    # ピクセル単位データを読み込み\n",
    "    df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "    # 必要な列だけ抽出\n",
    "    df_selected = df_pixels[['label_value', 'label_name'] + top_features]\n",
    "    \n",
    "    print(f\"上位{n_features}波長で新しいデータセットを作成しました。: {importance_csv_path}\")\n",
    "    print(f\"選択された波長: {top_features}\")\n",
    "    \n",
    "    return df_selected\n",
    "\n",
    "# データセット1と2を、それぞれの上位10波長でフィルタリング\n",
    "df_selected1 = create_filtered_dataset(dataset1_dir, n_features)\n",
    "df_selected2 = create_filtered_dataset(dataset2_dir, n_features)\n",
    "\n",
    "print(\"\\n--- 全てのデータセットのフィルタリングが完了しました ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"背景データを含め、特徴量とラベルに分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    X = df.drop(columns=['label_value', 'label_name'])\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, model_name):\n",
    "    print(f\"--- {model_name}の学習と評価 ---\")\n",
    "    \n",
    "    # 訓練データとテストデータで波長の列を揃える\n",
    "    common_features = list(set(X_train.columns) & set(X_test.columns))\n",
    "    X_train = X_train[common_features]\n",
    "    X_test = X_test[common_features]\n",
    "\n",
    "    # ランダムフォレストモデルの学習\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model\n",
    "\n",
    "# データセット1と2を学習・評価用に分割\n",
    "try:\n",
    "    X1, y1 = prepare_data(df_selected1)\n",
    "    X2, y2 = prepare_data(df_selected2)\n",
    "except ValueError as e:\n",
    "    print(f\"エラー: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 交差検証1: Dataset1で学習し、Dataset2でテスト\n",
    "model1 = train_and_evaluate(X1, y1, X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: Dataset2で学習し、Dataset1でテスト\n",
    "model2 = train_and_evaluate(X2, y2, X1, y1, \"モデル2 (Dataset2で学習)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "output_dir1 = dataset1_dir / \"results_top10_features\"\n",
    "output_dir1.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(model1, output_dir1 / \"model_trained_on_dataset1.joblib\")\n",
    "print(f\"学習済みモデルは以下のディレクトリに保存されました: {output_dir1}\")\n",
    "\n",
    "\n",
    "output_dir2 = dataset1_dir / \"results_top10_features\"\n",
    "output_dir2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(model2, output_dir2 / \"model_trained_on_dataset2.joblib\")\n",
    "print(f\"学習済みモデルは以下のディレクトリに保存されました: {output_dir2}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355e3ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "\n",
    "# 評価に使用するモデルのパス（例：Dataset2で学習したモデル）\n",
    "model_path = main_dir / test_dataset_folder_name / \"results_top10_features\" / \"model_trained_on_dataset2.joblib\"\n",
    "# ------------------------------\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ラベル名と色を対応付けるための辞書を定義\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\",\n",
    "    \"HDPE\": \"blue\",\n",
    "    \"LDPE\": \"green\",\n",
    "    \"PC\": \"yellow\",\n",
    "    \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\",\n",
    "    \"PP\": \"cyan\",\n",
    "    \"PS\": \"magenta\",\n",
    "    \"PVC\": \"lime\",\n",
    "    \"_background_\": \"gray\"\n",
    "}\n",
    "labels = list(label_to_color_map.keys())\n",
    "\n",
    "# 特徴量抽出に必要な波長リストを取得\n",
    "model = joblib.load(model_path)\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# 評価対象のデータセットを読み込む\n",
    "test_data_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_top10_wavelengths_with_background.csv\"\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 2. モデルによる予測\n",
    "print(\"\\n--- ピクセルごとのラベルを予測 ---\")\n",
    "# 特徴量（X）と正解ラベル（y）に分割\n",
    "X_test = df_test[feature_names]\n",
    "y_true = df_test['label_name']\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. 予測結果の可視化\n",
    "print(\"\\n--- 予測結果の可視化 ---\")\n",
    "\n",
    "# 元画像のパスを取得（可視化用）\n",
    "reference_image_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "original_image = np.asarray(Image.open(reference_image_path))\n",
    "\n",
    "# 元画像の形状（高さと幅）を取得\n",
    "img_height, img_width = original_image.shape\n",
    "\n",
    "# 予測結果からカラーマスクを生成\n",
    "pred_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "true_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "# ラベル名と色をマッピング\n",
    "for i, label_name in enumerate(labels):\n",
    "    color = plt.cm.get_cmap('jet', len(labels))(i)\n",
    "    color_rgb = (np.array(color[:3]) * 255).astype(np.uint8)\n",
    "    \n",
    "    # 予測マスクの作成\n",
    "    pred_indices = np.where(y_pred == label_name)[0]\n",
    "    pred_mask.reshape(-1, 3)[pred_indices] = color_rgb\n",
    "\n",
    "    # 正解マスクの作成\n",
    "    true_indices = np.where(y_true == label_name)[0]\n",
    "    true_mask.reshape(-1, 3)[true_indices] = color_rgb\n",
    "\n",
    "# 図の作成\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "# 1. 元画像の表示\n",
    "axes[0].imshow(original_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. 予測結果の可視化\n",
    "axes[1].imshow(pred_mask)\n",
    "axes[1].set_title('Predicted Labels')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 3. 正解ラベルの可視化\n",
    "axes[2].imshow(true_mask)\n",
    "axes[2].set_title('True Labels')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 凡例の作成\n",
    "legend_patches = []\n",
    "for label_name, color in label_to_color_map.items():\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722406a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b19512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# # --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# # ------------------------------\n",
    "\n",
    "# 作成されたピクセル単位のデータセットを読み込む\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "try:\n",
    "    df_pixels = pd.read_csv(output_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {output_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"データセットを正常に読み込みました。\")\n",
    "\n",
    "\n",
    "# 背景（_background_）データを除外して学習データを作成\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "\n",
    "if df_labeled_only.empty:\n",
    "    print(\"警告: データセットにラベル付けされたプラスチックのピクセルがありません。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量（X）と正解ラベル（y）に分割\n",
    "X = df_labeled_only.drop(columns=['label_value', 'label_name'])\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "# データを学習用とテスト用に分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\n学習データセットのサイズ: {len(X_train)} 件\")\n",
    "print(f\"テストデータセットのサイズ: {len(X_test)} 件\")\n",
    "\n",
    "# ランダムフォレストモデルの学習\n",
    "print(\"\\nランダムフォレストモデルの学習を開始します...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "# 学習済みモデルをjoblib形式で保存\n",
    "model_save_path = main_dir / \"random_forest_model_no_scatter.joblib\"\n",
    "joblib.dump(model, model_save_path)\n",
    "print(f\"\\n学習済みモデルを保存しました: {model_save_path}\")\n",
    "\n",
    "# テストデータで予測を行い、精度を評価\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n--- 精度評価レポート ---')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 特徴量の重要度を計算し、ランキング形式で表示\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 保存先を指定\n",
    "importance_csv_path = main_dir / \"csv\" /\"selected_wavelengths_importance_with_background.csv\"\n",
    "# 親ディレクトリが存在しない場合は作成\n",
    "importance_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "importance_df.to_csv(importance_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n特徴量重要度ランキングを保存しました: {importance_csv_path}\")\n",
    "print(\"\\n上位5件の特徴量:\")\n",
    "print(importance_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4623455",
   "metadata": {},
   "source": [
    "---\n",
    "# 選択した波長の分光画像からの画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a168147",
   "metadata": {},
   "source": [
    "## データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94aa3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e71af38",
   "metadata": {},
   "source": [
    "### 背景あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "n_features = 10  # 上位何個の波長を使うか指定\n",
    "importance_csv_path = main_dir / \"csv\" / \"selected_wavelengths_importance_with_background.csv\"  # 波長選択の結果\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"  #  ラベル域の全データセット\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 1. 特徴量重要度ランキングを読み込み\n",
    "importance_df = pd.read_csv(importance_csv_path)\n",
    "\n",
    "# 上位 n_features の波長名を取得\n",
    "top_features = importance_df['feature'].head(n_features).tolist()\n",
    "print(f\"選択された上位 {n_features} 波長: {top_features}\")\n",
    "\n",
    "# 2. ピクセル単位データを読み込み\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 背景を除外（ラベル名が _background_ の行を削除）\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "\n",
    "# 3. 必要な列だけ抽出\n",
    "df_selected = df_labeled_only[['label_value', 'label_name'] + top_features]\n",
    "\n",
    "# 4. 保存\n",
    "output_csv_path = main_dir / \"csv\" / f\"pixel_features_top{n_features}_wavelengths_with_background.csv\"\n",
    "df_selected.to_csv(output_csv_path, index=False)\n",
    "print(f\"データセットを保存しました: {output_csv_path}\")\n",
    "print(df_selected.head())\n",
    "\n",
    "# ラベルごとのピクセル数を確認\n",
    "print(\"\\nラベルごとのピクセル数:\")\n",
    "print(df_selected['label_name'].value_counts())\n",
    "\n",
    "\n",
    "# --- プレビュー表示 ---\n",
    "print(\"\\n=== データセット情報 ===\")\n",
    "print(f\"全体のサイズ: {df_selected.shape[0]} サンプル, {df_selected.shape[1]} 列\")\n",
    "\n",
    "print(\"\\n=== 先頭5行 ===\")\n",
    "print(df_selected.head())\n",
    "\n",
    "print(\"\\n=== ラベルごとのピクセル数 ===\")\n",
    "print(df_selected['label_name'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac0b2a",
   "metadata": {},
   "source": [
    "### 背景なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "n_features = 10 # 上位何個の波長を使うか指定\n",
    "importance_csv_path = main_dir / \"csv\" / \"selected_wavelengths_importance_no_background.csv\" # 波長選択の結果\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\" #  ラベル域の全データセット\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# 1. 特徴量重要度ランキングを読み込み\n",
    "try:\n",
    "    importance_df = pd.read_csv(importance_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {importance_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 上位 n_features の波長名を取得\n",
    "top_features = importance_df['feature'].head(n_features).tolist()\n",
    "print(f\"選択された上位 {n_features} 波長: {top_features}\")\n",
    "\n",
    "# 2. ピクセル単位データを読み込み\n",
    "try:\n",
    "    df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {pixel_features_all_data_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 背景データを含めるため、背景除外処理をスキップ\n",
    "df_labeled_only = df_pixels.copy()\n",
    "\n",
    "# 3. 必要な列だけ抽出\n",
    "df_selected = df_labeled_only[['label_value', 'label_name'] + top_features]\n",
    "\n",
    "# 4. 保存\n",
    "output_csv_path = main_dir / \"csv\" / f\"pixel_features_top{n_features}_wavelengths_no_background.csv\"\n",
    "output_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_selected.to_csv(output_csv_path, index=False)\n",
    "print(f\"データセットを保存しました: {output_csv_path}\")\n",
    "\n",
    "\n",
    "# --- プレビュー表示 ---\n",
    "print(\"\\n=== データセット情報 ===\")\n",
    "print(f\"全体のサイズ: {df_selected.shape[0]} サンプル, {df_selected.shape[1]} 列\")\n",
    "\n",
    "print(\"\\n=== 先頭5行 ===\") \n",
    "print(df_selected.head())\n",
    "\n",
    "print(\"\\n=== ラベルごとのピクセル数 ===\")\n",
    "print(df_selected['label_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48f3b5",
   "metadata": {},
   "source": [
    "## RandomForestで学習・評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 説明変数と目的変数\n",
    "X = df_selected.drop(columns=['label_value', 'label_name'])\n",
    "y = df_selected['label_name']\n",
    "\n",
    "# 学習データとテストデータ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# RandomForest（クラス不均衡対応）\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # 少数クラスを重視\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 精度評価\n",
    "y_pred = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a04593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "# reference_file_stem = \"MPs_20250905_2_Ex-1_Em-1_ET300_step1\"   # 元画像（JSON・tiff）の基準\n",
    "visualize_file_stem = f\"{folder_name}_Ex260_Em280_ET10000_step1\"  # 可視化対象画像\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\"\n",
    "\n",
    "# top_features = [\n",
    "#     'Ex360_Em380', 'Ex320_Em360', 'Ex380_Em420', 'Ex260_Em360', 'Ex300_Em380',\n",
    "#     'Ex360_Em460', 'Ex300_Em360', 'Ex280_Em380', 'Ex340_Em380', 'Ex340_Em400'\n",
    "# ]\n",
    "# --------------------\n",
    "\n",
    "# 1. データ読み込み\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 2. 背景も含むデータでモデル学習\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']  # 学習はラベルのみ\n",
    "\n",
    "X = df_labeled_only[top_features]\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# 3. JSONからラベル情報を取得\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i+1 for i, label in enumerate(labels_in_json)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "\n",
    "# 4. 可視化対象画像のサイズ\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\")\n",
    "original_img = np.asarray(Image.open(image_path))\n",
    "height, width = original_img.shape\n",
    "\n",
    "# 5. 全ピクセル（背景も含む）に対して予測\n",
    "X_all = df_pixels[top_features]  # 学習時と同じ列順・列名\n",
    "y_pred_all = model.predict(X_all)\n",
    "\n",
    "# 数値ラベルに変換（背景は0のまま）\n",
    "predicted_mask_flat = pd.Series(y_pred_all).map(lambda x: label_name_to_value.get(x, 0)).values\n",
    "predicted_mask = predicted_mask_flat.reshape(height, width)\n",
    "\n",
    "# 背景を透明にするマスク\n",
    "mask_alpha = np.where(predicted_mask == 0, 0.0, 0.6)\n",
    "\n",
    "# 6. カラーマップ設定\n",
    "colors = ['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF',\n",
    "          '#00FFFF', '#FFA500', '#800080', '#A52A2A']  # 適宜追加\n",
    "cmap = ListedColormap(colors[:len(value_to_label_name)])\n",
    "\n",
    "legend_patches = []\n",
    "for label_value, label_name in value_to_label_name.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    color_rgb = np.array([int(colors[label_value][i:i+2],16)/255. for i in (1,3,5)])\n",
    "    legend_patches.append(mpatches.Patch(color=color_rgb, label=label_name))\n",
    "\n",
    "# 7. 可視化\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.imshow(np.asarray(Image.open(main_dir / (visualize_file_stem + \".tiff\"))), cmap='gray')\n",
    "ax.imshow(predicted_mask, cmap=cmap, alpha=mask_alpha, vmin=0, vmax=len(value_to_label_name)-1)\n",
    "ax.set_title(f'Predicted Classification (Selected Wavelengths)')\n",
    "ax.axis('off')\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05,1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# # --- ユーザー設定 ---\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "# reference_file_stem = \"MPs_20250905_2_Ex-1_Em-1_ET300_step1\"   # 元画像（JSON・tiff）の基準\n",
    "# visualize_file_stem = \"MPs_20250905_2_Ex260_Em280_ET10000_step1\"  # 可視化対象画像\n",
    "# top_features = [\n",
    "#     'Ex360_Em380', 'Ex320_Em360', 'Ex380_Em420', 'Ex260_Em360', 'Ex300_Em380',\n",
    "#     'Ex360_Em460', 'Ex300_Em360', 'Ex280_Em380', 'Ex340_Em380', 'Ex340_Em400'\n",
    "# ]\n",
    "# --------------------\n",
    "\n",
    "# 1. データ読み込み\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\"\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 2. 学習用データ（背景は除外）\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "X = df_labeled_only[top_features]\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 精度評価\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# 3. JSONからラベル情報取得\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i+1 for i, label in enumerate(labels_in_json)}  # プラスチックのみ\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "\n",
    "# 4. 元画像サイズ取得\n",
    "image_path = main_dir / (visualize_file_stem + \".tiff\")\n",
    "original_img = np.asarray(Image.open(image_path))\n",
    "height, width = original_img.shape\n",
    "\n",
    "# 5. 背景は除外して予測\n",
    "df_for_pred = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "X_all = df_for_pred[top_features]\n",
    "y_pred_all = model.predict(X_all)\n",
    "\n",
    "# 6. 予測結果を元画像サイズに埋め込む\n",
    "predicted_mask = np.zeros((height, width), dtype=int)\n",
    "predicted_flat = pd.Series(y_pred_all).map(lambda x: label_name_to_value.get(x, 0)).values\n",
    "predicted_mask_flat_index = np.flatnonzero(df_pixels['label_name'] != '_background_')\n",
    "predicted_mask.ravel()[predicted_mask_flat_index] = predicted_flat\n",
    "\n",
    "# 7. カラーマップ設定\n",
    "colors = ['#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF',\n",
    "          '#00FFFF', '#FFA500', '#800080', '#A52A2A', '#FFC0CB']  # 適宜追加\n",
    "cmap = ListedColormap(colors[:len(value_to_label_name)])\n",
    "\n",
    "legend_patches = []\n",
    "for label_value, label_name in value_to_label_name.items():\n",
    "    color_rgb = np.array([int(colors[label_value-1][i:i+2],16)/255. for i in (1,3,5)])\n",
    "    legend_patches.append(mpatches.Patch(color=color_rgb, label=label_name))\n",
    "\n",
    "# 8. 可視化\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.imshow(original_img, cmap='gray')\n",
    "# 背景以外のみマスクを重ねる\n",
    "mask_alpha = np.where(predicted_mask==0, 0, 0.6)\n",
    "ax.imshow(predicted_mask, cmap=cmap, alpha=mask_alpha, vmin=0, vmax=len(value_to_label_name))\n",
    "ax.set_title(f'Predicted Classification (Selected Wavelengths)')\n",
    "ax.axis('off')\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05,1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc645d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
