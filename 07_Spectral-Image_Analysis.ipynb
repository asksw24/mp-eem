{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f8c782",
   "metadata": {},
   "source": [
    "# labelmeの結果可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2430386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "json_path = main_dir / (file_stem + \".json\")\n",
    "image_path = main_dir / (file_stem + \".tiff\")\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ラベル名と数値の対応辞書を作成\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# マスクを生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 各ラベルごとに画素値を抽出し、統計量を算出\n",
    "results = {}\n",
    "for label_name, value in label_name_to_value.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    \n",
    "    # ラベルに対応するマスクを作成\n",
    "    label_mask = (lbl == value)\n",
    "    pixel_values = img[label_mask]\n",
    "    \n",
    "    if len(pixel_values) > 0:\n",
    "        results[label_name] = {\n",
    "            'pixel_count': len(pixel_values),\n",
    "            'mean': np.mean(pixel_values),\n",
    "            'std_dev': np.std(pixel_values),\n",
    "            'max_value': np.max(pixel_values),\n",
    "            'min_value': np.min(pixel_values)\n",
    "        }\n",
    "    else:\n",
    "        results[label_name] = \"No pixels found for this label.\"\n",
    "\n",
    "# 結果を整形して表示\n",
    "for label, stats in results.items():\n",
    "    print(f'--- ラベル: {label} ---')\n",
    "    if isinstance(stats, str):\n",
    "        print(stats)\n",
    "    else:\n",
    "        print(f'画素数: {stats[\"pixel_count\"]}')\n",
    "        print(f'平均値: {stats[\"mean\"]}')\n",
    "        print(f'標準偏差: {stats[\"std_dev\"]}')\n",
    "        print(f'最大値: {stats[\"max_value\"]}')\n",
    "        print(f'最小値: {stats[\"min_value\"]}')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68da0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# # プロジェクトのメインディレクトリ\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "\n",
    "# # 画像とJSONファイルのパス\n",
    "# json_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.json\"\n",
    "# image_path = main_dir / \"MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(image_path)\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# label_name_to_value を作成\n",
    "label_name_to_value = {\"_background_\": 0}  # 背景は0\n",
    "for shape in data[\"shapes\"]:\n",
    "    label_name = shape[\"label\"]\n",
    "    if label_name not in label_name_to_value:\n",
    "        label_name_to_value[label_name] = len(label_name_to_value)\n",
    "\n",
    "# マスクを生成（新しいAPI）\n",
    "lbl, _ = labelme.utils.shapes_to_label(\n",
    "    img_shape=img.shape,\n",
    "    shapes=data[\"shapes\"],\n",
    "    label_name_to_value=label_name_to_value\n",
    ")\n",
    "\n",
    "# マスクを可視化\n",
    "mask = (lbl > 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Mask Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# 画像ファイルのパスを指定してください\n",
    "# 基準画像のパス\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2/MPs_20250905_2_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# 比較したい分光画像のパス（例）\n",
    "spectral_image_path = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}/{folder_name}_Ex360_Em480_ET10000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 画像を重ねて表示\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.imshow(ref_img, cmap='gray', alpha=1.0) # 基準画像を背景に表示\n",
    "ax.imshow(spec_img, cmap='jet', alpha=0.5) # 分光画像を半透明で重ねて表示\n",
    "ax.set_title('Image Alignment Check')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "# # 画像ファイルのパスを指定\n",
    "# reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# spectral_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex260_Em280_ET20000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 位相相関法でずれを計算\n",
    "# output: ずれの量 (y, x), 誤差, 位相相関のピーク\n",
    "shift, error, phase = phase_cross_correlation(ref_img, spec_img)\n",
    "\n",
    "# ずれの量（ピクセル単位）を表示\n",
    "print(f'基準画像に対する分光画像のずれ:')\n",
    "print(f'  y方向 (縦): {shift[0]:.2f} ピクセル')\n",
    "print(f'  x方向 (横): {shift[1]:.2f} ピクセル')\n",
    "print(f'  誤差: {error:.4f}')\n",
    "\n",
    "# ずれが非常に小さい（0に近い）ことを確認し、問題ないと判断\n",
    "if np.sqrt(shift[0]**2 + shift[1]**2) < 1.0:\n",
    "    print(\"\\n画像間のずれは1ピクセル未満です。位置合わせは正確であると考えられます。\")\n",
    "else:\n",
    "    print(\"\\n画像間にずれがある可能性があります。再撮影または画像補正を検討してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c795e5d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f122874",
   "metadata": {},
   "source": [
    "# ピクセル単位での分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8fa9b",
   "metadata": {},
   "source": [
    "## ラベリング結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # 凡例用\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\") # ラベリングに使用した元の画像パス\n",
    "\n",
    "print(f\"Loading JSON file: {json_path}\")\n",
    "print(f\"Loading original image: {image_path}\")\n",
    "\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: JSONファイル '{json_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    original_img = np.asarray(Image.open(image_path))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: 元画像ファイル '{image_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# ラベル名と数値の対応付け\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0 # 背景には0を割り当てる\n",
    "\n",
    "# ラベルマップ（数値）を生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(original_img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 可視化用のカラーマップを生成\n",
    "# ラベル数に応じて色を割り当てる\n",
    "unique_labels = np.unique(lbl)\n",
    "colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "colored_mask = np.zeros((*lbl.shape, 3), dtype=np.uint8)\n",
    "legend_patches = []\n",
    "label_value_to_color = {}\n",
    "\n",
    "for i, label_value in enumerate(unique_labels):\n",
    "    if label_value == 0:\n",
    "        color = np.array([0, 0, 0])\n",
    "        label_name = 'background'\n",
    "    else:\n",
    "        # 修正: np.array()で一度配列に変換してからastype()を適用\n",
    "        color = (np.array(colors(i)[:3]) * 255).astype(np.uint8)\n",
    "        label_name = list(label_name_to_value.keys())[list(label_name_to_value.values()).index(label_value)]\n",
    "        legend_patches.append(mpatches.Patch(color=color/255., label=label_name))\n",
    "    \n",
    "    colored_mask[lbl == label_value] = color\n",
    "\n",
    "# 元画像とカラーマスクを並べて表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(colored_mask)\n",
    "axes[1].set_title('Labeled Mask (Pixel-wise Labels)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化されたラベリング結果を確認しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcf5a7",
   "metadata": {},
   "source": [
    "## データセットの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b0bd4",
   "metadata": {},
   "source": [
    "### background情報あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83470f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# # --- ユーザーが設定する項目 ---\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "# reference_file_stem = \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "# # ------------------------------\n",
    "\n",
    "# 1. 基準JSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: JSONファイルが見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*.tiff\")) # フィルタなし画像もglobで取得\n",
    "\n",
    "if not image_files:\n",
    "    print(\"Error: 指定されたパターンに一致する分光画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "processed_files_count = 0\n",
    "image_size = None\n",
    "\n",
    "for image_path in image_files:\n",
    "    # フィルタなしの画像を除外\n",
    "    if '-1_Em-1' in image_path.stem:\n",
    "        print(f\"Skipping filter-less image: {image_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    match = wavelength_pattern.search(image_path.name)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    ex_wavelength = int(match.group(1))\n",
    "    em_wavelength = int(match.group(2))\n",
    "\n",
    "    # 1次散乱光のデータを除外\n",
    "    if ex_wavelength == em_wavelength:\n",
    "        print(f\"Skipping primary scattered light: {image_path.name}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        if image_size is None:\n",
    "            image_size = img.shape\n",
    "            print(f\"画像サイズを検出しました: {image_size}\")\n",
    "        \n",
    "        if img.shape != image_size:\n",
    "            print(f\"Warning: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "        \n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "        processed_files_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to process {image_path.name}. Reason: {e}\")\n",
    "        continue\n",
    "\n",
    "if processed_files_count > 0:\n",
    "    # 3. 正解ラベルの列をデータフレームに追加\n",
    "    pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "    \n",
    "    pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "    pixel_features_df['label_value'] = pixel_labels_flat\n",
    "    pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map({v: k for k, v in label_name_to_value.items()})\n",
    "\n",
    "\n",
    "    before_rows = len(pixel_features_df)\n",
    "    pixel_features_df = pixel_features_df[pixel_features_df['label_name'] != 'other'].reset_index(drop=True)\n",
    "    after_rows = len(pixel_features_df)\n",
    "    print(f\"otherラベルの行を除外しました: {before_rows - after_rows} 行削除, 残り {after_rows} 行\")\n",
    "\n",
    "    # データセットをCSVとして保存\n",
    "    output_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "    # 親ディレクトリが存在しない場合は作成\n",
    "    output_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f'\\nピクセル単位のデータセットが作成されました: {output_csv_path}')\n",
    "    print('\\nデータセットのプレビュー:')\n",
    "    print(pixel_features_df.head())\n",
    "else:\n",
    "    print(\"Warning: No data was successfully processed. Check your files and paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254660df",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899f79",
   "metadata": {},
   "source": [
    "# t-SNE データセットの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc54f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250911\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# ★★★ 変更点1: プロット用に'_background_'を'background'に名称変更 ★★★\n",
    "df_tsne['label'] = df_tsne['label'].replace({'_background_': 'background'})\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# --- ユーザー設定 (ここだけ編集してください) ---\n",
    "# ★ 解析したいデータフォルダ名を設定\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "\n",
    "# 1. パスの設定とCSVファイルの読み込み\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "input_csv_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "print(f\"データファイルを読み込みます: {input_csv_path}\")\n",
    "df = pd.read_csv(input_csv_path)\n",
    "label_column = 'label_name'\n",
    "if label_column not in df.columns:\n",
    "    print(f\"\\n--- エラー ---\")\n",
    "    print(f\"読み込んだCSVファイルに '{label_column}' 列が存在しません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nデータ読み込み成功。\")\n",
    "\n",
    "# 3. 各クラスから均等にデータをサンプリング\n",
    "n_samples_per_class = 2000\n",
    "print(f\"\\n各クラスから最大 {n_samples_per_class} 点をサンプリングします...\")\n",
    "\n",
    "sampled_dfs = []\n",
    "for label in df[label_column].unique():\n",
    "    group = df[df[label_column] == label]\n",
    "    sample = group.sample(n=min(len(group), n_samples_per_class), random_state=42)\n",
    "    sampled_dfs.append(sample)\n",
    "sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
    "print(f\"サンプリング後のデータセットサイズ: {len(sampled_df)} ピクセル\")\n",
    "\n",
    "# 4. データの前処理\n",
    "labels = sampled_df[label_column]\n",
    "columns_to_drop = [label_column]\n",
    "if 'label_value' in sampled_df.columns:\n",
    "    columns_to_drop.append('label_value')\n",
    "features = sampled_df.drop(columns=columns_to_drop)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 5. t-SNEの計算\n",
    "print(\"\\nt-SNEの計算を開始します...\")\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(features_scaled)\n",
    "end_time = time.time()\n",
    "print(f\"t-SNE計算完了。実行時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# 6. 結果の可視化\n",
    "print(\"\\n結果をプロットします...\")\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['tsne-2d-one', 'tsne-2d-two'])\n",
    "df_tsne['label'] = labels\n",
    "\n",
    "# ★★★ 変更点1: プロット用に'_background_'を'background'に名称変更 ★★★\n",
    "df_tsne['label'] = df_tsne['label'].replace({'_background_': 'background'})\n",
    "\n",
    "# 6-1. ユニークなラベル名を取得し、ソート\n",
    "unique_labels = sorted(df_tsne['label'].unique())\n",
    "\n",
    "# 6-2. カラーパレットを準備\n",
    "plastic_colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "# 6-3. ラベル名と色を対応付ける辞書を作成\n",
    "color_map = {}\n",
    "plastic_color_index = 0\n",
    "for label in unique_labels:\n",
    "    # ★★★ 変更点2: チェックする名前を'background'に変更 ★★★\n",
    "    if label == 'background':\n",
    "        color_map[label] = 'lightgray'\n",
    "    else:\n",
    "        color_map[label] = plastic_colors(plastic_color_index)\n",
    "        plastic_color_index += 1\n",
    "\n",
    "# 6-4. プロットの実行\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"label\",\n",
    "    hue_order=unique_labels,\n",
    "    palette=color_map,\n",
    "    data=df_tsne,\n",
    "    legend=\"full\",\n",
    "    # ★★★ ここを変更 ★★★\n",
    "    alpha=1.0,  # 点を不透明に変更 (0.7 -> 1.0)\n",
    "    s=50        # 点のサイズを大きく変更 (20 -> 50)\n",
    ")\n",
    "\n",
    "plt.title(f't-SNE Plot of Spectral Data (Sampled from {folder_name})', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4e567",
   "metadata": {},
   "source": [
    "----\n",
    "# 2つのデータセットを用いた交差検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# ------------------------------\n",
    "\n",
    "# データセットのパスを定義\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "# データセット1を読み込む\n",
    "try:\n",
    "    df1 = pd.read_csv(dataset1_csv_path)\n",
    "    print(f\"データセット1を正常に読み込みました: {dataset1_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset1_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# データセット2を読み込む\n",
    "try:\n",
    "    df2 = pd.read_csv(dataset2_csv_path)\n",
    "    print(f\"データセット2を正常に読み込みました: {dataset2_csv_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {dataset2_csv_path} が見つかりません。\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "# import time\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"背景データを含め、特徴量とラベルに分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    X = df.drop(columns=['label_value', 'label_name'])\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_save(X_train, y_train, model_save_path):\n",
    "    print(\"\\n--- ランダムフォレストモデルの学習を開始 ---\")\n",
    "    \n",
    "    # モデルの学習\n",
    "    # 修正点: class_weight='balanced' を追加\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # モデルの保存\n",
    "    joblib.dump(model, model_save_path)\n",
    "\n",
    "    print(f\"学習済みモデルを保存しました: {model_save_path}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# データセットの読み込み (前のセクションで定義されたパスを使用)\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "df1 = pd.read_csv(dataset1_csv_path)\n",
    "df2 = pd.read_csv(dataset2_csv_path)\n",
    "\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# モデル1を学習・保存\n",
    "train_and_save(X1, y1, main_dir / \"model_trained_on_dataset1.joblib\")\n",
    "print(f\"データセット1（{dataset1_folder_name}）学習完了\")\n",
    "\n",
    "\n",
    "# モデル2を学習・保存\n",
    "train_and_save(X2, y2, main_dir / \"model_trained_on_dataset2.joblib\")\n",
    "print(f\"データセット2（{dataset2_folder_name}）学習完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c899c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"背景データを含め、特徴量とラベルに分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    X = df.drop(columns=['label_value', 'label_name'])\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model_path, X_test, y_test, model_name):\n",
    "    print(f\"\\n--- {model_name}の評価を開始 ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # モデルの読み込み\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"評価が完了しました。実行時間: {elapsed_time:.2f}秒\")\n",
    "    \n",
    "    # 特徴量重要度を計算\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X_test.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df, model # 修正点: importance_df と model を返すように変更\n",
    "\n",
    "# データセットの読み込み\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset2_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "df1 = pd.read_csv(dataset1_csv_path)\n",
    "df2 = pd.read_csv(dataset2_csv_path)\n",
    "\n",
    "X1, y1 = prepare_data(df1)\n",
    "X2, y2 = prepare_data(df2)\n",
    "\n",
    "# 交差検証1: モデル1を評価\n",
    "# evaluate_model関数の返り値を model1 に格納\n",
    "importance1, model1 = evaluate_model(main_dir / \"model_trained_on_dataset1.joblib\", X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: モデル2を評価\n",
    "# evaluate_model関数の返り値を model2 に格納\n",
    "importance2, model2 = evaluate_model(main_dir / \"model_trained_on_dataset2.joblib\", X1, y1, \"モデル2 (Dataset2で学習)\")\n",
    "\n",
    "\n",
    "# --- 結果を保存するコードブロック ---\n",
    "# この部分で model1 と model2 変数が使用可能になっている\n",
    "data1_output_dir = main_dir / dataset1_folder_name\n",
    "data2_output_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 精度レポートをテキストファイルとして保存\n",
    "# 交差検証1の結果\n",
    "with open(data1_output_dir / \"classification_report_model1.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# 交差検証2の結果\n",
    "with open(data2_output_dir / \"classification_report_model2.txt\", \"w\") as f:\n",
    "    f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# 特徴量重要度をCSVファイルとして保存\n",
    "importance1.to_csv(data1_output_dir / \"csv\" / \"importance_from_dataset.csv\", index=False)\n",
    "importance2.to_csv(data2_output_dir / \"csv\" / \"importance_from_dataset.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "print(f\"精度レポートと重要度ランキングは保存されました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99889303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 結果を保存するコードブロック ---\n",
    "# output_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/results\")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # 精度レポートをテキストファイルとして保存\n",
    "# # 交差検証1の結果\n",
    "# with open(output_dir / \"classification_report_model1.txt\", \"w\") as f:\n",
    "#     f.write(classification_report(y2, model1.predict(X2)))\n",
    "\n",
    "# # 交差検証2の結果\n",
    "# with open(output_dir / \"classification_report_model2.txt\", \"w\") as f:\n",
    "#     f.write(classification_report(y1, model2.predict(X1)))\n",
    "\n",
    "# # 特徴量重要度をCSVファイルとして保存\n",
    "# importance1.to_csv(output_dir / \"importance_from_dataset1.csv\", index=False)\n",
    "# importance2.to_csv(output_dir / \"importance_from_dataset2.csv\", index=False)\n",
    "\n",
    "# print(\"\\n--- 全ての処理が完了しました ---\")\n",
    "# print(f\"精度レポートと重要度ランキングは以下のディレクトリに保存されました: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41020d3",
   "metadata": {},
   "source": [
    "## 分類結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d76904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import json\n",
    "import labelme\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセットのフォルダ名（テストデータとしてMPs_20250905_2を使用）\n",
    "test_dataset_folder_name = \"MPs_20250905_2\" \n",
    "# 学習済みモデルのパス（Dataset1で学習し、resultsフォルダに保存したもの）\n",
    "model_path = main_dir / \"model_trained_on_dataset1.joblib\"\n",
    "# ------------------------------\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ラベル名と色を対応付けるための辞書を定義\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"_background_\": \"gray\"\n",
    "}\n",
    "\n",
    "# モデルを読み込み、学習に使用された全波長を取得\n",
    "model = joblib.load(model_path)\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# 評価対象の全波長データセットを読み込む\n",
    "test_data_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path, index_col=0) # 修正点：index_col=0 を追加\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量（X_test）を準備\n",
    "X_test = df_test[feature_names]\n",
    "\n",
    "# 元画像のパスを取得（可視化用）\n",
    "reference_image_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "original_image = np.asarray(Image.open(reference_image_path))\n",
    "json_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.json\"\n",
    "\n",
    "# 2. モデルによるピクセルごとの分類\n",
    "print(\"\\n--- ピクセルごとのラベルを予測 ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. JSONファイルから完全なマスクを生成し、可視化\n",
    "print(\"\\n--- 予測結果の可視化 ---\")\n",
    "\n",
    "# 元画像の形状（高さと幅）を取得\n",
    "img_height, img_width = original_image.shape\n",
    "\n",
    "# 予測結果を画像全体にマッピング\n",
    "y_pred_full = np.array([''] * (img_height * img_width), dtype=object) # 空の文字列で初期化\n",
    "y_pred_full[df_test.index] = y_pred\n",
    "\n",
    "# JSONからotherラベルを特定\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "label_name_to_value = {\"_background_\": 0}\n",
    "for shape in json_data[\"shapes\"]:\n",
    "    label_name = shape[\"label\"]\n",
    "    if label_name not in label_name_to_value:\n",
    "        label_name_to_value[label_name] = len(label_name_to_value)\n",
    "\n",
    "full_mask, _ = labelme.utils.shapes_to_label(\n",
    "    original_image.shape, json_data[\"shapes\"], label_name_to_value\n",
    ")\n",
    "\n",
    "# カラーマスクの生成\n",
    "predicted_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    indices = np.where(y_pred_full == label_name)[0]\n",
    "    color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "    predicted_mask.reshape(-1, 3)[indices] = color_rgb\n",
    "\n",
    "# otherラベルの領域を黒く塗りつぶす\n",
    "other_indices = np.where(full_mask == label_name_to_value.get('other', -1))[0]\n",
    "predicted_mask.reshape(-1, 3)[other_indices] = [0, 0, 0]\n",
    "\n",
    "# 図の作成と表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Predicted Labels (from Dataset1 model)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 凡例の作成\n",
    "legend_patches = []\n",
    "for label_name, color in label_to_color_map.items():\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "# 評価に使用するデータセットのフォルダ名（テストデータとしてMPs_20250911を使用）\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "# 学習済みモデルのパス（Dataset2で学習し、resultsフォルダに保存したもの）\n",
    "model_path = main_dir / \"model_trained_on_dataset2.joblib\"\n",
    "# ------------------------------\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ラベル名と色を対応付けるための辞書を定義\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\", \"HDPE\": \"blue\", \"LDPE\": \"green\", \"PC\": \"yellow\", \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\", \"PP\": \"cyan\", \"PS\": \"magenta\", \"PVC\": \"lime\", \"_background_\": \"gray\"\n",
    "}\n",
    "labels = list(label_to_color_map.keys())\n",
    "\n",
    "# モデルを読み込み、学習に使用された全波長を取得\n",
    "model = joblib.load(model_path)\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# 評価対象の全波長データセットを読み込む\n",
    "test_data_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量（X_test）を準備\n",
    "X_test = df_test[feature_names]\n",
    "\n",
    "# 元画像のパスを取得（可視化用）\n",
    "reference_image_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "original_image = np.asarray(Image.open(reference_image_path))\n",
    "\n",
    "# 2. モデルによるピクセルごとの分類\n",
    "print(\"\\n--- ピクセルごとのラベルを予測 ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. 予測結果をカラーマスクとして可視化\n",
    "print(\"\\n--- 予測結果の可視化 ---\")\n",
    "\n",
    "# 元画像の形状（高さと幅）を取得\n",
    "img_height, img_width = original_image.shape\n",
    "\n",
    "# 予測結果からカラーマスクを生成\n",
    "predicted_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "# ラベル名と色をマッピングし、マスクに適用\n",
    "for label_name, color_name in label_to_color_map.items():\n",
    "    indices = np.where(y_pred == label_name)[0]\n",
    "    color_rgb = (np.array(plt.cm.colors.to_rgb(color_name)) * 255).astype(np.uint8)\n",
    "    \n",
    "    # 予測マスクの作成\n",
    "    predicted_mask.reshape(-1, 3)[indices] = color_rgb\n",
    "\n",
    "# 図の作成と表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# 1. 元画像の表示\n",
    "axes[0].imshow(original_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. 予測結果の可視化\n",
    "axes[1].imshow(predicted_mask)\n",
    "axes[1].set_title('Predicted Labels (from Dataset2 model)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 凡例の作成\n",
    "legend_patches = []\n",
    "for label_name, color in label_to_color_map.items():\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化が完了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403fad1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2089b",
   "metadata": {},
   "source": [
    "# 上位10個の分光画像のみを使用して交差検証\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23abd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "dataset1_dir = main_dir / dataset1_folder_name\n",
    "dataset2_dir = main_dir / dataset2_folder_name\n",
    "\n",
    "n_features = 10  # 上位何個の波長を使うか指定\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# print(Path(data1_output_dir / \"importance_from_dataset.csv\"))\n",
    "\n",
    "def create_filtered_dataset(dataset_dir, n_features):\n",
    "    \"\"\"\n",
    "    指定されたフォルダの重要度ランキングから上位N波長を抽出し、\n",
    "    新しいデータセットを生成する関数\n",
    "    \"\"\"\n",
    "    importance_csv_path = dataset_dir / \"importance_from_dataset.csv\"\n",
    "    pixel_features_all_data_path = dataset_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "    # importance_csv_path = dataset_dir / \"csv\" / \"importance_from_dataset.csv\"\n",
    "    # pixel_features_all_data_path = dataset_dir / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "    # 特徴量重要度ランキングを読み込み\n",
    "    importance_df = pd.read_csv(importance_csv_path)\n",
    "    # 上位 n_features の波長名を取得\n",
    "    top_features = importance_df['feature'].head(n_features).tolist()\n",
    "\n",
    "    # ピクセル単位データを読み込み\n",
    "    df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "    # 必要な列だけ抽出\n",
    "    df_selected = df_pixels[['label_value', 'label_name'] + top_features]\n",
    "    \n",
    "    print(f\"上位{n_features}波長で新しいデータセットを作成しました。: {importance_csv_path}\")\n",
    "    print(f\"選択された波長: {top_features}\")\n",
    "    \n",
    "    return df_selected\n",
    "\n",
    "# データセット1と2を、それぞれの上位10波長でフィルタリング\n",
    "df_selected1 = create_filtered_dataset(dataset1_dir, n_features)\n",
    "df_selected2 = create_filtered_dataset(dataset2_dir, n_features)\n",
    "\n",
    "print(\"\\n--- 全てのデータセットのフィルタリングが完了しました ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"背景データを含め、特徴量とラベルに分割するヘルパー関数\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"データセットにピクセルデータがありません。\")\n",
    "    X = df.drop(columns=['label_value', 'label_name'])\n",
    "    y = df['label_name']\n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, model_name):\n",
    "    print(f\"--- {model_name}の学習と評価 ---\")\n",
    "    \n",
    "    # 訓練データとテストデータで波長の列を揃える\n",
    "    common_features = list(set(X_train.columns) & set(X_test.columns))\n",
    "    X_train = X_train[common_features]\n",
    "    X_test = X_test[common_features]\n",
    "\n",
    "    # ランダムフォレストモデルの学習\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 評価\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('--- 精度評価レポート ---')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model\n",
    "\n",
    "# データセット1と2を学習・評価用に分割\n",
    "try:\n",
    "    X1, y1 = prepare_data(df_selected1)\n",
    "    X2, y2 = prepare_data(df_selected2)\n",
    "except ValueError as e:\n",
    "    print(f\"エラー: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 交差検証1: Dataset1で学習し、Dataset2でテスト\n",
    "model1 = train_and_evaluate(X1, y1, X2, y2, \"モデル1 (Dataset1で学習)\")\n",
    "\n",
    "# 交差検証2: Dataset2で学習し、Dataset1でテスト\n",
    "model2 = train_and_evaluate(X2, y2, X1, y1, \"モデル2 (Dataset2で学習)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "output_dir1 = dataset1_dir / \"results_top10_features\"\n",
    "output_dir1.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(model1, output_dir1 / \"model_trained_on_dataset1.joblib\")\n",
    "print(f\"学習済みモデルは以下のディレクトリに保存されました: {output_dir1}\")\n",
    "\n",
    "\n",
    "output_dir2 = dataset1_dir / \"results_top10_features\"\n",
    "output_dir2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(model2, output_dir2 / \"model_trained_on_dataset2.joblib\")\n",
    "print(f\"学習済みモデルは以下のディレクトリに保存されました: {output_dir2}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 全ての処理が完了しました ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355e3ad",
   "metadata": {},
   "source": [
    "---\n",
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "test_dataset_folder_name = \"MPs_20250911\" \n",
    "\n",
    "# 評価に使用するモデルのパス（例：Dataset2で学習したモデル）\n",
    "model_path = main_dir / test_dataset_folder_name / \"results_top10_features\" / \"model_trained_on_dataset2.joblib\"\n",
    "# ------------------------------\n",
    "\n",
    "# 1. データの準備とモデルの読み込み\n",
    "print(\"--- データの準備 ---\")\n",
    "\n",
    "# ラベル名と色を対応付けるための辞書を定義\n",
    "label_to_color_map = {\n",
    "    \"ABS\": \"red\",\n",
    "    \"HDPE\": \"blue\",\n",
    "    \"LDPE\": \"green\",\n",
    "    \"PC\": \"yellow\",\n",
    "    \"PET\": \"purple\",\n",
    "    \"PMMA\": \"orange\",\n",
    "    \"PP\": \"cyan\",\n",
    "    \"PS\": \"magenta\",\n",
    "    \"PVC\": \"lime\",\n",
    "    \"_background_\": \"gray\"\n",
    "}\n",
    "labels = list(label_to_color_map.keys())\n",
    "\n",
    "# 特徴量抽出に必要な波長リストを取得\n",
    "model = joblib.load(model_path)\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# 評価対象のデータセットを読み込む\n",
    "test_data_path = main_dir / test_dataset_folder_name / \"csv\" / \"pixel_features_top10_wavelengths_with_background.csv\"\n",
    "try:\n",
    "    df_test = pd.read_csv(test_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {test_data_path} が見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 2. モデルによる予測\n",
    "print(\"\\n--- ピクセルごとのラベルを予測 ---\")\n",
    "# 特徴量（X）と正解ラベル（y）に分割\n",
    "X_test = df_test[feature_names]\n",
    "y_true = df_test['label_name']\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"予測が完了しました。\")\n",
    "\n",
    "# 3. 予測結果の可視化\n",
    "print(\"\\n--- 予測結果の可視化 ---\")\n",
    "\n",
    "# 元画像のパスを取得（可視化用）\n",
    "reference_image_path = main_dir / test_dataset_folder_name / f\"{test_dataset_folder_name}_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "original_image = np.asarray(Image.open(reference_image_path))\n",
    "\n",
    "# 元画像の形状（高さと幅）を取得\n",
    "img_height, img_width = original_image.shape\n",
    "\n",
    "# 予測結果からカラーマスクを生成\n",
    "pred_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "true_mask = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "\n",
    "# ラベル名と色をマッピング\n",
    "for i, label_name in enumerate(labels):\n",
    "    color = plt.cm.get_cmap('jet', len(labels))(i)\n",
    "    color_rgb = (np.array(color[:3]) * 255).astype(np.uint8)\n",
    "    \n",
    "    # 予測マスクの作成\n",
    "    pred_indices = np.where(y_pred == label_name)[0]\n",
    "    pred_mask.reshape(-1, 3)[pred_indices] = color_rgb\n",
    "\n",
    "    # 正解マスクの作成\n",
    "    true_indices = np.where(y_true == label_name)[0]\n",
    "    true_mask.reshape(-1, 3)[true_indices] = color_rgb\n",
    "\n",
    "# 図の作成\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "# 1. 元画像の表示\n",
    "axes[0].imshow(original_image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. 予測結果の可視化\n",
    "axes[1].imshow(pred_mask)\n",
    "axes[1].set_title('Predicted Labels')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 3. 正解ラベルの可視化\n",
    "axes[2].imshow(true_mask)\n",
    "axes[2].set_title('True Labels')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 凡例の作成\n",
    "legend_patches = []\n",
    "for label_name, color in label_to_color_map.items():\n",
    "    legend_patches.append(mpatches.Patch(color=color, label=label_name))\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722406a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b19512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# # --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data\")\n",
    "dataset1_folder_name = \"MPs_20250911\"\n",
    "dataset2_folder_name = \"MPs_20250905_2\"\n",
    "# # ------------------------------\n",
    "\n",
    "# 作成されたピクセル単位のデータセットを読み込む\n",
    "dataset1_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "dataset2_csv_path = main_dir / dataset1_folder_name / \"csv\" / \"pixel_features_with_background.csv\"\n",
    "\n",
    "try:\n",
    "    df_pixels = pd.read_csv(output_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: {output_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "print(\"データセットを正常に読み込みました。\")\n",
    "\n",
    "\n",
    "# 背景（_background_）データを除外して学習データを作成\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "\n",
    "if df_labeled_only.empty:\n",
    "    print(\"警告: データセットにラベル付けされたプラスチックのピクセルがありません。\")\n",
    "    exit()\n",
    "\n",
    "# 特徴量（X）と正解ラベル（y）に分割\n",
    "X = df_labeled_only.drop(columns=['label_value', 'label_name'])\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "# データを学習用とテスト用に分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\n学習データセットのサイズ: {len(X_train)} 件\")\n",
    "print(f\"テストデータセットのサイズ: {len(X_test)} 件\")\n",
    "\n",
    "# ランダムフォレストモデルの学習\n",
    "print(\"\\nランダムフォレストモデルの学習を開始します...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"学習が完了しました。\")\n",
    "\n",
    "# 学習済みモデルをjoblib形式で保存\n",
    "model_save_path = main_dir / \"random_forest_model_no_scatter.joblib\"\n",
    "joblib.dump(model, model_save_path)\n",
    "print(f\"\\n学習済みモデルを保存しました: {model_save_path}\")\n",
    "\n",
    "# テストデータで予測を行い、精度を評価\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n--- 精度評価レポート ---')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 特徴量の重要度を計算し、ランキング形式で表示\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 保存先を指定\n",
    "importance_csv_path = main_dir / \"csv\" /\"selected_wavelengths_importance_with_background.csv\"\n",
    "# 親ディレクトリが存在しない場合は作成\n",
    "importance_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "importance_df.to_csv(importance_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n特徴量重要度ランキングを保存しました: {importance_csv_path}\")\n",
    "print(\"\\n上位5件の特徴量:\")\n",
    "print(importance_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4623455",
   "metadata": {},
   "source": [
    "---\n",
    "# 選択した波長の分光画像からの画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a168147",
   "metadata": {},
   "source": [
    "## データセットの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71af38",
   "metadata": {},
   "source": [
    "### 背景あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "folder_name = \"MPs_20250911\"\n",
    "# folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "n_features = 10  # 上位何個の波長を使うか指定\n",
    "importance_csv_path = main_dir / \"csv\" / \"selected_wavelengths_importance_with_background.csv\"  # 波長選択の結果\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_with_background.csv\"  #  ラベル域の全データセット\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 1. 特徴量重要度ランキングを読み込み\n",
    "importance_df = pd.read_csv(importance_csv_path)\n",
    "\n",
    "# 上位 n_features の波長名を取得\n",
    "top_features = importance_df['feature'].head(n_features).tolist()\n",
    "print(f\"選択された上位 {n_features} 波長: {top_features}\")\n",
    "\n",
    "# 2. ピクセル単位データを読み込み\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 背景を除外（ラベル名が _background_ の行を削除）\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "\n",
    "# 3. 必要な列だけ抽出\n",
    "df_selected = df_labeled_only[['label_value', 'label_name'] + top_features]\n",
    "\n",
    "# 4. 保存\n",
    "output_csv_path = main_dir / \"csv\" / f\"pixel_features_top{n_features}_wavelengths_with_background.csv\"\n",
    "df_selected.to_csv(output_csv_path, index=False)\n",
    "print(f\"データセットを保存しました: {output_csv_path}\")\n",
    "print(df_selected.head())\n",
    "\n",
    "# ラベルごとのピクセル数を確認\n",
    "print(\"\\nラベルごとのピクセル数:\")\n",
    "print(df_selected['label_name'].value_counts())\n",
    "\n",
    "\n",
    "# --- プレビュー表示 ---\n",
    "print(\"\\n=== データセット情報 ===\")\n",
    "print(f\"全体のサイズ: {df_selected.shape[0]} サンプル, {df_selected.shape[1]} 列\")\n",
    "\n",
    "print(\"\\n=== 先頭5行 ===\")\n",
    "print(df_selected.head())\n",
    "\n",
    "print(\"\\n=== ラベルごとのピクセル数 ===\")\n",
    "print(df_selected['label_name'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac0b2a",
   "metadata": {},
   "source": [
    "### 背景なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "# folder_name = \"MPs_20250911\"\n",
    "folder_name = \"MPs_20250905_2\"\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "file_stem =f\"{folder_name}_Ex-1_Em-1_ET300_step1\"\n",
    "main_dir = Path(f\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/{folder_name}\")\n",
    "reference_file_stem = f\"{folder_name}_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "\n",
    "n_features = 10 # 上位何個の波長を使うか指定\n",
    "importance_csv_path = main_dir / \"csv\" / \"selected_wavelengths_importance_no_background.csv\" # 波長選択の結果\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\" #  ラベル域の全データセット\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# 1. 特徴量重要度ランキングを読み込み\n",
    "try:\n",
    "    importance_df = pd.read_csv(importance_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {importance_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 上位 n_features の波長名を取得\n",
    "top_features = importance_df['feature'].head(n_features).tolist()\n",
    "print(f\"選択された上位 {n_features} 波長: {top_features}\")\n",
    "\n",
    "# 2. ピクセル単位データを読み込み\n",
    "try:\n",
    "    df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {pixel_features_all_data_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 背景データを含めるため、背景除外処理をスキップ\n",
    "df_labeled_only = df_pixels.copy()\n",
    "\n",
    "# 3. 必要な列だけ抽出\n",
    "df_selected = df_labeled_only[['label_value', 'label_name'] + top_features]\n",
    "\n",
    "# 4. 保存\n",
    "output_csv_path = main_dir / \"csv\" / f\"pixel_features_top{n_features}_wavelengths_no_background.csv\"\n",
    "output_csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_selected.to_csv(output_csv_path, index=False)\n",
    "print(f\"データセットを保存しました: {output_csv_path}\")\n",
    "\n",
    "\n",
    "# --- プレビュー表示 ---\n",
    "print(\"\\n=== データセット情報 ===\")\n",
    "print(f\"全体のサイズ: {df_selected.shape[0]} サンプル, {df_selected.shape[1]} 列\")\n",
    "\n",
    "print(\"\\n=== 先頭5行 ===\") \n",
    "print(df_selected.head())\n",
    "\n",
    "print(\"\\n=== ラベルごとのピクセル数 ===\")\n",
    "print(df_selected['label_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48f3b5",
   "metadata": {},
   "source": [
    "## RandomForestで学習・評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 説明変数と目的変数\n",
    "X = df_selected.drop(columns=['label_value', 'label_name'])\n",
    "y = df_selected['label_name']\n",
    "\n",
    "# 学習データとテストデータ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# RandomForest（クラス不均衡対応）\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  # 少数クラスを重視\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 精度評価\n",
    "y_pred = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a04593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "# reference_file_stem = \"MPs_20250905_2_Ex-1_Em-1_ET300_step1\"   # 元画像（JSON・tiff）の基準\n",
    "visualize_file_stem = f\"{folder_name}_Ex260_Em280_ET10000_step1\"  # 可視化対象画像\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\"\n",
    "\n",
    "# top_features = [\n",
    "#     'Ex360_Em380', 'Ex320_Em360', 'Ex380_Em420', 'Ex260_Em360', 'Ex300_Em380',\n",
    "#     'Ex360_Em460', 'Ex300_Em360', 'Ex280_Em380', 'Ex340_Em380', 'Ex340_Em400'\n",
    "# ]\n",
    "# --------------------\n",
    "\n",
    "# 1. データ読み込み\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 2. 背景も含むデータでモデル学習\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']  # 学習はラベルのみ\n",
    "\n",
    "X = df_labeled_only[top_features]\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# 3. JSONからラベル情報を取得\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i+1 for i, label in enumerate(labels_in_json)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "\n",
    "# 4. 可視化対象画像のサイズ\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\")\n",
    "original_img = np.asarray(Image.open(image_path))\n",
    "height, width = original_img.shape\n",
    "\n",
    "# 5. 全ピクセル（背景も含む）に対して予測\n",
    "X_all = df_pixels[top_features]  # 学習時と同じ列順・列名\n",
    "y_pred_all = model.predict(X_all)\n",
    "\n",
    "# 数値ラベルに変換（背景は0のまま）\n",
    "predicted_mask_flat = pd.Series(y_pred_all).map(lambda x: label_name_to_value.get(x, 0)).values\n",
    "predicted_mask = predicted_mask_flat.reshape(height, width)\n",
    "\n",
    "# 背景を透明にするマスク\n",
    "mask_alpha = np.where(predicted_mask == 0, 0.0, 0.6)\n",
    "\n",
    "# 6. カラーマップ設定\n",
    "colors = ['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF',\n",
    "          '#00FFFF', '#FFA500', '#800080', '#A52A2A']  # 適宜追加\n",
    "cmap = ListedColormap(colors[:len(value_to_label_name)])\n",
    "\n",
    "legend_patches = []\n",
    "for label_value, label_name in value_to_label_name.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    color_rgb = np.array([int(colors[label_value][i:i+2],16)/255. for i in (1,3,5)])\n",
    "    legend_patches.append(mpatches.Patch(color=color_rgb, label=label_name))\n",
    "\n",
    "# 7. 可視化\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.imshow(np.asarray(Image.open(main_dir / (visualize_file_stem + \".tiff\"))), cmap='gray')\n",
    "ax.imshow(predicted_mask, cmap=cmap, alpha=mask_alpha, vmin=0, vmax=len(value_to_label_name)-1)\n",
    "ax.set_title(f'Predicted Classification (Selected Wavelengths)')\n",
    "ax.axis('off')\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05,1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3442b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# # --- ユーザー設定 ---\n",
    "# main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_20250905_2\")\n",
    "# reference_file_stem = \"MPs_20250905_2_Ex-1_Em-1_ET300_step1\"   # 元画像（JSON・tiff）の基準\n",
    "# visualize_file_stem = \"MPs_20250905_2_Ex260_Em280_ET10000_step1\"  # 可視化対象画像\n",
    "# top_features = [\n",
    "#     'Ex360_Em380', 'Ex320_Em360', 'Ex380_Em420', 'Ex260_Em360', 'Ex300_Em380',\n",
    "#     'Ex360_Em460', 'Ex300_Em360', 'Ex280_Em380', 'Ex340_Em380', 'Ex340_Em400'\n",
    "# ]\n",
    "# --------------------\n",
    "\n",
    "# 1. データ読み込み\n",
    "pixel_features_all_data_path = main_dir / \"csv\" / \"pixel_features_no_background.csv\"\n",
    "df_pixels = pd.read_csv(pixel_features_all_data_path)\n",
    "\n",
    "# 2. 学習用データ（背景は除外）\n",
    "df_labeled_only = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "X = df_labeled_only[top_features]\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 精度評価\n",
    "y_pred_test = model.predict(X_test)\n",
    "print('--- 精度評価レポート（重要波長のみ・クラス不均衡対応） ---')\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# 3. JSONからラベル情報取得\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "labels_in_json = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i+1 for i, label in enumerate(labels_in_json)}  # プラスチックのみ\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "\n",
    "# 4. 元画像サイズ取得\n",
    "image_path = main_dir / (visualize_file_stem + \".tiff\")\n",
    "original_img = np.asarray(Image.open(image_path))\n",
    "height, width = original_img.shape\n",
    "\n",
    "# 5. 背景は除外して予測\n",
    "df_for_pred = df_pixels[df_pixels['label_name'] != '_background_']\n",
    "X_all = df_for_pred[top_features]\n",
    "y_pred_all = model.predict(X_all)\n",
    "\n",
    "# 6. 予測結果を元画像サイズに埋め込む\n",
    "predicted_mask = np.zeros((height, width), dtype=int)\n",
    "predicted_flat = pd.Series(y_pred_all).map(lambda x: label_name_to_value.get(x, 0)).values\n",
    "predicted_mask_flat_index = np.flatnonzero(df_pixels['label_name'] != '_background_')\n",
    "predicted_mask.ravel()[predicted_mask_flat_index] = predicted_flat\n",
    "\n",
    "# 7. カラーマップ設定\n",
    "colors = ['#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF',\n",
    "          '#00FFFF', '#FFA500', '#800080', '#A52A2A', '#FFC0CB']  # 適宜追加\n",
    "cmap = ListedColormap(colors[:len(value_to_label_name)])\n",
    "\n",
    "legend_patches = []\n",
    "for label_value, label_name in value_to_label_name.items():\n",
    "    color_rgb = np.array([int(colors[label_value-1][i:i+2],16)/255. for i in (1,3,5)])\n",
    "    legend_patches.append(mpatches.Patch(color=color_rgb, label=label_name))\n",
    "\n",
    "# 8. 可視化\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.imshow(original_img, cmap='gray')\n",
    "# 背景以外のみマスクを重ねる\n",
    "mask_alpha = np.where(predicted_mask==0, 0, 0.6)\n",
    "ax.imshow(predicted_mask, cmap=cmap, alpha=mask_alpha, vmin=0, vmax=len(value_to_label_name))\n",
    "ax.set_title(f'Predicted Classification (Selected Wavelengths)')\n",
    "ax.axis('off')\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05,1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc645d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
