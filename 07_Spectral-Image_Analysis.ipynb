{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# プロジェクトのメインディレクトリ\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "\n",
    "# 画像とJSONファイルのパス\n",
    "json_path = main_dir / \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.json\"\n",
    "image_path = main_dir / \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\"\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(image_path)\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# label_name_to_value を作成\n",
    "label_name_to_value = {\"_background_\": 0}  # 背景は0\n",
    "for shape in data[\"shapes\"]:\n",
    "    label_name = shape[\"label\"]\n",
    "    if label_name not in label_name_to_value:\n",
    "        label_name_to_value[label_name] = len(label_name_to_value)\n",
    "\n",
    "# マスクを生成（新しいAPI）\n",
    "lbl, _ = labelme.utils.shapes_to_label(\n",
    "    img_shape=img.shape,\n",
    "    shapes=data[\"shapes\"],\n",
    "    label_name_to_value=label_name_to_value\n",
    ")\n",
    "\n",
    "# マスクを可視化\n",
    "mask = (lbl > 0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Mask Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48695cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# プロジェクトのメインディレクトリとファイル名を指定\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "file_stem = \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1\"\n",
    "\n",
    "json_path = main_dir / (file_stem + \".json\")\n",
    "image_path = main_dir / (file_stem + \".tiff\")\n",
    "\n",
    "# JSONファイルを読み込む\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ラベル名と数値の対応辞書を作成\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 画像を読み込む\n",
    "img = np.asarray(Image.open(image_path))\n",
    "\n",
    "# マスクを生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 各ラベルごとに画素値を抽出し、統計量を算出\n",
    "results = {}\n",
    "for label_name, value in label_name_to_value.items():\n",
    "    if label_name == '_background_':\n",
    "        continue\n",
    "    \n",
    "    # ラベルに対応するマスクを作成\n",
    "    label_mask = (lbl == value)\n",
    "    pixel_values = img[label_mask]\n",
    "    \n",
    "    if len(pixel_values) > 0:\n",
    "        results[label_name] = {\n",
    "            'pixel_count': len(pixel_values),\n",
    "            'mean': np.mean(pixel_values),\n",
    "            'std_dev': np.std(pixel_values),\n",
    "            'max_value': np.max(pixel_values),\n",
    "            'min_value': np.min(pixel_values)\n",
    "        }\n",
    "    else:\n",
    "        results[label_name] = \"No pixels found for this label.\"\n",
    "\n",
    "# 結果を整形して表示\n",
    "for label, stats in results.items():\n",
    "    print(f'--- ラベル: {label} ---')\n",
    "    if isinstance(stats, str):\n",
    "        print(stats)\n",
    "    else:\n",
    "        print(f'画素数: {stats[\"pixel_count\"]}')\n",
    "        print(f'平均値: {stats[\"mean\"]}')\n",
    "        print(f'標準偏差: {stats[\"std_dev\"]}')\n",
    "        print(f'最大値: {stats[\"max_value\"]}')\n",
    "        print(f'最小値: {stats[\"min_value\"]}')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# 画像ファイルのパスを指定してください\n",
    "# 基準画像のパス\n",
    "reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "# 比較したい分光画像のパス（例）\n",
    "spectral_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex260_Em280_ET20000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(reference_image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 画像を重ねて表示\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.imshow(ref_img, cmap='gray', alpha=1.0) # 基準画像を背景に表示\n",
    "ax.imshow(spec_img, cmap='jet', alpha=0.5) # 分光画像を半透明で重ねて表示\n",
    "ax.set_title('Image Alignment Check')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.registration import phase_cross_correlation\n",
    "\n",
    "# 画像ファイルのパスを指定\n",
    "reference_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex-1_Em-1_ET300_step1.tiff\")\n",
    "spectral_image_path = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826/MPs_15cm_20250826_Ex260_Em280_ET20000_step1.tiff\")\n",
    "\n",
    "# 画像を読み込み\n",
    "try:\n",
    "    ref_img = np.asarray(Image.open(reference_image_path))\n",
    "    spec_img = np.asarray(Image.open(spectral_image_path))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"ファイルパスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "# 画像のサイズを確認\n",
    "if ref_img.shape != spec_img.shape:\n",
    "    print(\"Error: 画像のサイズが異なります。\")\n",
    "    exit()\n",
    "\n",
    "# 位相相関法でずれを計算\n",
    "# output: ずれの量 (y, x), 誤差, 位相相関のピーク\n",
    "shift, error, phase = phase_cross_correlation(ref_img, spec_img)\n",
    "\n",
    "# ずれの量（ピクセル単位）を表示\n",
    "print(f'基準画像に対する分光画像のずれ:')\n",
    "print(f'  y方向 (縦): {shift[0]:.2f} ピクセル')\n",
    "print(f'  x方向 (横): {shift[1]:.2f} ピクセル')\n",
    "print(f'  誤差: {error:.4f}')\n",
    "\n",
    "# ずれが非常に小さい（0に近い）ことを確認し、問題ないと判断\n",
    "if np.sqrt(shift[0]**2 + shift[1]**2) < 1.0:\n",
    "    print(\"\\n画像間のずれは1ピクセル未満です。位置合わせは正確であると考えられます。\")\n",
    "else:\n",
    "    print(\"\\n画像間にずれがある可能性があります。再撮影または画像補正を検討してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c795e5d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a136d9",
   "metadata": {},
   "source": [
    "## ラベル単位での分類(修正版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "reference_file_stem = \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1\"\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準JSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "print(f\"Loading reference JSON file from: {json_path}\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: JSONファイルが見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "all_results = []\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "\n",
    "# 2. フォルダ内の分光画像ファイルだけを対象にループ処理\n",
    "image_files = list(main_dir.glob(\"*Ex*_Em*.tiff\"))\n",
    "image_files = [f for f in image_files if '-1-Em-1-' not in f.stem]\n",
    "\n",
    "if not image_files:\n",
    "    print(\"Error: 指定されたパターンに一致する分光画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nFound {len(image_files)} spectral image files to process.\")\n",
    "\n",
    "# 各プラスチック片にユニークなIDを付与\n",
    "shapes_with_ids = [{**shape, 'id': f\"{shape['label']}_{idx}\"} for idx, shape in enumerate(data['shapes'])]\n",
    "\n",
    "for image_path in image_files:\n",
    "    try:\n",
    "        match = wavelength_pattern.search(image_path.name)\n",
    "        if not match:\n",
    "            print(f\"Warning: Wavelength pattern not found in {image_path.name}. Skipping.\")\n",
    "            continue\n",
    "        ex_wavelength = int(match.group(1))\n",
    "        em_wavelength = int(match.group(2))\n",
    "\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        lbl, _ = labelme.utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)\n",
    "        \n",
    "        # 各プラスチック片（shape）ごとに処理\n",
    "        for shape_obj in shapes_with_ids:\n",
    "            label_name = shape_obj['label']\n",
    "            shape_id = shape_obj['id']\n",
    "            label_value = label_name_to_value[label_name]\n",
    "            \n",
    "            # マスクを作成\n",
    "            shape_mask = (lbl == label_value)\n",
    "\n",
    "            pixel_values = img[shape_mask]\n",
    "\n",
    "            if len(pixel_values) > 0:\n",
    "                result = {\n",
    "                    'image_name': image_path.name,\n",
    "                    'label': label_name,\n",
    "                    'shape_id': shape_id,\n",
    "                    'Ex_wavelength': ex_wavelength,\n",
    "                    'Em_wavelength': em_wavelength,\n",
    "                    'pixel_count': len(pixel_values),\n",
    "                    'mean': np.mean(pixel_values),\n",
    "                    'std_dev': np.std(pixel_values),\n",
    "                    'max_value': np.max(pixel_values),\n",
    "                    'min_value': np.min(pixel_values)\n",
    "                }\n",
    "                all_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to process {image_path.name}. Reason: {e}\")\n",
    "        continue\n",
    "\n",
    "# 3. すべての結果をデータフレームに整理し、CSVとして保存\n",
    "if all_results:\n",
    "    df = pd.DataFrame(all_results)\n",
    "    output_csv_path = main_dir / \"combined_spectral_features_with_ids.csv\"\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f'\\n全分光データの統合データセットが作成されました: {output_csv_path}')\n",
    "    print('\\nデータセットのプレビュー:')\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Warning: No data was successfully processed. Check your files and paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 作成された統合データセットのパスを指定\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "output_csv_path = main_dir / \"combined_spectral_features_with_ids.csv\"\n",
    "\n",
    "# データセットを読み込み\n",
    "try:\n",
    "    df = pd.read_csv(output_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {output_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 'mean'値の列名を 'Ex' と 'Em' の波長情報を使って動的に作成\n",
    "df['feature_name'] = 'mean_' + 'Ex' + df['Ex_wavelength'].astype(str) + '_Em' + df['Em_wavelength'].astype(str)\n",
    "\n",
    "# 不要な列を削除\n",
    "df_pivot = df.drop(columns=['Ex_wavelength', 'Em_wavelength', 'image_name', 'pixel_count', 'std_dev', 'max_value', 'min_value'])\n",
    "\n",
    "# pivot_tableを使ってデータを「横長」に変換\n",
    "# indexに 'shape_id' と 'label' を指定して、各プラスチック片をユニークな行として扱う\n",
    "df_profile = df_pivot.pivot_table(\n",
    "    index=['shape_id', 'label'],\n",
    "    columns='feature_name',\n",
    "    values='mean',\n",
    "    aggfunc='mean'\n",
    ").reset_index()\n",
    "\n",
    "# 欠損値があれば0で埋める\n",
    "df_profile = df_profile.fillna(0)\n",
    "\n",
    "# 新しいデータセットをCSVファイルとして保存\n",
    "profile_csv_path = main_dir / \"spectral_profiles_per_piece.csv\"\n",
    "df_profile.to_csv(profile_csv_path, index=False)\n",
    "\n",
    "print(f'プラスチック片ごとの分光プロファイルデータセットが作成されました: {profile_csv_path}')\n",
    "print('\\nデータセットのプレビュー:')\n",
    "print(df_profile.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 作成された分光プロファイルデータセットのパスを指定\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "profile_csv_path = main_dir / \"spectral_profiles_per_piece.csv\"\n",
    "\n",
    "# データセットを読み込み\n",
    "try:\n",
    "    df_profile = pd.read_csv(profile_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {profile_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# ラベルとshape_idのユニークな組み合わせを取得し、これを分割\n",
    "unique_samples = df_profile[['shape_id', 'label']].drop_duplicates()\n",
    "\n",
    "# 訓練用とテスト用に分割\n",
    "# ここでは、プラスチックの種類ごとにサンプルを均等に分割\n",
    "X_train_samples, X_test_samples, y_train_samples, y_test_samples = train_test_split(\n",
    "    unique_samples['shape_id'],\n",
    "    unique_samples['label'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=unique_samples['label']\n",
    ")\n",
    "\n",
    "# 分割したサンプルIDを使って、元のデータフレームから訓練・テストデータを抽出\n",
    "X_train = df_profile[df_profile['shape_id'].isin(X_train_samples)].drop(columns=['shape_id', 'label'])\n",
    "y_train = df_profile[df_profile['shape_id'].isin(X_train_samples)]['label']\n",
    "X_test = df_profile[df_profile['shape_id'].isin(X_test_samples)].drop(columns=['shape_id', 'label'])\n",
    "y_test = df_profile[df_profile['shape_id'].isin(X_test_samples)]['label']\n",
    "\n",
    "\n",
    "# RandomForestClassifierモデルを初期化し、学習\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# テストデータに対する予測を実行\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 精度評価レポートを表示\n",
    "print('--- 精度評価レポート（正しい分割による評価） ---')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 特徴量の重要度を取得\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# 重要度をデータフレームに整理し、重要度が高い順に並べる\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 重要度を可視化\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(importance_df['feature'], importance_df['importance'])\n",
    "plt.xticks(rotation=90, ha='right', fontsize=8)\n",
    "plt.title('Feature Importances based on Spectral Profiles')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n特徴量の重要度ランキング（トップ10）:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5a1f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f122874",
   "metadata": {},
   "source": [
    "# ピクセル単位での分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8fa9b",
   "metadata": {},
   "source": [
    "## ラベリング結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # 凡例用\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "reference_file_stem = \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "# ------------------------------\n",
    "\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "image_path = main_dir / (reference_file_stem + \".tiff\") # ラベリングに使用した元の画像パス\n",
    "\n",
    "print(f\"Loading JSON file: {json_path}\")\n",
    "print(f\"Loading original image: {image_path}\")\n",
    "\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: JSONファイル '{json_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    original_img = np.asarray(Image.open(image_path))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: 元画像ファイル '{image_path}' が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# ラベル名と数値の対応付け\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0 # 背景には0を割り当てる\n",
    "\n",
    "# ラベルマップ（数値）を生成\n",
    "lbl, _ = labelme.utils.shapes_to_label(original_img.shape, data['shapes'], label_name_to_value)\n",
    "\n",
    "# 可視化用のカラーマップを生成\n",
    "# ラベル数に応じて色を割り当てる\n",
    "unique_labels = np.unique(lbl)\n",
    "colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "colored_mask = np.zeros((*lbl.shape, 3), dtype=np.uint8)\n",
    "legend_patches = []\n",
    "label_value_to_color = {}\n",
    "\n",
    "for i, label_value in enumerate(unique_labels):\n",
    "    if label_value == 0:\n",
    "        color = np.array([0, 0, 0])\n",
    "        label_name = 'background'\n",
    "    else:\n",
    "        # 修正: np.array()で一度配列に変換してからastype()を適用\n",
    "        color = (np.array(colors(i)[:3]) * 255).astype(np.uint8)\n",
    "        label_name = list(label_name_to_value.keys())[list(label_name_to_value.values()).index(label_value)]\n",
    "        legend_patches.append(mpatches.Patch(color=color/255., label=label_name))\n",
    "    \n",
    "    colored_mask[lbl == label_value] = color\n",
    "\n",
    "# 元画像とカラーマスクを並べて表示\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(colored_mask)\n",
    "axes[1].set_title('Labeled Mask (Pixel-wise Labels)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.legend(handles=legend_patches, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n可視化されたラベリング結果を確認しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfcf5a7",
   "metadata": {},
   "source": [
    "## データセットの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import labelme\n",
    "import json\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# --- ユーザーが設定する項目 ---\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "reference_file_stem = \"MPs_15cm_20250826_Ex-1_Em-1_ET300_step1\" # ラベリングに使用した画像ファイル名（拡張子なし）\n",
    "# ------------------------------\n",
    "\n",
    "# 1. 基準JSONファイルを読み込む\n",
    "json_path = main_dir / (reference_file_stem + \".json\")\n",
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: JSONファイルが見つかりません。パスを確認してください。\")\n",
    "    exit()\n",
    "\n",
    "labels = sorted(list(set(shape['label'] for shape in data['shapes'])))\n",
    "label_name_to_value = {label: i for i, label in enumerate(labels, start=1)}\n",
    "label_name_to_value['_background_'] = 0\n",
    "\n",
    "# 2. すべての分光画像の画素値をピクセル単位で抽出\n",
    "wavelength_pattern = re.compile(r'Ex(\\d+)_Em(\\d+)')\n",
    "image_files = list(main_dir.glob(\"*Ex*_Em*.tiff\"))\n",
    "image_files = [f for f in image_files if '-1-Em-1-' not in f.stem]\n",
    "\n",
    "if not image_files:\n",
    "    print(\"Error: 指定されたパターンに一致する分光画像ファイルが見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "pixel_features_df = pd.DataFrame()\n",
    "processed_files_count = 0\n",
    "image_size = None # 画像サイズを動的に取得するための変数\n",
    "\n",
    "for image_path in image_files:\n",
    "    try:\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        # 初回ループ時に画像サイズを取得\n",
    "        if image_size is None:\n",
    "            image_size = img.shape\n",
    "            print(f\"画像サイズを検出しました: {image_size}\")\n",
    "        \n",
    "        # サイズが一致しない場合はスキップ\n",
    "        if img.shape != image_size:\n",
    "            print(f\"Warning: {image_path.name} のサイズが異なります。スキップします。\")\n",
    "            continue\n",
    "\n",
    "        match = wavelength_pattern.search(image_path.name)\n",
    "        if not match:\n",
    "            continue\n",
    "        ex_wavelength = int(match.group(1))\n",
    "        em_wavelength = int(match.group(2))\n",
    "        \n",
    "        pixel_features_df[f'Ex{ex_wavelength}_Em{em_wavelength}'] = img.flatten()\n",
    "        processed_files_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to process {image_path.name}. Reason: {e}\")\n",
    "        continue\n",
    "\n",
    "if processed_files_count > 0:\n",
    "    # 3. 正解ラベルの列をデータフレームに追加\n",
    "    # 動的に取得した画像サイズでマスクを生成\n",
    "    pixel_label_mask, _ = labelme.utils.shapes_to_label(image_size, data['shapes'], label_name_to_value)\n",
    "    \n",
    "    # マスクを1次元配列に変換\n",
    "    pixel_labels_flat = pixel_label_mask.flatten()\n",
    "\n",
    "    pixel_features_df['label_value'] = pixel_labels_flat\n",
    "    pixel_features_df['label_name'] = pd.Series(pixel_labels_flat).map({v: k for k, v in label_name_to_value.items()})\n",
    "\n",
    "    # データセットをCSVとして保存\n",
    "    output_csv_path = main_dir / \"pixel_features_all_data.csv\"\n",
    "    pixel_features_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f'\\nピクセル単位のデータセットが作成されました: {output_csv_path}')\n",
    "    print('\\nデータセットのプレビュー:')\n",
    "    print(pixel_features_df.head())\n",
    "else:\n",
    "    print(\"Warning: No data was successfully processed. Check your files and paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ec443",
   "metadata": {},
   "source": [
    "## 学習と波長選択(散乱光を除く)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# 作成されたピクセル単位のデータセットを読み込む\n",
    "main_dir = Path(\"C:/Users/sawamoto24/sawamoto24/master/microplastic/data/MPs_15cm_20250826\")\n",
    "output_csv_path = main_dir / \"pixel_features_all_data.csv\"\n",
    "\n",
    "try:\n",
    "    df_pixels = pd.read_csv(output_csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {output_csv_path} が見つかりません。\")\n",
    "    exit()\n",
    "\n",
    "# 散乱光の波長を除外する処理\n",
    "# 列名から'Ex'と'Em'の波長が同じものをフィルタリング\n",
    "scatter_light_cols = [col for col in df_pixels.columns if 'Ex' in col and 'Em' in col and col.split('_')[0].replace('Ex', '') == col.split('_')[1].replace('Em', '')]\n",
    "df_filtered = df_pixels.drop(columns=scatter_light_cols)\n",
    "\n",
    "df_labeled_only = df_filtered[df_filtered['label_name'] != '_background_']\n",
    "\n",
    "if df_labeled_only.empty:\n",
    "    print(\"Warning: データセットにラベル付けされたプラスチックのピクセルがありません。\")\n",
    "    exit()\n",
    "\n",
    "X = df_labeled_only.drop(columns=['label_value', 'label_name'])\n",
    "y = df_labeled_only['label_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model_save_path = main_dir / \"random_forest_model_no_scatter.joblib\"\n",
    "joblib.dump(model, model_save_path)\n",
    "print(f\"\\n学習済みモデルを保存しました: {model_save_path}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('--- 精度評価レポート（散乱光除去後） ---')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\n特徴量の重要度ランキング（トップ10）:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4623455",
   "metadata": {},
   "source": [
    "---\n",
    "# 選択した波長の分光画像からの画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a168147",
   "metadata": {},
   "source": [
    "## データセットの作成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
