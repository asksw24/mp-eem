{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  matplotlib import pyplot as plt\n",
    "import os \n",
    "from pathlib import Path\n",
    "import re\n",
    "import PIL\n",
    "import cv2\n",
    "import seaborn as sns \n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "import spectral_util\n",
    "importlib.reload(spectral_util)\n",
    "from spectral_util import *\n",
    "\n",
    "import fluorescence_util\n",
    "importlib.reload(fluorescence_util)\n",
    "from fluorescence_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'board.xlsx'\n",
    "# 'board_noFlux.xlsx'\n",
    "# 'flux_20240925_184835.xlsx'\n",
    "# 'flux-onBoard.xlsx'\n",
    "# 'lead_noFlux.xlsx'\n",
    "\n",
    "# srcbase = Path(\"./data/EEM_F-7000_2025-04-11/\")\n",
    "print(Path.cwd())\n",
    "srcbase = Path(\"./data/EEM_F-7000_2025-05-29/\")\n",
    "dstdir = Path(\"./dst/eem/filter\")\n",
    "\n",
    "srcdata = [\n",
    "    {\n",
    "        \"path\": fpath,\n",
    "        \"sample\": fpath.stem.split(\"_\")[0],  # 'ABS_20250411' → 'ABS'\n",
    "        \"label\": None\n",
    "    }\n",
    "    for fpath in srcbase.glob(\"*.xlsx\")\n",
    "]\n",
    "srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in srcdata:\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "    print(eem)\n",
    "\n",
    "    plt.figure()\n",
    "    eem.plot_contour(level=100, show_sample_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_bands = eem.em_bands\n",
    "ex_bands = eem.ex_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 散乱光の除去と波長域の調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% EEMデータの読み込みと前処理（散乱除去 & NaN保持）\n",
    "\n",
    "sample_data_processed = []\n",
    "sample_name = []\n",
    "\n",
    "# 波長域を先に定義しておく\n",
    "eem_template = fluorescence_util.EEMF7000(srcdata[0]['path'])\n",
    "ex_bands_full = eem_template.ex_bands\n",
    "em_bands_full = eem_template.em_bands\n",
    "\n",
    "# 250nm以上の波長マスクを作成\n",
    "ex_mask = ex_bands_full >= 250\n",
    "em_mask = em_bands_full >= 250\n",
    "\n",
    "# トリミング後の波長域を保存\n",
    "ex_bands_trimmed = ex_bands_full[ex_mask]\n",
    "em_bands_trimmed = em_bands_full[em_mask]\n",
    "\n",
    "\n",
    "print(\"--- データの前処理を開始します ---\")\n",
    "for data in srcdata:\n",
    "    # EEMデータの読み込み\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "\n",
    "    # ① 散乱ピーク除去（NaNを代入）\n",
    "    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "                                                       remove_first_order=True,\n",
    "                                                       inplace=True)\n",
    "    # ② 追加で散乱領域全体を除去（NaNを代入）\n",
    "    eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "    # 生の行列を取得\n",
    "    eem_matrix = eem.mat\n",
    "\n",
    "    # ③ 波長域をトリミング\n",
    "    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]\n",
    "\n",
    "    # 前処理済みのデータをリストに追加\n",
    "    sample_data_processed.append(eem_matrix_trimmed)\n",
    "    sample_name.append(eem.sample)\n",
    "    print(f\"  - サンプル '{eem.sample}' の前処理が完了しました。\")\n",
    "\n",
    "print(\"--- 全ての前処理が完了しました ---\")\n",
    "\n",
    "# リストを3Dのnumpy配列に変換\n",
    "# この段階ではNaNが含まれている\n",
    "eem_array_processed = np.array(sample_data_processed)\n",
    "\n",
    "print(\"\\n処理後のデータ形状:\", eem_array_processed.shape)\n",
    "print(\"励起波長の数:\", len(ex_bands_trimmed))\n",
    "print(\"蛍光波長の数:\", len(em_bands_trimmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% データの正規化（論文準拠: Unit Norm Scaling）\n",
    "\n",
    "# 正規化済みのデータを格納する新しいリストを作成\n",
    "sample_data_normalized = []\n",
    "\n",
    "print(\"--- データの正規化を開始します（論文準拠）---\")\n",
    "for i, eem_matrix in enumerate(eem_array_processed):\n",
    "    # NaNを無視して、二乗和を計算\n",
    "    sum_of_squares = np.nansum(eem_matrix**2)\n",
    "\n",
    "    # 二乗和が0または非常に小さい場合は、ゼロ除算を避ける\n",
    "    if sum_of_squares > 1e-8:\n",
    "        eem_normalized = eem_matrix / sum_of_squares\n",
    "    else:\n",
    "        # データが全て0やNaNの場合、そのまま（変更なし）\n",
    "        eem_normalized = eem_matrix\n",
    "\n",
    "    sample_data_normalized.append(eem_normalized)\n",
    "    print(f\"  - サンプル '{sample_name[i]}' の正規化が完了しました。\")\n",
    "\n",
    "print(\"--- 全ての正規化が完了しました ---\")\n",
    "\n",
    "# 正規化後のデータを3Dのnumpy配列に変換\n",
    "# この段階でもNaNは保持されています\n",
    "eem_array_normalized = np.array(sample_data_normalized)\n",
    "\n",
    "print(\"\\n正規化後のデータ形状:\", eem_array_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップA: サンプル名とデータの対応を確認\n",
    "\n",
    "print(\"--- サンプル名とデータの対応を確認します ---\")\n",
    "print(f\"合計サンプル数: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # 対応するデータの形状も一緒に表示\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"インデックス {i}: サンプル名 = '{name}', データ形状 = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"上記の順番でデータは並んでいます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップA: サンプル名とデータの対応を確認\n",
    "\n",
    "print(\"--- サンプル名とデータの対応を確認します ---\")\n",
    "print(f\"合計サンプル数: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # 対応するデータの形状も一緒に表示\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"インデックス {i}: サンプル名 = '{name}', データ形状 = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"上記の順番でデータは並んでいます。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 妥当性評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップB: 横軸を見やすくしたレバレッジプロット（レイアウト調整版）\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- この部分は変更ありません ---\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "# max_components = 9\n",
    "component_range = range(2, max_components + 1)\n",
    "leverage_results = {}\n",
    "for n_comp in component_range:\n",
    "    weights, factors = non_negative_parafac(tensor,\n",
    "                                            rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    sample_scores = factors[2]\n",
    "    try:\n",
    "        q, _ = np.linalg.qr(sample_scores)\n",
    "        leverage = np.sum(q**2, axis=1)\n",
    "        leverage_results[n_comp] = leverage\n",
    "    except np.linalg.LinAlgError:\n",
    "        leverage_results[n_comp] = np.full(tensor.shape[2], np.nan)\n",
    "# --- ここまで変更なし ---\n",
    "\n",
    "\n",
    "# --- 結果の可視化（レイアウト調整版） ---\n",
    "print(\"\\n--- レバレッジをプロットします ---\")\n",
    "\n",
    "# ▼▼▼ グラフ全体のサイズを、より縦長に調整 ▼▼▼\n",
    "fig, axes = plt.subplots(len(component_range), 1, figsize=(12, 5 * len(component_range)), sharex=True)\n",
    "if len(component_range) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, n_comp in enumerate(component_range):\n",
    "    ax = axes[i]\n",
    "    leverage = leverage_results.get(n_comp)\n",
    "    if leverage is not None and not np.isnan(leverage).all():\n",
    "        bars = ax.bar(sample_name, leverage)\n",
    "        ax.set_ylabel(\"Leverage\", fontsize=12)\n",
    "        ax.set_title(f\"Component = {n_comp}\", fontsize=14)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=11)\n",
    "        ax.tick_params(axis='y', labelsize=10) # y軸のラベルサイズも調整\n",
    "\n",
    "        threshold = 2 * n_comp / tensor.shape[2]\n",
    "        ax.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.2f})')\n",
    "        ax.legend()\n",
    "\n",
    "        for bar, name, lev_val in zip(bars, sample_name, leverage):\n",
    "            if lev_val > threshold:\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, lev_val, name,\n",
    "                        ha='center', va='bottom', fontsize=10, color='blue', weight='bold')\n",
    "    else:\n",
    "        ax.set_title(f\"Component = {n_comp} (Calculation Failed)\")\n",
    "\n",
    "plt.xlabel(\"Sample Name\", fontsize=14)\n",
    "\n",
    "# ▼▼▼ 各プロット間の余白をしっかり確保する命令を追加 ▼▼▼\n",
    "# pad=3.0 で、各グラフの周囲に十分なスペースを確保します\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## core consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% コアコンシステンシーの手動計算とプロット\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "\n",
    "# --- 事前準備（これまでのステップで準備した変数） ---\n",
    "# eem_array_normalized: 正規化済みでNaNを含むデータ配列\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNを0で埋めた正規化済みデータ\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# テンソルに変換 (励起, 蛍光, サンプル)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "\n",
    "# 試行する成分数の範囲\n",
    "# max_components = 9\n",
    "component_range = range(1, max_components + 1)\n",
    "\n",
    "\n",
    "print(\"--- コアコンシステンシーの計算を開始します (手動計算) ---\")\n",
    "core_consistencies = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"  - 成分数 = {n_comp} でモデルを構築中...\")\n",
    "    weights, factors = non_negative_parafac(tensor, rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    \n",
    "    # --- コアコンシステンシーの手動計算 ---\n",
    "    # 1. ローディング行列から、擬似逆行列を計算\n",
    "    pseudo_inverses = [np.linalg.pinv(f) for f in factors]\n",
    "    \n",
    "    # 2. 現実のコアテンソル（G）を計算\n",
    "    # G = X * (A^-1, B^-1, C^-1)\n",
    "    core_tensor_G = multi_mode_dot(tensor, pseudo_inverses, modes=[0, 1, 2])\n",
    "\n",
    "    # 3. 理想のコアテンソル（T）を作成（対角成分が1、他が0）\n",
    "    ideal_core_T = tl.zeros_like(core_tensor_G)\n",
    "    for i in range(n_comp):\n",
    "        ideal_core_T[i, i, i] = 1\n",
    "        \n",
    "    # 4. コアテンソルGの全要素の二乗和 (ssq_G) を計算\n",
    "    ssq_G = tl.sum(core_tensor_G**2)\n",
    "    \n",
    "    # 5. GとTの差の二乗和 (ssq_diff) を計算\n",
    "    ssq_diff = tl.sum((core_tensor_G - ideal_core_T)**2)\n",
    "    \n",
    "    # 6. コアコンシステンシーを計算\n",
    "    # 100 * (1 - (GとTの差の二乗和) / (Gの全要素の二乗和))\n",
    "    if ssq_G > 1e-8: # ゼロ除算を避ける\n",
    "        cc = (1 - (ssq_diff / ssq_G)) * 100\n",
    "    else:\n",
    "        cc = 0\n",
    "        \n",
    "    core_consistencies.append(cc)\n",
    "    print(f\"  - 成分数 = {n_comp} のコアコンシステンシー: {cc:.1f}%\")\n",
    "\n",
    "print(\"--- 計算が完了しました ---\")\n",
    "\n",
    "# --- 結果のプロット ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, core_consistencies, 'o-', color='b', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Core Consistency (%)\", fontsize=12)\n",
    "plt.title(\"Core Consistency Diagnostic\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 60%のラインに補助線を追加\n",
    "plt.axhline(y=60, color='r', linestyle='--', label='60% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(-5, 105) # 負の値も表示できるように調整\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% スプリットハーフ分析\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 事前準備（これまでのステップで準備した変数） ---\n",
    "# eem_array_normalized: 正規化済みでNaNを含むデータ配列\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNを0で埋めた正規化済みデータ\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# テンソルに変換 (励起, 蛍光, サンプル)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "num_samples = tensor.shape[2]\n",
    "\n",
    "\n",
    "# 試行する成分数の範囲\n",
    "# max_components = 9\n",
    "component_range = range(2, max_components + 1)\n",
    "\n",
    "print(\"--- スプリットハーフ分析を開始します ---\")\n",
    "similarity_scores = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"\\n--- 成分数 = {n_comp} で分析中... ---\")\n",
    "    \n",
    "    # 1. データセットをランダムに半分に分割\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    half1_indices = indices[:num_samples // 2]\n",
    "    half2_indices = indices[num_samples // 2:]\n",
    "    \n",
    "    tensor_half1 = tl.tensor(tensor[:, :, half1_indices])\n",
    "    tensor_half2 = tl.tensor(tensor[:, :, half2_indices])\n",
    "    \n",
    "    # 2. それぞれの半分でPARAFACを実行\n",
    "    _, factors1 = non_negative_parafac(tensor_half1, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    _, factors2 = non_negative_parafac(tensor_half2, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    \n",
    "    # 3. ローディングを比較\n",
    "    excitation_loadings1, emission_loadings1, _ = factors1\n",
    "    excitation_loadings2, emission_loadings2, _ = factors2\n",
    "    \n",
    "    # 類似度を計算 (最適なペアを見つけてマッチング)\n",
    "    total_similarity = 0\n",
    "    matched_indices2 = []\n",
    "    \n",
    "    for i in range(n_comp):\n",
    "        best_match_idx = -1\n",
    "        max_corr = -1\n",
    "        for j in range(n_comp):\n",
    "            if j in matched_indices2:\n",
    "                continue\n",
    "            corr_ex, _ = pearsonr(excitation_loadings1[:, i], excitation_loadings2[:, j])\n",
    "            corr_em, _ = pearsonr(emission_loadings1[:, i], emission_loadings2[:, j])\n",
    "            avg_corr = (corr_ex + corr_em) / 2\n",
    "            \n",
    "            if avg_corr > max_corr:\n",
    "                max_corr = avg_corr\n",
    "                best_match_idx = j\n",
    "        \n",
    "        total_similarity += max_corr\n",
    "        matched_indices2.append(best_match_idx)\n",
    "        \n",
    "    avg_similarity = total_similarity / n_comp\n",
    "    similarity_scores.append(avg_similarity * 100) # パーセントに変換\n",
    "    print(f\"  - 成分数 = {n_comp} の平均類似度: {avg_similarity*100:.1f}%\")\n",
    "\n",
    "print(\"--- 分析が完了しました ---\")\n",
    "\n",
    "# --- 結果のプロット ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, similarity_scores, 'o-', color='g', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Split-Half Similarity (%)\", fontsize=12)\n",
    "plt.title(\"Split-Half Analysis\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 95%のラインに補助線を追加\n",
    "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(0, 105)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ローディングの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 最終モデルの構築と結果の可視化\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 最適な成分数を設定 ---\n",
    "# max_components = 9\n",
    "\n",
    "# --- 事前準備 ---\n",
    "# 以下の変数が事前に定義されている必要があります\n",
    "# eem_array_normalized: 正規化済みの3次元データ配列 (サンプル x 励起 x 蛍光)\n",
    "# sample_name: サンプル名のリスト (例: ['ABS', 'HDPE', ...])\n",
    "# ex_bands_trimmed: 励起波長のリスト\n",
    "# em_bands_trimmed: 蛍光波長のリスト\n",
    "\n",
    "# NaNを0で埋めた正規化済みデータ\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# テンソルに変換 (励起, 蛍光, サンプル)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "\n",
    "# --- 最終モデルの計算 ---\n",
    "print(f\"--- 最適な成分数 = {max_components} で最終モデルを構築します ---\")\n",
    "weights, factors = non_negative_parafac(tensor, rank=max_components,\n",
    "                                        n_iter_max=500, tol=1e-7, init='random')\n",
    "\n",
    "# --- 結果の分解 ---\n",
    "# factors は [励起ローディング, 蛍光ローディング, サンプルスコア]\n",
    "excitation_loadings, emission_loadings, sample_scores = factors\n",
    "\n",
    "# 各ローディングとスコアを最大値で正規化して見やすくする\n",
    "excitation_loadings_norm = excitation_loadings / np.max(excitation_loadings, axis=0)\n",
    "emission_loadings_norm = emission_loadings / np.max(emission_loadings, axis=0)\n",
    "sample_scores_norm = sample_scores / np.max(sample_scores, axis=0)\n",
    "\n",
    "print(\"--- モデル構築完了 ---\")\n",
    "\n",
    "# --- 結果の可視化 ---\n",
    "\n",
    "# 1. 励起・蛍光ローディング（成分のスペクトル形状）のプロット\n",
    "print(\"\\n--- 抽出された成分のスペクトルをプロットします ---\")\n",
    "fig, axes = plt.subplots(max_components, 2, figsize=(12, 3 * max_components))\n",
    "for i in range(max_components):\n",
    "    # 励起ローディング\n",
    "    axes[i, 0].plot(ex_bands_trimmed, excitation_loadings_norm[:, i])\n",
    "    axes[i, 0].set_title(f'Component {i+1} - Excitation')\n",
    "    axes[i, 0].set_xlabel('Excitation (nm)')\n",
    "    axes[i, 0].grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # 蛍光ローディング\n",
    "    axes[i, 1].plot(em_bands_trimmed, emission_loadings_norm[:, i])\n",
    "    axes[i, 1].set_title(f'Component {i+1} - Emission')\n",
    "    axes[i, 1].set_xlabel('Emission (nm)')\n",
    "    axes[i, 1].grid(True, linestyle='--', alpha=0.6)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 全成分のスペクトルを一枚の図にまとめてプロット\n",
    "\n",
    "# --- 事前準備は変更なし ---\n",
    "# (excitation_loadings_norm, emission_loadings_norm, sample_scores など)\n",
    "# ---\n",
    "\n",
    "print(\"\\n--- 抽出された全成分のスペクトルを一枚の図にまとめてプロットします ---\")\n",
    "\n",
    "# --- 1. グラフ全体の準備 ---\n",
    "# ループの外で、成分の数だけ縦に並ぶサブプロットを作成\n",
    "fig, axes = plt.subplots(max_components, 1, figsize=(10, 4 * max_components))\n",
    "\n",
    "# 成分が1つの場合でも、axesがリストになるように調整\n",
    "if max_components == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# --- 2. 各成分についてループし、対応するサブプロットに描画 ---\n",
    "for i in range(max_components):\n",
    "    # 対応するサブプロット(ax1)を選択\n",
    "    ax1 = axes[i]\n",
    "    ax2 = ax1.twinx()  # 各サブプロットでY軸を共有\n",
    "\n",
    "    # --- スペクトルのプロット ---\n",
    "    color1 = 'tab:blue'\n",
    "    ax1.plot(ex_bands_trimmed, excitation_loadings_norm[:, i], color=color1, lw=2.5)\n",
    "    ax1.set_ylabel(f'Comp. {i+1} Ex (norm)', color=color1, fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    color2 = 'tab:red'\n",
    "    ax2.plot(em_bands_trimmed, emission_loadings_norm[:, i], color=color2, lw=2.5)\n",
    "    ax2.set_ylabel(f'Comp. {i+1} Em (norm)', color=color2, fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # --- ピーク波長の検出と描画 ---\n",
    "    ex_peak_idx = np.argmax(excitation_loadings_norm[:, i])\n",
    "    ex_peak_wl = ex_bands_trimmed[ex_peak_idx]\n",
    "    ax1.axvline(x=ex_peak_wl, color=color1, linestyle='--', alpha=0.8)\n",
    "    ax1.text(ex_peak_wl - 3, ax1.get_ylim()[1] * 0.5, f'{ex_peak_wl:.0f} nm',\n",
    "             color=color1, rotation='vertical', ha='right', va='center', fontsize=11)\n",
    "\n",
    "    em_peak_idx = np.argmax(emission_loadings_norm[:, i])\n",
    "    em_peak_wl = em_bands_trimmed[em_peak_idx]\n",
    "    ax2.axvline(x=em_peak_wl, color=color2, linestyle='--', alpha=0.8)\n",
    "    ax2.text(em_peak_wl + 3, ax2.get_ylim()[1] * 0.5, f'{em_peak_wl:.0f} nm',\n",
    "             color=color2, rotation='vertical', ha='left', va='center', fontsize=11)\n",
    "    \n",
    "    # --- Y軸の範囲を0からに固定 ---\n",
    "    ax1.set_ylim(bottom=0)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "\n",
    "# --- 3. 仕上げ ---\n",
    "# 最後のサブプロットにのみX軸のラベルを表示\n",
    "axes[-1].set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "\n",
    "# 図全体のレイアウトを調整\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. サンプルスコア（各MPの成分含有量）のプロット\n",
    "print(\"\\n--- 各MPの成分含有量をプロットします ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "# ヒートマップで可視化\n",
    "plt.imshow(sample_scores_norm.T, cmap='viridis', aspect='auto')\n",
    "plt.yticks(ticks=np.arange(max_components), labels=[f'Component {i+1}' for i in range(max_components)])\n",
    "plt.xticks(ticks=np.arange(len(sample_name)), labels=sample_name, rotation=45, ha='right')\n",
    "plt.colorbar(label='Relative Concentration (normalized)')\n",
    "plt.title('Component Scores for Each Microplastic', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 全成分のEEMを一枚の図にまとめてプロット\n",
    "\n",
    "# --- 事前準備は変更なし ---\n",
    "# (excitation_loadings, emission_loadingsなど)\n",
    "# ---\n",
    "\n",
    "print(\"\\n--- 分離された全成分のEEMを一枚の図にまとめてプロットします ---\")\n",
    "\n",
    "# --- 1. グラフ全体の準備 ---\n",
    "# サブプロットの行数と列数をいい感じに決める (例: 3列で表示)\n",
    "n_cols = 3\n",
    "n_rows = (max_components + n_cols - 1) // n_cols # 切り上げ除算\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4.5 * n_rows))\n",
    "# axesを1次元のリストにして扱いやすくする\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- 2. 各成分についてループし、対応するサブプロットに描画 ---\n",
    "for i in range(max_components):\n",
    "    ax = axes[i] # 対応するサブプロットを選択\n",
    "\n",
    "    # --- 外積を計算して、成分のEEMを再構成 ---\n",
    "    component_eem = np.outer(excitation_loadings[:, i], emission_loadings[:, i])\n",
    "\n",
    "    # --- ヒートマップとしてプロット ---\n",
    "    im = ax.imshow(\n",
    "        component_eem,\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        cmap='viridis',\n",
    "        extent=[em_bands_trimmed[0], em_bands_trimmed[-1], ex_bands_trimmed[0], ex_bands_trimmed[-1]]\n",
    "    )\n",
    "\n",
    "    # --- 仕上げ ---\n",
    "    ax.set_title(f'Component {i+1}')\n",
    "    ax.set_xlabel('Emission (nm)')\n",
    "    ax.set_ylabel('Excitation (nm)')\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "# --- 3. 空のサブプロットを非表示にする ---\n",
    "for j in range(max_components, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "# --- 4. 図全体のレイアウトを調整 ---\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 全サンプルの残差プロット（転置なし・ピーク表示付き）\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 事前準備（最終モデルの計算結果から） ---\n",
    "# tensor: 前処理済みの全サンプルEEMテンソル (励起, 蛍光, サンプル)\n",
    "# weights: PARAFACの計算結果\n",
    "# factors: PARAFACの計算結果 [励起ローディング, 蛍光ローディング, サンプルスコア]\n",
    "# sample_name: サンプル名のリスト\n",
    "# ex_bands_trimmed, em_bands_trimmed: 波長リスト\n",
    "# ---------------------------------------------\n",
    "\n",
    "# 1. PARAFACモデルによる再現テンソルを計算\n",
    "reconstructed_tensor = tl.cp_to_tensor((weights, factors))\n",
    "\n",
    "# 2. 残差テンソルを計算\n",
    "residual_tensor = tensor - reconstructed_tensor\n",
    "\n",
    "print(\"--- 全サンプルの元のEEMと残差EEM（転置なし）をプロットします ---\")\n",
    "\n",
    "# 3. 全てのサンプルについてループ処理\n",
    "for i, sample in enumerate(sample_name):\n",
    "\n",
    "    # 4. 対象サンプルの元のEEMと残差EEMを準備\n",
    "    original_eem = tensor[:, :, i]\n",
    "    residual_eem = residual_tensor[:, :, i]\n",
    "\n",
    "    # 5. 残差EEMのピーク位置を特定\n",
    "    peak_idx_flat = np.argmax(residual_eem)\n",
    "    peak_ex_idx, peak_em_idx = np.unravel_index(peak_idx_flat, residual_eem.shape)\n",
    "    \n",
    "    peak_ex_wl = ex_bands_trimmed[peak_ex_idx]\n",
    "    peak_em_wl = em_bands_trimmed[peak_em_idx]\n",
    "\n",
    "    # 6. プロット作成\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f'Original vs. Residual EEM for: {sample}', fontsize=16)\n",
    "\n",
    "    # --- 元のEEMプロット ---\n",
    "    # ▼▼▼ .T を削除し、extentと軸ラベルを修正 ▼▼▼\n",
    "    im1 = axes[0].imshow(original_eem, origin='lower', aspect='auto', cmap='viridis',\n",
    "                         extent=[em_bands_trimmed[0], em_bands_trimmed[-1], ex_bands_trimmed[0], ex_bands_trimmed[-1]])\n",
    "    axes[0].set_title('Original EEM')\n",
    "    axes[0].set_xlabel('Emission (nm)')\n",
    "    axes[0].set_ylabel('Excitation (nm)')\n",
    "    # ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\n",
    "    fig.colorbar(im1, ax=axes[0], label='Intensity')\n",
    "\n",
    "    # --- 残差EEMプロット ---\n",
    "    # vminとvmaxを元のEEMと合わせてスケールを統一\n",
    "    # ▼▼▼ .T を削除し、extentと軸ラベル、textの位置を修正 ▼▼▼\n",
    "    im2 = axes[1].imshow(residual_eem, origin='lower', aspect='auto', cmap='viridis',\n",
    "                         extent=[em_bands_trimmed[0], em_bands_trimmed[-1], ex_bands_trimmed[0], ex_bands_trimmed[-1]],\n",
    "                         vmin=np.min(original_eem), vmax=np.max(original_eem))\n",
    "    axes[1].set_title('Residual EEM (Model Error)')\n",
    "    axes[1].set_xlabel('Emission (nm)')\n",
    "    \n",
    "    # # ピーク位置に十字線を描画\n",
    "    # axes[1].axhline(y=peak_ex_wl, color='red', linestyle='--', alpha=0.7) # 水平線 (励起)\n",
    "    # axes[1].axvline(x=peak_em_wl, color='red', linestyle='--', alpha=0.7) # 垂直線 (蛍光)\n",
    "    \n",
    "    # # 軸上に波長を表示\n",
    "    # # Y軸（励起）\n",
    "    # axes[1].text(axes[1].get_xlim()[0], peak_ex_wl, f'{peak_ex_wl:.0f} nm ',\n",
    "    #            color='red', ha='right', va='center', weight='bold')\n",
    "    # # X軸（蛍光）\n",
    "    # axes[1].text(peak_em_wl, axes[1].get_ylim()[0], f'\\n{peak_em_wl:.0f} nm',\n",
    "    #            color='red', ha='center', va='top', weight='bold')\n",
    "    # ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\n",
    "\n",
    "    fig.colorbar(im2, ax=axes[1], label='Intensity')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
