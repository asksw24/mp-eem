{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  matplotlib import pyplot as plt\n",
    "import os \n",
    "from pathlib import Path\n",
    "import re\n",
    "import PIL\n",
    "import cv2\n",
    "import seaborn as sns \n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "import spectral_util\n",
    "importlib.reload(spectral_util)\n",
    "from spectral_util import *\n",
    "\n",
    "import fluorescence_util\n",
    "importlib.reload(fluorescence_util)\n",
    "from fluorescence_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'board.xlsx'\n",
    "# 'board_noFlux.xlsx'\n",
    "# 'flux_20240925_184835.xlsx'\n",
    "# 'flux-onBoard.xlsx'\n",
    "# 'lead_noFlux.xlsx'\n",
    "\n",
    "# srcbase = Path(\"./data/EEM_F-7000_2025-04-11/\")\n",
    "print(Path.cwd())\n",
    "srcbase = Path(\"./data/EEM_F-7000_2025-05-29/\")\n",
    "dstdir = Path(\"./dst/eem/filter\")\n",
    "\n",
    "srcdata = [\n",
    "    {\n",
    "        \"path\": fpath,\n",
    "        \"sample\": fpath.stem.split(\"_\")[0],  # 'ABS_20250411' → 'ABS'\n",
    "        \"label\": None\n",
    "    }\n",
    "    for fpath in srcbase.glob(\"*.xlsx\")\n",
    "]\n",
    "srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in srcdata:\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "    print(eem)\n",
    "\n",
    "    plt.figure()\n",
    "    eem.plot_contour(level=100, show_sample_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_bands = eem.em_bands\n",
    "ex_bands = eem.ex_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 散乱光の除去と波長域の調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% EEMデータの読み込みと前処理（散乱除去 & NaN保持）\n",
    "\n",
    "sample_data_processed = []\n",
    "sample_name = []\n",
    "\n",
    "# 波長域を先に定義しておく\n",
    "eem_template = fluorescence_util.EEMF7000(srcdata[0]['path'])\n",
    "ex_bands_full = eem_template.ex_bands\n",
    "em_bands_full = eem_template.em_bands\n",
    "\n",
    "# 250nm以上の波長マスクを作成\n",
    "ex_mask = ex_bands_full >= 250\n",
    "em_mask = em_bands_full >= 250\n",
    "\n",
    "# トリミング後の波長域を保存\n",
    "ex_bands_trimmed = ex_bands_full[ex_mask]\n",
    "em_bands_trimmed = em_bands_full[em_mask]\n",
    "\n",
    "\n",
    "print(\"--- データの前処理を開始します ---\")\n",
    "for data in srcdata:\n",
    "    # EEMデータの読み込み\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "\n",
    "    # ① 散乱ピーク除去（NaNを代入）\n",
    "    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "                                                       remove_first_order=True,\n",
    "                                                       inplace=True)\n",
    "    # ② 追加で散乱領域全体を除去（NaNを代入）\n",
    "    eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "    # 生の行列を取得\n",
    "    eem_matrix = eem.mat\n",
    "\n",
    "    # ③ 波長域をトリミング\n",
    "    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]\n",
    "\n",
    "    # 前処理済みのデータをリストに追加\n",
    "    sample_data_processed.append(eem_matrix_trimmed)\n",
    "    sample_name.append(eem.sample)\n",
    "    print(f\"  - サンプル '{eem.sample}' の前処理が完了しました。\")\n",
    "\n",
    "print(\"--- 全ての前処理が完了しました ---\")\n",
    "\n",
    "# リストを3Dのnumpy配列に変換\n",
    "# この段階ではNaNが含まれている\n",
    "eem_array_processed = np.array(sample_data_processed)\n",
    "\n",
    "print(\"\\n処理後のデータ形状:\", eem_array_processed.shape)\n",
    "print(\"励起波長の数:\", len(ex_bands_trimmed))\n",
    "print(\"蛍光波長の数:\", len(em_bands_trimmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% データの正規化（論文準拠: Unit Norm Scaling）\n",
    "\n",
    "# 正規化済みのデータを格納する新しいリストを作成\n",
    "sample_data_normalized = []\n",
    "\n",
    "print(\"--- データの正規化を開始します（論文準拠）---\")\n",
    "for i, eem_matrix in enumerate(eem_array_processed):\n",
    "    # NaNを無視して、二乗和を計算\n",
    "    sum_of_squares = np.nansum(eem_matrix**2)\n",
    "\n",
    "    # 二乗和が0または非常に小さい場合は、ゼロ除算を避ける\n",
    "    if sum_of_squares > 1e-8:\n",
    "        eem_normalized = eem_matrix / sum_of_squares\n",
    "    else:\n",
    "        # データが全て0やNaNの場合、そのまま（変更なし）\n",
    "        eem_normalized = eem_matrix\n",
    "\n",
    "    sample_data_normalized.append(eem_normalized)\n",
    "    print(f\"  - サンプル '{sample_name[i]}' の正規化が完了しました。\")\n",
    "\n",
    "print(\"--- 全ての正規化が完了しました ---\")\n",
    "\n",
    "# 正規化後のデータを3Dのnumpy配列に変換\n",
    "# この段階でもNaNは保持されています\n",
    "eem_array_normalized = np.array(sample_data_normalized)\n",
    "\n",
    "print(\"\\n正規化後のデータ形状:\", eem_array_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップA: サンプル名とデータの対応を確認\n",
    "\n",
    "print(\"--- サンプル名とデータの対応を確認します ---\")\n",
    "print(f\"合計サンプル数: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # 対応するデータの形状も一緒に表示\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"インデックス {i}: サンプル名 = '{name}', データ形状 = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"上記の順番でデータは並んでいます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップA: サンプル名とデータの対応を確認\n",
    "\n",
    "print(\"--- サンプル名とデータの対応を確認します ---\")\n",
    "print(f\"合計サンプル数: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # 対応するデータの形状も一緒に表示\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"インデックス {i}: サンプル名 = '{name}', データ形状 = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"上記の順番でデータは並んでいます。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 妥当性評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ステップB: 横軸を見やすくしたレバレッジプロット（レイアウト調整版）\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- この部分は変更ありません ---\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "max_components = 7\n",
    "component_range = range(2, max_components + 1)\n",
    "leverage_results = {}\n",
    "for n_comp in component_range:\n",
    "    weights, factors = non_negative_parafac(tensor,\n",
    "                                            rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    sample_scores = factors[2]\n",
    "    try:\n",
    "        q, _ = np.linalg.qr(sample_scores)\n",
    "        leverage = np.sum(q**2, axis=1)\n",
    "        leverage_results[n_comp] = leverage\n",
    "    except np.linalg.LinAlgError:\n",
    "        leverage_results[n_comp] = np.full(tensor.shape[2], np.nan)\n",
    "# --- ここまで変更なし ---\n",
    "\n",
    "\n",
    "# --- 結果の可視化（レイアウト調整版） ---\n",
    "print(\"\\n--- レバレッジをプロットします ---\")\n",
    "\n",
    "# ▼▼▼ グラフ全体のサイズを、より縦長に調整 ▼▼▼\n",
    "fig, axes = plt.subplots(len(component_range), 1, figsize=(12, 5 * len(component_range)), sharex=True)\n",
    "if len(component_range) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, n_comp in enumerate(component_range):\n",
    "    ax = axes[i]\n",
    "    leverage = leverage_results.get(n_comp)\n",
    "    if leverage is not None and not np.isnan(leverage).all():\n",
    "        bars = ax.bar(sample_name, leverage)\n",
    "        ax.set_ylabel(\"Leverage\", fontsize=12)\n",
    "        ax.set_title(f\"Component = {n_comp}\", fontsize=14)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=11)\n",
    "        ax.tick_params(axis='y', labelsize=10) # y軸のラベルサイズも調整\n",
    "\n",
    "        threshold = 2 * n_comp / tensor.shape[2]\n",
    "        ax.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.2f})')\n",
    "        ax.legend()\n",
    "\n",
    "        for bar, name, lev_val in zip(bars, sample_name, leverage):\n",
    "            if lev_val > threshold:\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, lev_val, name,\n",
    "                        ha='center', va='bottom', fontsize=10, color='blue', weight='bold')\n",
    "    else:\n",
    "        ax.set_title(f\"Component = {n_comp} (Calculation Failed)\")\n",
    "\n",
    "plt.xlabel(\"Sample Name\", fontsize=14)\n",
    "\n",
    "# ▼▼▼ 各プロット間の余白をしっかり確保する命令を追加 ▼▼▼\n",
    "# pad=3.0 で、各グラフの周囲に十分なスペースを確保します\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## core consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% コアコンシステンシーの手動計算とプロット\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "\n",
    "# --- 事前準備（これまでのステップで準備した変数） ---\n",
    "# eem_array_normalized: 正規化済みでNaNを含むデータ配列\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNを0で埋めた正規化済みデータ\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# テンソルに変換 (励起, 蛍光, サンプル)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "\n",
    "# 試行する成分数の範囲\n",
    "max_components = 7\n",
    "component_range = range(1, max_components + 1)\n",
    "\n",
    "\n",
    "print(\"--- コアコンシステンシーの計算を開始します (手動計算) ---\")\n",
    "core_consistencies = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"  - 成分数 = {n_comp} でモデルを構築中...\")\n",
    "    weights, factors = non_negative_parafac(tensor, rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    \n",
    "    # --- コアコンシステンシーの手動計算 ---\n",
    "    # 1. ローディング行列から、擬似逆行列を計算\n",
    "    pseudo_inverses = [np.linalg.pinv(f) for f in factors]\n",
    "    \n",
    "    # 2. 現実のコアテンソル（G）を計算\n",
    "    # G = X * (A^-1, B^-1, C^-1)\n",
    "    core_tensor_G = multi_mode_dot(tensor, pseudo_inverses, modes=[0, 1, 2])\n",
    "\n",
    "    # 3. 理想のコアテンソル（T）を作成（対角成分が1、他が0）\n",
    "    ideal_core_T = tl.zeros_like(core_tensor_G)\n",
    "    for i in range(n_comp):\n",
    "        ideal_core_T[i, i, i] = 1\n",
    "        \n",
    "    # 4. コアテンソルGの全要素の二乗和 (ssq_G) を計算\n",
    "    ssq_G = tl.sum(core_tensor_G**2)\n",
    "    \n",
    "    # 5. GとTの差の二乗和 (ssq_diff) を計算\n",
    "    ssq_diff = tl.sum((core_tensor_G - ideal_core_T)**2)\n",
    "    \n",
    "    # 6. コアコンシステンシーを計算\n",
    "    # 100 * (1 - (GとTの差の二乗和) / (Gの全要素の二乗和))\n",
    "    if ssq_G > 1e-8: # ゼロ除算を避ける\n",
    "        cc = (1 - (ssq_diff / ssq_G)) * 100\n",
    "    else:\n",
    "        cc = 0\n",
    "        \n",
    "    core_consistencies.append(cc)\n",
    "    print(f\"  - 成分数 = {n_comp} のコアコンシステンシー: {cc:.1f}%\")\n",
    "\n",
    "print(\"--- 計算が完了しました ---\")\n",
    "\n",
    "# --- 結果のプロット ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, core_consistencies, 'o-', color='b', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Core Consistency (%)\", fontsize=12)\n",
    "plt.title(\"Core Consistency Diagnostic\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 60%のラインに補助線を追加\n",
    "plt.axhline(y=60, color='r', linestyle='--', label='60% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(-5, 105) # 負の値も表示できるように調整\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% スプリットハーフ分析\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 事前準備（これまでのステップで準備した変数） ---\n",
    "# eem_array_normalized: 正規化済みでNaNを含むデータ配列\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNを0で埋めた正規化済みデータ\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# テンソルに変換 (励起, 蛍光, サンプル)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "num_samples = tensor.shape[2]\n",
    "\n",
    "\n",
    "# 試行する成分数の範囲\n",
    "max_components = 7\n",
    "component_range = range(2, max_components + 1)\n",
    "\n",
    "print(\"--- スプリットハーフ分析を開始します ---\")\n",
    "similarity_scores = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"\\n--- 成分数 = {n_comp} で分析中... ---\")\n",
    "    \n",
    "    # 1. データセットをランダムに半分に分割\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    half1_indices = indices[:num_samples // 2]\n",
    "    half2_indices = indices[num_samples // 2:]\n",
    "    \n",
    "    tensor_half1 = tl.tensor(tensor[:, :, half1_indices])\n",
    "    tensor_half2 = tl.tensor(tensor[:, :, half2_indices])\n",
    "    \n",
    "    # 2. それぞれの半分でPARAFACを実行\n",
    "    _, factors1 = non_negative_parafac(tensor_half1, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    _, factors2 = non_negative_parafac(tensor_half2, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    \n",
    "    # 3. ローディングを比較\n",
    "    excitation_loadings1, emission_loadings1, _ = factors1\n",
    "    excitation_loadings2, emission_loadings2, _ = factors2\n",
    "    \n",
    "    # 類似度を計算 (最適なペアを見つけてマッチング)\n",
    "    total_similarity = 0\n",
    "    matched_indices2 = []\n",
    "    \n",
    "    for i in range(n_comp):\n",
    "        best_match_idx = -1\n",
    "        max_corr = -1\n",
    "        for j in range(n_comp):\n",
    "            if j in matched_indices2:\n",
    "                continue\n",
    "            corr_ex, _ = pearsonr(excitation_loadings1[:, i], excitation_loadings2[:, j])\n",
    "            corr_em, _ = pearsonr(emission_loadings1[:, i], emission_loadings2[:, j])\n",
    "            avg_corr = (corr_ex + corr_em) / 2\n",
    "            \n",
    "            if avg_corr > max_corr:\n",
    "                max_corr = avg_corr\n",
    "                best_match_idx = j\n",
    "        \n",
    "        total_similarity += max_corr\n",
    "        matched_indices2.append(best_match_idx)\n",
    "        \n",
    "    avg_similarity = total_similarity / n_comp\n",
    "    similarity_scores.append(avg_similarity * 100) # パーセントに変換\n",
    "    print(f\"  - 成分数 = {n_comp} の平均類似度: {avg_similarity*100:.1f}%\")\n",
    "\n",
    "print(\"--- 分析が完了しました ---\")\n",
    "\n",
    "# --- 結果のプロット ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, similarity_scores, 'o-', color='g', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Split-Half Similarity (%)\", fontsize=12)\n",
    "plt.title(\"Split-Half Analysis\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 95%のラインに補助線を追加\n",
    "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(0, 105)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 最終モデルの可視化（正規化＋ピーク表示改良版）\n",
    "\n",
    "# --- 事前準備は変更なし ---\n",
    "# (excitation_loadings, emission_loadings, sample_scores など)\n",
    "# ---\n",
    "\n",
    "print(\"\\n--- 抽出された成分のスペクトルをプロットします（ピーク表示改良版） ---\")\n",
    "\n",
    "# 各成分についてループ\n",
    "for i in range(OPTIMAL_COMPONENTS):\n",
    "    # --- 1. グラフの準備 ---\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- 2. スペクトルのプロット (正規化されたローディングを使用) ---\n",
    "    color1 = 'tab:blue'\n",
    "    ax1.plot(ex_bands_trimmed, excitation_loadings_norm[:, i], color=color1, lw=2.5)\n",
    "    ax1.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax1.set_ylabel('Ex loading (normalized)', color=color1, fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    color2 = 'tab:red'\n",
    "    ax2.plot(em_bands_trimmed, emission_loadings_norm[:, i], color=color2, lw=2.5)\n",
    "    ax2.set_ylabel('Em loading (normalized)', color=color2, fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # --- 3. ピーク波長の検出と描画（表示方法を改良） ---\n",
    "    # 励起ピーク\n",
    "    ex_peak_idx = np.argmax(excitation_loadings_norm[:, i])\n",
    "    ex_peak_wl = ex_bands_trimmed[ex_peak_idx]\n",
    "    ax1.axvline(x=ex_peak_wl, color=color1, linestyle='--', alpha=0.8)\n",
    "    # ▼▼▼ テキストを縦書きにし、位置を調整 ▼▼▼\n",
    "    ax1.text(ex_peak_wl - 3, ax1.get_ylim()[1] * 0.5, f'{ex_peak_wl:.0f} nm',\n",
    "             color=color1, rotation='vertical', ha='right', va='center', fontsize=11)\n",
    "\n",
    "    # 蛍光ピーク\n",
    "    em_peak_idx = np.argmax(emission_loadings_norm[:, i])\n",
    "    em_peak_wl = em_bands_trimmed[em_peak_idx]\n",
    "    ax2.axvline(x=em_peak_wl, color=color2, linestyle='--', alpha=0.8)\n",
    "    # ▼▼▼ テキストを縦書きにし、位置を調整 ▼▼▼\n",
    "    ax2.text(em_peak_wl + 3, ax2.get_ylim()[1] * 0.5, f'{em_peak_wl:.0f} nm',\n",
    "             color=color2, rotation='vertical', ha='left', va='center', fontsize=11)\n",
    "\n",
    "    # --- 4. 仕上げ ---\n",
    "    ax1.set_title(f'Component {i+1}', fontsize=14)\n",
    "    # Y軸の範囲を0からに固定して見やすくする\n",
    "    ax1.set_ylim(bottom=0)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. サンプルスコア（各MPの成分含有量）のプロット\n",
    "print(\"\\n--- 各MPの成分含有量をプロットします ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "# ヒートマップで可視化\n",
    "plt.imshow(sample_scores_norm.T, cmap='viridis', aspect='auto')\n",
    "plt.yticks(ticks=np.arange(OPTIMAL_COMPONENTS), labels=[f'Component {i+1}' for i in range(OPTIMAL_COMPONENTS)])\n",
    "plt.xticks(ticks=np.arange(len(sample_name)), labels=sample_name, rotation=45, ha='right')\n",
    "plt.colorbar(label='Relative Concentration (normalized)')\n",
    "plt.title('Component Scores for Each Microplastic', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 各成分のEEMをプロット\n",
    "\n",
    "# --- 事前準備（最終モデルの計算結果から） ---\n",
    "# excitation_loadings: 励起ローディング\n",
    "# emission_loadings: 蛍光ローディング\n",
    "# ex_bands_trimmed: 励起波長のリスト\n",
    "# em_bands_trimmed: 蛍光波長のリスト\n",
    "# OPTIMAL_COMPONENTS: 最適な成分数\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"\\n--- 分離された各成分のEEMをプロットします ---\")\n",
    "\n",
    "# 各成分についてループ\n",
    "for i in range(OPTIMAL_COMPONENTS):\n",
    "    # --- 1. 外積を計算して、成分のEEMを再構成 ---\n",
    "    # np.outer() で2つのベクトルから2次元の行列を作成\n",
    "    component_eem = np.outer(excitation_loadings[:, i], emission_loadings[:, i])\n",
    "\n",
    "    # --- 2. グラフの準備 ---\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "    # --- 3. ヒートマップとしてプロット ---\n",
    "    im = ax.imshow(\n",
    "        component_eem,  \n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        cmap='viridis',\n",
    "        extent=[ex_bands_trimmed[0], ex_bands_trimmed[-1], em_bands_trimmed[0], em_bands_trimmed[-1]]\n",
    "    )\n",
    "\n",
    "    # --- 4. 仕上げ ---\n",
    "    ax.set_title(f'Reconstructed EEM for Component {i+1}', fontsize=14)\n",
    "    ax.set_xlabel('Excitation Wavelength (nm)', fontsize=12)\n",
    "    ax.set_ylabel('Emission Wavelength (nm)', fontsize=12)\n",
    "    fig.colorbar(im, ax=ax, label='Relative Intensity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in srcdata:\n",
    "#     eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "#     print(eem)\n",
    "\n",
    "#     plt.figure()\n",
    "\n",
    "#     # ① 散乱ピーク除去\n",
    "#     eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "#                                                        remove_first_order=True, \n",
    "#                                                        inplace=True)\n",
    "\n",
    "#     # ② 追加で散乱領域全体を除去\n",
    "#     eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "#     eem.plot_heatmap()\n",
    "#     plt.title(eem.sample)\n",
    "\n",
    "sample_data = []\n",
    "sample_name = []\n",
    "\n",
    "for data in srcdata:\n",
    "\n",
    "    # EEMデータの読み込み\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "    print(eem)\n",
    "\n",
    "    # ①散乱ピーク除去\n",
    "    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "                                                       remove_first_order=True,\n",
    "                                                        inplace=True)\n",
    "    # ② 追加で散乱領域全体を除去\n",
    "    eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "    # 250nm以上のインデックスを取得\n",
    "    ex_mask = ex_bands >= 250\n",
    "    em_mask = em_bands >= 250\n",
    "\n",
    "    eem_matrix = eem.mat  # numpy配列を取り出す\n",
    "\n",
    "    # eem_matrix = np.nan_to_num(eem.mat, nan=0.0)\n",
    "    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]\n",
    "\n",
    "    sample_data.append(eem_matrix_trimmed)\n",
    "    sample_name.append(eem.sample)\n",
    "\n",
    "    # eem.plot_heatmap()\n",
    "    # plt.title(eem.sample)\n",
    "\n",
    "# numpy配列に保存\n",
    "eem_array = np.array(sample_data)\n",
    "print(eem_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 波長域の調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_mask = np.array(ex_bands) >= 250\n",
    "em_mask = np.array(em_bands) >= 250\n",
    "\n",
    "# trim\n",
    "ex_bands = np.array(ex_bands)[ex_mask]\n",
    "em_bands = np.array(em_bands)[em_mask]\n",
    "\n",
    "print(\"Excitation bands ≥ 250nm:\", ex_bands)\n",
    "print(\"Emission bands ≥ 250nm:\", em_bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ノイズありサンプルの生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各MPごとに生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_eem_per_mp_with_scatter_removal(eem_array, ex_bands, em_bands, n_variants=20, noise_level=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    ノイズ付きEEMを生成し、散乱領域を0にして除去する。\n",
    "\n",
    "    Parameters:\n",
    "        eem_array: np.ndarray\n",
    "            入力EEM配列。shape = (num_MP, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            励起波長リスト（shape = n_ex）\n",
    "        em_bands: np.ndarray\n",
    "            蛍光波長リスト（shape = n_em）\n",
    "        n_variants: int\n",
    "            各MPごとに生成するノイズ付きEEMの数\n",
    "        noise_level: float\n",
    "            ノイズのスケール（最大値に対する割合）\n",
    "        seed: int or None\n",
    "            乱数シード\n",
    "\n",
    "    Returns:\n",
    "        augmented_eems: np.ndarray\n",
    "            shape = (num_MP, n_variants, n_ex, n_em)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    num_MP, n_ex, n_em = eem_array.shape\n",
    "    augmented_eems = np.zeros((num_MP, n_variants, n_ex, n_em))\n",
    "\n",
    "    # 散乱領域マスク（True: 有効領域, False: 散乱 → 0にする）\n",
    "    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')\n",
    "    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)\n",
    "\n",
    "    for i in range(num_MP):\n",
    "        base_eem = eem_array[i]\n",
    "        for j in range(n_variants):\n",
    "            noise = np.random.normal(loc=0, scale=noise_level * np.max(base_eem), size=base_eem.shape)\n",
    "            noisy_eem = np.clip(base_eem + noise, 0, None)\n",
    "            noisy_eem[~valid_mask] = 0  # 散乱領域を0に\n",
    "            augmented_eems[i, j] = noisy_eem\n",
    "\n",
    "    return augmented_eems\n",
    "# ex_bands, em_bands は np.array で定義されていると仮定\n",
    "augmented_eems = augment_eem_per_mp_with_scatter_removal(\n",
    "    eem_array,\n",
    "    ex_bands=ex_bands,\n",
    "    em_bands=em_bands,\n",
    "    n_variants=50,\n",
    "    noise_level=0,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=None):\n",
    "    \"\"\"\n",
    "    各MPから1つずつノイズ付きEEMを、個別にプロット（励起：横軸、放射：縦軸）。\n",
    "\n",
    "    Parameters:\n",
    "        augmented_eems: np.ndarray\n",
    "            shape = (num_MP, n_variants, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            励起波長リスト（横軸）\n",
    "        em_bands: np.ndarray\n",
    "            発光波長リスト（縦軸）\n",
    "        sample_names: list or None\n",
    "            MPごとの名前リスト（任意）\n",
    "    \"\"\"\n",
    "    num_MP = augmented_eems.shape[0]\n",
    "\n",
    "    for mp_idx in range(num_MP):\n",
    "        eem = augmented_eems[mp_idx, 0]  # 各MPで最初のノイズバージョンを表示\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.imshow(eem, origin='lower',\n",
    "                   extent=[ex_bands[0], ex_bands[-1], em_bands[0], em_bands[-1]],\n",
    "                   aspect='auto', cmap='viridis')\n",
    "\n",
    "        plt.xlabel('Excitation (nm)')\n",
    "        plt.ylabel('Emission (nm)')\n",
    "        title = sample_names[mp_idx] if sample_names else f'MP {mp_idx}'\n",
    "        plt.title(f'Augmented EEM - {title}')\n",
    "        plt.colorbar(label='Intensity')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=sample_name)\n",
    "# plot_augmented_eems_one_by_one(combined_augmented_eems, ex_bands, em_bands, sample_names=sample_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPのEEMを合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_eem_with_noise(\n",
    "    eem_array, ex_bands, em_bands,\n",
    "    n_variants=20, noise_level=0.05, seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    全MPのEEMを合成して、ノイズ付きのEEMを生成（散乱領域除去つき）\n",
    "\n",
    "    Parameters:\n",
    "        eem_array: np.ndarray\n",
    "            shape = (num_MP, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            励起波長リスト（shape = n_ex）\n",
    "        em_bands: np.ndarray\n",
    "            放射波長リスト（shape = n_em）\n",
    "        n_variants: int\n",
    "            生成するバリエーション数\n",
    "        noise_level: float\n",
    "            ノイズのスケール（合成EEMの最大値に対する割合）\n",
    "        seed: int or None\n",
    "            乱数シード\n",
    "\n",
    "    Returns:\n",
    "        combined_eems: np.ndarray\n",
    "            shape = (n_variants, n_ex, n_em)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # --- 合成EEM（すべてのMPの和）\n",
    "    combined_base = np.sum(eem_array, axis=0)  # shape = (n_ex, n_em)\n",
    "\n",
    "    # --- 散乱領域マスクを作成\n",
    "    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')\n",
    "    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)\n",
    "\n",
    "    # --- ノイズ付きEEMの生成\n",
    "    combined_eems = np.zeros((n_variants, *combined_base.shape))\n",
    "    for i in range(n_variants):\n",
    "        noise = np.random.normal(loc=0, scale=noise_level * np.max(combined_base), size=combined_base.shape)\n",
    "        noisy_eem = np.clip(combined_base + noise, 0, None)\n",
    "        noisy_eem[~valid_mask] = 0  # 散乱領域をゼロに\n",
    "        combined_eems[i] = noisy_eem\n",
    "\n",
    "    return combined_eems\n",
    "\n",
    "combined_augmented_eems = generate_combined_eem_with_noise(\n",
    "    eem_array,\n",
    "    ex_bands=ex_bands,\n",
    "    em_bands=em_bands,\n",
    "    n_variants=50,\n",
    "    noise_level=0.05,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "\n",
    "# 1枚目を取得\n",
    "eem_sample = combined_augmented_eems[0]\n",
    "\n",
    "# プロット\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(\n",
    "    eem_sample,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=[em_bands.min(), em_bands.max(), ex_bands.min(), ex_bands.max()],\n",
    "    cmap='viridis'\n",
    ")\n",
    "plt.colorbar(label='Fluorescence Intensity')\n",
    "plt.xlabel('Emission Wavelength (nm)')\n",
    "plt.ylabel('Excitation Wavelength (nm)')\n",
    "plt.title('Combined EEM Sample #1')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAFAC，Core Consistency，Split half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from scipy.stats import pearsonr\n",
    "from corcondia import corcondia_3d\n",
    "\n",
    "tl.set_backend('numpy')\n",
    "\n",
    "# --- PARAFAC結果をすべて保存する関数 ---\n",
    "def compute_parafac_results(eem_tensor, max_components):\n",
    "    results = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        factors = parafac(eem_tensor, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "        results.append(factors)\n",
    "    return results\n",
    "\n",
    "# --- Core Consistency Diagnostic (正式版 CORCONDIA)\n",
    "def compute_core_consistency_corcondia(tensor, max_components=7):\n",
    "    cc_list = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        cc = corcondia_3d(tensor, k=r)\n",
    "        cc_list.append(cc)\n",
    "    return cc_list\n",
    "\n",
    "# --- Split-Half 類似度の一括計算（各ランクで別々に分割＋分解）\n",
    "def compute_split_half_similarities(tensor, max_components):\n",
    "    sim_list = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        all_idx = np.arange(tensor.shape[2])\n",
    "        np.random.shuffle(all_idx)\n",
    "        half1 = tensor[:, :, all_idx[:tensor.shape[2] // 2]]\n",
    "        half2 = tensor[:, :, all_idx[tensor.shape[2] // 2:]]\n",
    "\n",
    "        f1 = parafac(half1, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "        f2 = parafac(half2, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "\n",
    "        ex1, em1, _ = f1.factors\n",
    "        ex2, em2, _ = f2.factors\n",
    "\n",
    "        sim_total = 0\n",
    "        for i in range(r):\n",
    "            r_ex, _ = pearsonr(ex1[:, i], ex2[:, i])\n",
    "            r_em, _ = pearsonr(em1[:, i], em2[:, i])\n",
    "            sim_total += (r_ex + r_em) / 2\n",
    "        sim_list.append(sim_total / r)\n",
    "    return sim_list\n",
    "\n",
    "# --- 各MPに対して Core Consistency（CORCONDIA）と Split-Half 類似度を計算 ---\n",
    "cc_dict = {}\n",
    "sh_dict = {}\n",
    "factors_dict = {}\n",
    "\n",
    "for idx, eem_tensor in enumerate(augmented_eems):\n",
    "    sample = sample_name[idx]\n",
    "    print(f\"\\n🔍【{sample}】の Core Consistency / Split-Half 計算中...\")\n",
    "\n",
    "    tensor = np.transpose(eem_tensor, (1, 2, 0))  # (exc, em, sample)\n",
    "    factors_dict[sample] = compute_parafac_results(tensor, max_components=7)\n",
    "\n",
    "    # 正式な Core Consistency 計算（CORCONDIA）\n",
    "    cc_dict[sample] = compute_core_consistency_corcondia(tensor, max_components=7)\n",
    "\n",
    "    # Split-Half 類似度\n",
    "    sh_dict[sample] = compute_split_half_similarities(tensor, max_components=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=\"Sample\", start_rank=1):\n",
    "    \"\"\"\n",
    "    Core ConsistencyとSplit-Half類似度を同時にプロットする関数\n",
    "\n",
    "    Parameters:\n",
    "        cc_list: list of float（Core Consistency, 各成分数に対応）\n",
    "        sh_list: list of float（Split-Half 類似度, 各成分数に対応）\n",
    "        sample_label: str（プロットタイトル用）\n",
    "        start_rank: int（通常は1, cc_list[0]がrank=1のとき）\n",
    "    \"\"\"\n",
    "    ranks = list(range(start_rank, start_rank + len(cc_list)))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(7, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax1.plot(ranks, cc_list, 'o-', color='tab:blue', label='Core Consistency')\n",
    "    ax2.plot(ranks, sh_list, 's--', color='tab:red', label='Split-Half Similarity')\n",
    "\n",
    "    ax1.set_xlabel(\"Component Rank\")\n",
    "    ax1.set_ylabel(\"Core Consistency (%)\", color='tab:blue')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax2.set_ylabel(\"Similarity(%)\", color='tab:red')\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    ax1.set_title(f\"{sample_label}: Core Consistency & Split-Half Similarity\")\n",
    "\n",
    "    # 凡例の設定\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# for sample in sample_name:\n",
    "#     plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)\n",
    "for sample in sample_name:\n",
    "    cc_list = cc_dict.get(sample)\n",
    "    sh_list = sh_dict.get(sample)\n",
    "    if cc_list is not None and sh_list is not None:\n",
    "        plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)\n",
    "    else:\n",
    "        print(f\"{sample} の解析結果が見つかりません。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンポーネントの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def plot_eem_with_bandpass_box(eem, ex_bands, em_bands,\n",
    "                                excitation_loading, emission_loading,\n",
    "                                rank, band_width=20, sample_label=\"MP\"):\n",
    "    \"\"\"\n",
    "    ノイズ付きEEM上に、指定コンポーネントのバンドパス波長範囲を紫の四角で重ねて表示\n",
    "\n",
    "    Parameters:\n",
    "        eem: 2D array (ex × em)\n",
    "        ex_bands: 1D array\n",
    "        em_bands: 1D array\n",
    "        excitation_loading: 2D array (ex, rank)\n",
    "        emission_loading: 2D array (em, rank)\n",
    "        component_idx: int（何番目のコンポーネントか、0始まり）\n",
    "        band_width: float（±何nmで範囲を取るか）\n",
    "        sample_label: str\n",
    "    \"\"\"\n",
    "\n",
    "    # EEMをプロット\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(eem, origin='lower',\n",
    "                   extent=[em_bands[0], em_bands[-1],\n",
    "                           ex_bands[0], ex_bands[-1]],\n",
    "                   aspect='auto', cmap='viridis')\n",
    "    \n",
    "    for i in range(rank):\n",
    "        # ピーク波長をローディングから抽出\n",
    "        exc_idx = np.argmax(excitation_loading[:, i])\n",
    "        em_idx = np.argmax(emission_loading[:, i])\n",
    "        exc_peak = ex_bands[exc_idx]\n",
    "        em_peak = em_bands[em_idx]\n",
    "\n",
    "        # 四角の範囲（±band_width）\n",
    "        exc_min = exc_peak - band_width\n",
    "        exc_max = exc_peak + band_width\n",
    "        em_min = em_peak - band_width\n",
    "        em_max = em_peak + band_width\n",
    "\n",
    "        # # ローディング\n",
    "        # exc = excitation_loading[:, i]\n",
    "        # em = emission_loading[:, i]\n",
    "\n",
    "        # # ピーク位置（最大値）インデックス → 波長\n",
    "        # exc_idx = np.argmax(exc)\n",
    "        # em_idx = np.argmax(em)\n",
    "        # exc_peak = ex_bands[exc_idx]\n",
    "        # em_peak = em_bands[em_idx]\n",
    "\n",
    "        # # 🎯 励起ローディングの標準偏差を使って band_width を決める\n",
    "        # # 重み付き平均と分散（中心波長±幅）\n",
    "        # exc_mean = np.sum(ex_bands * exc) / np.sum(exc)\n",
    "        # exc_var = np.sum(((ex_bands - exc_mean) ** 2) * exc) / np.sum(exc)\n",
    "        # band_width = np.sqrt(exc_var)   # 標準偏差\n",
    "\n",
    "        # # 四角の範囲（±1σ程度）\n",
    "        # exc_min = exc_peak - band_width\n",
    "        # exc_max = exc_peak + band_width\n",
    "        # em_min = em_peak - band_width\n",
    "        # em_max = em_peak + band_width\n",
    "\n",
    "        # 🔴 赤い横線で Excitation peak を示す  \n",
    "        ax.hlines(y=exc_peak, xmin=em_bands[0], xmax=em_bands[-1], colors='red', linestyles='dashed', linewidth=1.5)\n",
    "\n",
    "        # # ⬅ ラベルを左に表示（x=最小放射波長 - 少し左にオフセット）\n",
    "        # ax.text(em_bands[0] - 10, exc_peak, f\"Ex = {exc_peak} nm\",\n",
    "        #         color='red', fontsize=10, va='center', ha='right')\n",
    "\n",
    "        print(f\"Loading_{i+1} peak ex_band: {exc_peak}\")\n",
    "        print(f\"Loading_{i+1} peak em_band: {em_peak}\")\n",
    "        \n",
    "        # 紫の四角を重ねる\n",
    "        rect = patches.Rectangle(\n",
    "            (em_min, exc_min),  # 左下角 (x, y)\n",
    "            em_max - em_min,    # 幅\n",
    "            exc_max - exc_min,  # 高さ\n",
    "            linewidth=2,\n",
    "            edgecolor='white',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_title(f\"{sample_label} - EEM with Bandpass Box (Component {rank})\")\n",
    "        ax.set_xlabel(\"Emission Wavelength (nm)\")\n",
    "        ax.set_ylabel(\"Excitation Wavelength (nm)\")\n",
    "        plt.tight_layout()\n",
    "    plt.colorbar(im, ax=ax, label=\"Fluorescence Intensity\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_selected_loadings(factors, rank, ex_bands, em_bands, sample_label=\"Sample\"):\n",
    "    \"\"\"\n",
    "    指定したrankのPARAFAC結果を使って、励起と発光のローディングをプロット\n",
    "\n",
    "    Parameters:\n",
    "        results: list of parafac results（compute_parafac_results()の出力）\n",
    "        rank: int（表示したいコンポーネント数）\n",
    "        ex_bands: 1D array（励起波長）\n",
    "        em_bands: 1D array（発光波長）\n",
    "        sample_label: str（MPの名前など）\n",
    "    \"\"\"\n",
    "    factors_rank = factors[rank - 1]  # インデックス注意：rank=1 → results[0]\n",
    "    excitation_loading, emission_loading, _ = factors_rank.factors\n",
    "\n",
    "    # --- 励起ローディング ---\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(rank):\n",
    "        plt.plot(ex_bands, excitation_loading[:, i], label=f\"Component {i+1}\")\n",
    "    plt.title(f\"{sample_label} - Excitation Loading (Rank {rank})\")\n",
    "    plt.xlabel(\"Excitation Wavelength (nm)\")\n",
    "    plt.ylabel(\"Loading Strength\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 発光ローディング ---\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(rank):\n",
    "        plt.plot(em_bands, emission_loading[:, i], label=f\"Component {i+1}\")\n",
    "    plt.title(f\"{sample_label} - Emission Loading (Rank {rank})\")\n",
    "    plt.xlabel(\"Emission Wavelength (nm)\")\n",
    "    plt.ylabel(\"Loading Strength\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ローディングの帯域図示化\n",
    "    plot_eem_with_bandpass_box(eem, ex_bands, em_bands,\n",
    "                            excitation_loading, emission_loading,\n",
    "                            rank, band_width=20, sample_label=sample\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"ABS\"\n",
    "rank = 1\n",
    "factors = factors_dict.get(sample)\n",
    "\n",
    "mp_idx = sample_name.index(sample)  # \"PET\" に対応するインデックス（例：0）\n",
    "eem = augmented_eems[mp_idx, 0]  # PETの最初のノイズ付きEEM（shape: 81x81）\n",
    "\n",
    "\n",
    "if factors is not None:\n",
    "    plot_selected_loadings(\n",
    "        factors, \n",
    "        rank,\n",
    "        ex_bands,\n",
    "        em_bands,\n",
    "        sample_label=sample\n",
    "    )\n",
    "else:\n",
    "    print(f\"{sample} の解析結果が見つかりません。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
