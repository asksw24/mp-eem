{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  matplotlib import pyplot as plt\n",
    "import os \n",
    "from pathlib import Path\n",
    "import re\n",
    "import PIL\n",
    "import cv2\n",
    "import seaborn as sns \n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "import spectral_util\n",
    "importlib.reload(spectral_util)\n",
    "from spectral_util import *\n",
    "\n",
    "import fluorescence_util\n",
    "importlib.reload(fluorescence_util)\n",
    "from fluorescence_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'board.xlsx'\n",
    "# 'board_noFlux.xlsx'\n",
    "# 'flux_20240925_184835.xlsx'\n",
    "# 'flux-onBoard.xlsx'\n",
    "# 'lead_noFlux.xlsx'\n",
    "\n",
    "# srcbase = Path(\"./data/EEM_F-7000_2025-04-11/\")\n",
    "print(Path.cwd())\n",
    "srcbase = Path(\"./data/EEM_F-7000_2025-05-29/\")\n",
    "dstdir = Path(\"./dst/eem/filter\")\n",
    "\n",
    "srcdata = [\n",
    "    {\n",
    "        \"path\": fpath,\n",
    "        \"sample\": fpath.stem.split(\"_\")[0],  # 'ABS_20250411' â†’ 'ABS'\n",
    "        \"label\": None\n",
    "    }\n",
    "    for fpath in srcbase.glob(\"*.xlsx\")\n",
    "]\n",
    "srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in srcdata:\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "    print(eem)\n",
    "\n",
    "    plt.figure()\n",
    "    eem.plot_contour(level=100, show_sample_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_bands = eem.em_bands\n",
    "ex_bands = eem.ex_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ•£ä¹±å…‰ã®é™¤åŽ»ã¨æ³¢é•·åŸŸã®èª¿æ•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆæ•£ä¹±é™¤åŽ» & NaNä¿æŒï¼‰\n",
    "\n",
    "sample_data_processed = []\n",
    "sample_name = []\n",
    "\n",
    "# æ³¢é•·åŸŸã‚’å…ˆã«å®šç¾©ã—ã¦ãŠã\n",
    "eem_template = fluorescence_util.EEMF7000(srcdata[0]['path'])\n",
    "ex_bands_full = eem_template.ex_bands\n",
    "em_bands_full = eem_template.em_bands\n",
    "\n",
    "# 250nmä»¥ä¸Šã®æ³¢é•·ãƒžã‚¹ã‚¯ã‚’ä½œæˆ\n",
    "ex_mask = ex_bands_full >= 250\n",
    "em_mask = em_bands_full >= 250\n",
    "\n",
    "# ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ³¢é•·åŸŸã‚’ä¿å­˜\n",
    "ex_bands_trimmed = ex_bands_full[ex_mask]\n",
    "em_bands_trimmed = em_bands_full[em_mask]\n",
    "\n",
    "\n",
    "print(\"--- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ ---\")\n",
    "for data in srcdata:\n",
    "    # EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "\n",
    "    # â‘  æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»ï¼ˆNaNã‚’ä»£å…¥ï¼‰\n",
    "    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "                                                       remove_first_order=True,\n",
    "                                                       inplace=True)\n",
    "    # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»ï¼ˆNaNã‚’ä»£å…¥ï¼‰\n",
    "    eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "    # ç”Ÿã®è¡Œåˆ—ã‚’å–å¾—\n",
    "    eem_matrix = eem.mat\n",
    "\n",
    "    # â‘¢ æ³¢é•·åŸŸã‚’ãƒˆãƒªãƒŸãƒ³ã‚°\n",
    "    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]\n",
    "\n",
    "    # å‰å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ \n",
    "    sample_data_processed.append(eem_matrix_trimmed)\n",
    "    sample_name.append(eem.sample)\n",
    "    print(f\"  - ã‚µãƒ³ãƒ—ãƒ« '{eem.sample}' ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "print(\"--- å…¨ã¦ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---\")\n",
    "\n",
    "# ãƒªã‚¹ãƒˆã‚’3Dã®numpyé…åˆ—ã«å¤‰æ›\n",
    "# ã“ã®æ®µéšŽã§ã¯NaNãŒå«ã¾ã‚Œã¦ã„ã‚‹\n",
    "eem_array_processed = np.array(sample_data_processed)\n",
    "\n",
    "print(\"\\nå‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:\", eem_array_processed.shape)\n",
    "print(\"åŠ±èµ·æ³¢é•·ã®æ•°:\", len(ex_bands_trimmed))\n",
    "print(\"è›å…‰æ³¢é•·ã®æ•°:\", len(em_bands_trimmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­£è¦åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ï¼ˆè«–æ–‡æº–æ‹ : Unit Norm Scalingï¼‰\n",
    "\n",
    "# æ­£è¦åŒ–æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "sample_data_normalized = []\n",
    "\n",
    "print(\"--- ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆè«–æ–‡æº–æ‹ ï¼‰---\")\n",
    "for i, eem_matrix in enumerate(eem_array_processed):\n",
    "    # NaNã‚’ç„¡è¦–ã—ã¦ã€äºŒä¹—å’Œã‚’è¨ˆç®—\n",
    "    sum_of_squares = np.nansum(eem_matrix**2)\n",
    "\n",
    "    # äºŒä¹—å’ŒãŒ0ã¾ãŸã¯éžå¸¸ã«å°ã•ã„å ´åˆã¯ã€ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹\n",
    "    if sum_of_squares > 1e-8:\n",
    "        eem_normalized = eem_matrix / sum_of_squares\n",
    "    else:\n",
    "        # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦0ã‚„NaNã®å ´åˆã€ãã®ã¾ã¾ï¼ˆå¤‰æ›´ãªã—ï¼‰\n",
    "        eem_normalized = eem_matrix\n",
    "\n",
    "    sample_data_normalized.append(eem_normalized)\n",
    "    print(f\"  - ã‚µãƒ³ãƒ—ãƒ« '{sample_name[i]}' ã®æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "print(\"--- å…¨ã¦ã®æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ ---\")\n",
    "\n",
    "# æ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’3Dã®numpyé…åˆ—ã«å¤‰æ›\n",
    "# ã“ã®æ®µéšŽã§ã‚‚NaNã¯ä¿æŒã•ã‚Œã¦ã„ã¾ã™\n",
    "eem_array_normalized = np.array(sample_data_normalized)\n",
    "\n",
    "print(\"\\næ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:\", eem_array_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ã‚¹ãƒ†ãƒƒãƒ—A: ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèª\n",
    "\n",
    "print(\"--- ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèªã—ã¾ã™ ---\")\n",
    "print(f\"åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚‚ä¸€ç·’ã«è¡¨ç¤º\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i}: ã‚µãƒ³ãƒ—ãƒ«å = '{name}', ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"ä¸Šè¨˜ã®é †ç•ªã§ãƒ‡ãƒ¼ã‚¿ã¯ä¸¦ã‚“ã§ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ã‚¹ãƒ†ãƒƒãƒ—A: ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèª\n",
    "\n",
    "print(\"--- ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèªã—ã¾ã™ ---\")\n",
    "print(f\"åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(sample_name)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, name in enumerate(sample_name):\n",
    "    # å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚‚ä¸€ç·’ã«è¡¨ç¤º\n",
    "    data_shape = eem_array_normalized[i].shape\n",
    "    print(f\"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i}: ã‚µãƒ³ãƒ—ãƒ«å = '{name}', ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ = {data_shape}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"ä¸Šè¨˜ã®é †ç•ªã§ãƒ‡ãƒ¼ã‚¿ã¯ä¸¦ã‚“ã§ã„ã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¦¥å½“æ€§è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ã‚¹ãƒ†ãƒƒãƒ—B: æ¨ªè»¸ã‚’è¦‹ã‚„ã™ãã—ãŸãƒ¬ãƒãƒ¬ãƒƒã‚¸ãƒ—ãƒ­ãƒƒãƒˆï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ç‰ˆï¼‰\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ã“ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“ ---\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "max_components = 7\n",
    "component_range = range(2, max_components + 1)\n",
    "leverage_results = {}\n",
    "for n_comp in component_range:\n",
    "    weights, factors = non_negative_parafac(tensor,\n",
    "                                            rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    sample_scores = factors[2]\n",
    "    try:\n",
    "        q, _ = np.linalg.qr(sample_scores)\n",
    "        leverage = np.sum(q**2, axis=1)\n",
    "        leverage_results[n_comp] = leverage\n",
    "    except np.linalg.LinAlgError:\n",
    "        leverage_results[n_comp] = np.full(tensor.shape[2], np.nan)\n",
    "# --- ã“ã“ã¾ã§å¤‰æ›´ãªã— ---\n",
    "\n",
    "\n",
    "# --- çµæžœã®å¯è¦–åŒ–ï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ç‰ˆï¼‰ ---\n",
    "print(\"\\n--- ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---\")\n",
    "\n",
    "# â–¼â–¼â–¼ ã‚°ãƒ©ãƒ•å…¨ä½“ã®ã‚µã‚¤ã‚ºã‚’ã€ã‚ˆã‚Šç¸¦é•·ã«èª¿æ•´ â–¼â–¼â–¼\n",
    "fig, axes = plt.subplots(len(component_range), 1, figsize=(12, 5 * len(component_range)), sharex=True)\n",
    "if len(component_range) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, n_comp in enumerate(component_range):\n",
    "    ax = axes[i]\n",
    "    leverage = leverage_results.get(n_comp)\n",
    "    if leverage is not None and not np.isnan(leverage).all():\n",
    "        bars = ax.bar(sample_name, leverage)\n",
    "        ax.set_ylabel(\"Leverage\", fontsize=12)\n",
    "        ax.set_title(f\"Component = {n_comp}\", fontsize=14)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=11)\n",
    "        ax.tick_params(axis='y', labelsize=10) # yè»¸ã®ãƒ©ãƒ™ãƒ«ã‚µã‚¤ã‚ºã‚‚èª¿æ•´\n",
    "\n",
    "        threshold = 2 * n_comp / tensor.shape[2]\n",
    "        ax.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.2f})')\n",
    "        ax.legend()\n",
    "\n",
    "        for bar, name, lev_val in zip(bars, sample_name, leverage):\n",
    "            if lev_val > threshold:\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, lev_val, name,\n",
    "                        ha='center', va='bottom', fontsize=10, color='blue', weight='bold')\n",
    "    else:\n",
    "        ax.set_title(f\"Component = {n_comp} (Calculation Failed)\")\n",
    "\n",
    "plt.xlabel(\"Sample Name\", fontsize=14)\n",
    "\n",
    "# â–¼â–¼â–¼ å„ãƒ—ãƒ­ãƒƒãƒˆé–“ã®ä½™ç™½ã‚’ã—ã£ã‹ã‚Šç¢ºä¿ã™ã‚‹å‘½ä»¤ã‚’è¿½åŠ  â–¼â–¼â–¼\n",
    "# pad=3.0 ã§ã€å„ã‚°ãƒ©ãƒ•ã®å‘¨å›²ã«ååˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿ã—ã¾ã™\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## core consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®æ‰‹å‹•è¨ˆç®—ã¨ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "\n",
    "# --- äº‹å‰æº–å‚™ï¼ˆã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æº–å‚™ã—ãŸå¤‰æ•°ï¼‰ ---\n",
    "# eem_array_normalized: æ­£è¦åŒ–æ¸ˆã¿ã§NaNã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿é…åˆ—\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNã‚’0ã§åŸ‹ã‚ãŸæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› (åŠ±èµ·, è›å…‰, ã‚µãƒ³ãƒ—ãƒ«)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "\n",
    "# è©¦è¡Œã™ã‚‹æˆåˆ†æ•°ã®ç¯„å›²\n",
    "max_components = 7\n",
    "component_range = range(1, max_components + 1)\n",
    "\n",
    "\n",
    "print(\"--- ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™ (æ‰‹å‹•è¨ˆç®—) ---\")\n",
    "core_consistencies = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"  - æˆåˆ†æ•° = {n_comp} ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "    weights, factors = non_negative_parafac(tensor, rank=n_comp, n_iter_max=200,\n",
    "                                            tol=1e-6, init='random')\n",
    "    \n",
    "    # --- ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®æ‰‹å‹•è¨ˆç®— ---\n",
    "    # 1. ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡Œåˆ—ã‹ã‚‰ã€æ“¬ä¼¼é€†è¡Œåˆ—ã‚’è¨ˆç®—\n",
    "    pseudo_inverses = [np.linalg.pinv(f) for f in factors]\n",
    "    \n",
    "    # 2. ç¾å®Ÿã®ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆGï¼‰ã‚’è¨ˆç®—\n",
    "    # G = X * (A^-1, B^-1, C^-1)\n",
    "    core_tensor_G = multi_mode_dot(tensor, pseudo_inverses, modes=[0, 1, 2])\n",
    "\n",
    "    # 3. ç†æƒ³ã®ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆTï¼‰ã‚’ä½œæˆï¼ˆå¯¾è§’æˆåˆ†ãŒ1ã€ä»–ãŒ0ï¼‰\n",
    "    ideal_core_T = tl.zeros_like(core_tensor_G)\n",
    "    for i in range(n_comp):\n",
    "        ideal_core_T[i, i, i] = 1\n",
    "        \n",
    "    # 4. ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«Gã®å…¨è¦ç´ ã®äºŒä¹—å’Œ (ssq_G) ã‚’è¨ˆç®—\n",
    "    ssq_G = tl.sum(core_tensor_G**2)\n",
    "    \n",
    "    # 5. Gã¨Tã®å·®ã®äºŒä¹—å’Œ (ssq_diff) ã‚’è¨ˆç®—\n",
    "    ssq_diff = tl.sum((core_tensor_G - ideal_core_T)**2)\n",
    "    \n",
    "    # 6. ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã‚’è¨ˆç®—\n",
    "    # 100 * (1 - (Gã¨Tã®å·®ã®äºŒä¹—å’Œ) / (Gã®å…¨è¦ç´ ã®äºŒä¹—å’Œ))\n",
    "    if ssq_G > 1e-8: # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹\n",
    "        cc = (1 - (ssq_diff / ssq_G)) * 100\n",
    "    else:\n",
    "        cc = 0\n",
    "        \n",
    "    core_consistencies.append(cc)\n",
    "    print(f\"  - æˆåˆ†æ•° = {n_comp} ã®ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼: {cc:.1f}%\")\n",
    "\n",
    "print(\"--- è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ ---\")\n",
    "\n",
    "# --- çµæžœã®ãƒ—ãƒ­ãƒƒãƒˆ ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, core_consistencies, 'o-', color='b', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Core Consistency (%)\", fontsize=12)\n",
    "plt.title(\"Core Consistency Diagnostic\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 60%ã®ãƒ©ã‚¤ãƒ³ã«è£œåŠ©ç·šã‚’è¿½åŠ \n",
    "plt.axhline(y=60, color='r', linestyle='--', label='60% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(-5, 105) # è² ã®å€¤ã‚‚è¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«èª¿æ•´\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ã‚¹ãƒ—ãƒªãƒƒãƒˆãƒãƒ¼ãƒ•åˆ†æž\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import non_negative_parafac\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- äº‹å‰æº–å‚™ï¼ˆã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æº–å‚™ã—ãŸå¤‰æ•°ï¼‰ ---\n",
    "# eem_array_normalized: æ­£è¦åŒ–æ¸ˆã¿ã§NaNã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿é…åˆ—\n",
    "# -----------------------------------------------\n",
    "\n",
    "# NaNã‚’0ã§åŸ‹ã‚ãŸæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿\n",
    "eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)\n",
    "# ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› (åŠ±èµ·, è›å…‰, ã‚µãƒ³ãƒ—ãƒ«)\n",
    "tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))\n",
    "num_samples = tensor.shape[2]\n",
    "\n",
    "\n",
    "# è©¦è¡Œã™ã‚‹æˆåˆ†æ•°ã®ç¯„å›²\n",
    "max_components = 7\n",
    "component_range = range(2, max_components + 1)\n",
    "\n",
    "print(\"--- ã‚¹ãƒ—ãƒªãƒƒãƒˆãƒãƒ¼ãƒ•åˆ†æžã‚’é–‹å§‹ã—ã¾ã™ ---\")\n",
    "similarity_scores = []\n",
    "\n",
    "for n_comp in component_range:\n",
    "    print(f\"\\n--- æˆåˆ†æ•° = {n_comp} ã§åˆ†æžä¸­... ---\")\n",
    "    \n",
    "    # 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åŠåˆ†ã«åˆ†å‰²\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    half1_indices = indices[:num_samples // 2]\n",
    "    half2_indices = indices[num_samples // 2:]\n",
    "    \n",
    "    tensor_half1 = tl.tensor(tensor[:, :, half1_indices])\n",
    "    tensor_half2 = tl.tensor(tensor[:, :, half2_indices])\n",
    "    \n",
    "    # 2. ãã‚Œãžã‚Œã®åŠåˆ†ã§PARAFACã‚’å®Ÿè¡Œ\n",
    "    _, factors1 = non_negative_parafac(tensor_half1, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    _, factors2 = non_negative_parafac(tensor_half2, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')\n",
    "    \n",
    "    # 3. ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¯”è¼ƒ\n",
    "    excitation_loadings1, emission_loadings1, _ = factors1\n",
    "    excitation_loadings2, emission_loadings2, _ = factors2\n",
    "    \n",
    "    # é¡žä¼¼åº¦ã‚’è¨ˆç®— (æœ€é©ãªãƒšã‚¢ã‚’è¦‹ã¤ã‘ã¦ãƒžãƒƒãƒãƒ³ã‚°)\n",
    "    total_similarity = 0\n",
    "    matched_indices2 = []\n",
    "    \n",
    "    for i in range(n_comp):\n",
    "        best_match_idx = -1\n",
    "        max_corr = -1\n",
    "        for j in range(n_comp):\n",
    "            if j in matched_indices2:\n",
    "                continue\n",
    "            corr_ex, _ = pearsonr(excitation_loadings1[:, i], excitation_loadings2[:, j])\n",
    "            corr_em, _ = pearsonr(emission_loadings1[:, i], emission_loadings2[:, j])\n",
    "            avg_corr = (corr_ex + corr_em) / 2\n",
    "            \n",
    "            if avg_corr > max_corr:\n",
    "                max_corr = avg_corr\n",
    "                best_match_idx = j\n",
    "        \n",
    "        total_similarity += max_corr\n",
    "        matched_indices2.append(best_match_idx)\n",
    "        \n",
    "    avg_similarity = total_similarity / n_comp\n",
    "    similarity_scores.append(avg_similarity * 100) # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã«å¤‰æ›\n",
    "    print(f\"  - æˆåˆ†æ•° = {n_comp} ã®å¹³å‡é¡žä¼¼åº¦: {avg_similarity*100:.1f}%\")\n",
    "\n",
    "print(\"--- åˆ†æžãŒå®Œäº†ã—ã¾ã—ãŸ ---\")\n",
    "\n",
    "# --- çµæžœã®ãƒ—ãƒ­ãƒƒãƒˆ ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(component_range, similarity_scores, 'o-', color='g', markersize=8)\n",
    "plt.xlabel(\"Number of Components\", fontsize=12)\n",
    "plt.ylabel(\"Split-Half Similarity (%)\", fontsize=12)\n",
    "plt.title(\"Split-Half Analysis\", fontsize=14)\n",
    "plt.xticks(component_range)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "# 95%ã®ãƒ©ã‚¤ãƒ³ã«è£œåŠ©ç·šã‚’è¿½åŠ \n",
    "plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')\n",
    "plt.legend()\n",
    "plt.ylim(0, 105)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–ï¼ˆæ­£è¦åŒ–ï¼‹ãƒ”ãƒ¼ã‚¯è¡¨ç¤ºæ”¹è‰¯ç‰ˆï¼‰\n",
    "\n",
    "# --- äº‹å‰æº–å‚™ã¯å¤‰æ›´ãªã— ---\n",
    "# (excitation_loadings, emission_loadings, sample_scores ãªã©)\n",
    "# ---\n",
    "\n",
    "print(\"\\n--- æŠ½å‡ºã•ã‚ŒãŸæˆåˆ†ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ï¼ˆãƒ”ãƒ¼ã‚¯è¡¨ç¤ºæ”¹è‰¯ç‰ˆï¼‰ ---\")\n",
    "\n",
    "# å„æˆåˆ†ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—\n",
    "for i in range(OPTIMAL_COMPONENTS):\n",
    "    # --- 1. ã‚°ãƒ©ãƒ•ã®æº–å‚™ ---\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆ (æ­£è¦åŒ–ã•ã‚ŒãŸãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨) ---\n",
    "    color1 = 'tab:blue'\n",
    "    ax1.plot(ex_bands_trimmed, excitation_loadings_norm[:, i], color=color1, lw=2.5)\n",
    "    ax1.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax1.set_ylabel('Ex loading (normalized)', color=color1, fontsize=12)\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    color2 = 'tab:red'\n",
    "    ax2.plot(em_bands_trimmed, emission_loadings_norm[:, i], color=color2, lw=2.5)\n",
    "    ax2.set_ylabel('Em loading (normalized)', color=color2, fontsize=12)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "    # --- 3. ãƒ”ãƒ¼ã‚¯æ³¢é•·ã®æ¤œå‡ºã¨æç”»ï¼ˆè¡¨ç¤ºæ–¹æ³•ã‚’æ”¹è‰¯ï¼‰ ---\n",
    "    # åŠ±èµ·ãƒ”ãƒ¼ã‚¯\n",
    "    ex_peak_idx = np.argmax(excitation_loadings_norm[:, i])\n",
    "    ex_peak_wl = ex_bands_trimmed[ex_peak_idx]\n",
    "    ax1.axvline(x=ex_peak_wl, color=color1, linestyle='--', alpha=0.8)\n",
    "    # â–¼â–¼â–¼ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¸¦æ›¸ãã«ã—ã€ä½ç½®ã‚’èª¿æ•´ â–¼â–¼â–¼\n",
    "    ax1.text(ex_peak_wl - 3, ax1.get_ylim()[1] * 0.5, f'{ex_peak_wl:.0f} nm',\n",
    "             color=color1, rotation='vertical', ha='right', va='center', fontsize=11)\n",
    "\n",
    "    # è›å…‰ãƒ”ãƒ¼ã‚¯\n",
    "    em_peak_idx = np.argmax(emission_loadings_norm[:, i])\n",
    "    em_peak_wl = em_bands_trimmed[em_peak_idx]\n",
    "    ax2.axvline(x=em_peak_wl, color=color2, linestyle='--', alpha=0.8)\n",
    "    # â–¼â–¼â–¼ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¸¦æ›¸ãã«ã—ã€ä½ç½®ã‚’èª¿æ•´ â–¼â–¼â–¼\n",
    "    ax2.text(em_peak_wl + 3, ax2.get_ylim()[1] * 0.5, f'{em_peak_wl:.0f} nm',\n",
    "             color=color2, rotation='vertical', ha='left', va='center', fontsize=11)\n",
    "\n",
    "    # --- 4. ä»•ä¸Šã’ ---\n",
    "    ax1.set_title(f'Component {i+1}', fontsize=14)\n",
    "    # Yè»¸ã®ç¯„å›²ã‚’0ã‹ã‚‰ã«å›ºå®šã—ã¦è¦‹ã‚„ã™ãã™ã‚‹\n",
    "    ax1.set_ylim(bottom=0)\n",
    "    ax2.set_ylim(bottom=0)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢ï¼ˆå„MPã®æˆåˆ†å«æœ‰é‡ï¼‰ã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "print(\"\\n--- å„MPã®æˆåˆ†å«æœ‰é‡ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "# ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ã§å¯è¦–åŒ–\n",
    "plt.imshow(sample_scores_norm.T, cmap='viridis', aspect='auto')\n",
    "plt.yticks(ticks=np.arange(OPTIMAL_COMPONENTS), labels=[f'Component {i+1}' for i in range(OPTIMAL_COMPONENTS)])\n",
    "plt.xticks(ticks=np.arange(len(sample_name)), labels=sample_name, rotation=45, ha='right')\n",
    "plt.colorbar(label='Relative Concentration (normalized)')\n",
    "plt.title('Component Scores for Each Microplastic', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% å„æˆåˆ†ã®EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "\n",
    "# --- äº‹å‰æº–å‚™ï¼ˆæœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—çµæžœã‹ã‚‰ï¼‰ ---\n",
    "# excitation_loadings: åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "# emission_loadings: è›å…‰ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "# ex_bands_trimmed: åŠ±èµ·æ³¢é•·ã®ãƒªã‚¹ãƒˆ\n",
    "# em_bands_trimmed: è›å…‰æ³¢é•·ã®ãƒªã‚¹ãƒˆ\n",
    "# OPTIMAL_COMPONENTS: æœ€é©ãªæˆåˆ†æ•°\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"\\n--- åˆ†é›¢ã•ã‚ŒãŸå„æˆåˆ†ã®EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---\")\n",
    "\n",
    "# å„æˆåˆ†ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—\n",
    "for i in range(OPTIMAL_COMPONENTS):\n",
    "    # --- 1. å¤–ç©ã‚’è¨ˆç®—ã—ã¦ã€æˆåˆ†ã®EEMã‚’å†æ§‹æˆ ---\n",
    "    # np.outer() ã§2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰2æ¬¡å…ƒã®è¡Œåˆ—ã‚’ä½œæˆ\n",
    "    component_eem = np.outer(excitation_loadings[:, i], emission_loadings[:, i])\n",
    "\n",
    "    # --- 2. ã‚°ãƒ©ãƒ•ã®æº–å‚™ ---\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "    # --- 3. ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ ---\n",
    "    im = ax.imshow(\n",
    "        component_eem,  \n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        cmap='viridis',\n",
    "        extent=[ex_bands_trimmed[0], ex_bands_trimmed[-1], em_bands_trimmed[0], em_bands_trimmed[-1]]\n",
    "    )\n",
    "\n",
    "    # --- 4. ä»•ä¸Šã’ ---\n",
    "    ax.set_title(f'Reconstructed EEM for Component {i+1}', fontsize=14)\n",
    "    ax.set_xlabel('Excitation Wavelength (nm)', fontsize=12)\n",
    "    ax.set_ylabel('Emission Wavelength (nm)', fontsize=12)\n",
    "    fig.colorbar(im, ax=ax, label='Relative Intensity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in srcdata:\n",
    "#     eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "#     print(eem)\n",
    "\n",
    "#     plt.figure()\n",
    "\n",
    "#     # â‘  æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»\n",
    "#     eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "#                                                        remove_first_order=True, \n",
    "#                                                        inplace=True)\n",
    "\n",
    "#     # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»\n",
    "#     eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "#     eem.plot_heatmap()\n",
    "#     plt.title(eem.sample)\n",
    "\n",
    "sample_data = []\n",
    "sample_name = []\n",
    "\n",
    "for data in srcdata:\n",
    "\n",
    "    # EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "    eem = fluorescence_util.EEMF7000(data.get('path'))\n",
    "    print(eem)\n",
    "\n",
    "    # â‘ æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»\n",
    "    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,\n",
    "                                                       remove_first_order=True,\n",
    "                                                        inplace=True)\n",
    "    # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»\n",
    "    eem.remove_scatter_regions(inplace=True)\n",
    "\n",
    "    # 250nmä»¥ä¸Šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "    ex_mask = ex_bands >= 250\n",
    "    em_mask = em_bands >= 250\n",
    "\n",
    "    eem_matrix = eem.mat  # numpyé…åˆ—ã‚’å–ã‚Šå‡ºã™\n",
    "\n",
    "    # eem_matrix = np.nan_to_num(eem.mat, nan=0.0)\n",
    "    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]\n",
    "\n",
    "    sample_data.append(eem_matrix_trimmed)\n",
    "    sample_name.append(eem.sample)\n",
    "\n",
    "    # eem.plot_heatmap()\n",
    "    # plt.title(eem.sample)\n",
    "\n",
    "# numpyé…åˆ—ã«ä¿å­˜\n",
    "eem_array = np.array(sample_data)\n",
    "print(eem_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ³¢é•·åŸŸã®èª¿æ•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_mask = np.array(ex_bands) >= 250\n",
    "em_mask = np.array(em_bands) >= 250\n",
    "\n",
    "# trim\n",
    "ex_bands = np.array(ex_bands)[ex_mask]\n",
    "em_bands = np.array(em_bands)[em_mask]\n",
    "\n",
    "print(\"Excitation bands â‰¥ 250nm:\", ex_bands)\n",
    "print(\"Emission bands â‰¥ 250nm:\", em_bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒŽã‚¤ã‚ºã‚ã‚Šã‚µãƒ³ãƒ—ãƒ«ã®ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å„MPã”ã¨ã«ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_eem_per_mp_with_scatter_removal(eem_array, ex_bands, em_bands, n_variants=20, noise_level=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    ãƒŽã‚¤ã‚ºä»˜ãEEMã‚’ç”Ÿæˆã—ã€æ•£ä¹±é ˜åŸŸã‚’0ã«ã—ã¦é™¤åŽ»ã™ã‚‹ã€‚\n",
    "\n",
    "    Parameters:\n",
    "        eem_array: np.ndarray\n",
    "            å…¥åŠ›EEMé…åˆ—ã€‚shape = (num_MP, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_exï¼‰\n",
    "        em_bands: np.ndarray\n",
    "            è›å…‰æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_emï¼‰\n",
    "        n_variants: int\n",
    "            å„MPã”ã¨ã«ç”Ÿæˆã™ã‚‹ãƒŽã‚¤ã‚ºä»˜ãEEMã®æ•°\n",
    "        noise_level: float\n",
    "            ãƒŽã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆæœ€å¤§å€¤ã«å¯¾ã™ã‚‹å‰²åˆï¼‰\n",
    "        seed: int or None\n",
    "            ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
    "\n",
    "    Returns:\n",
    "        augmented_eems: np.ndarray\n",
    "            shape = (num_MP, n_variants, n_ex, n_em)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    num_MP, n_ex, n_em = eem_array.shape\n",
    "    augmented_eems = np.zeros((num_MP, n_variants, n_ex, n_em))\n",
    "\n",
    "    # æ•£ä¹±é ˜åŸŸãƒžã‚¹ã‚¯ï¼ˆTrue: æœ‰åŠ¹é ˜åŸŸ, False: æ•£ä¹± â†’ 0ã«ã™ã‚‹ï¼‰\n",
    "    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')\n",
    "    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)\n",
    "\n",
    "    for i in range(num_MP):\n",
    "        base_eem = eem_array[i]\n",
    "        for j in range(n_variants):\n",
    "            noise = np.random.normal(loc=0, scale=noise_level * np.max(base_eem), size=base_eem.shape)\n",
    "            noisy_eem = np.clip(base_eem + noise, 0, None)\n",
    "            noisy_eem[~valid_mask] = 0  # æ•£ä¹±é ˜åŸŸã‚’0ã«\n",
    "            augmented_eems[i, j] = noisy_eem\n",
    "\n",
    "    return augmented_eems\n",
    "# ex_bands, em_bands ã¯ np.array ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š\n",
    "augmented_eems = augment_eem_per_mp_with_scatter_removal(\n",
    "    eem_array,\n",
    "    ex_bands=ex_bands,\n",
    "    em_bands=em_bands,\n",
    "    n_variants=50,\n",
    "    noise_level=0,\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=None):\n",
    "    \"\"\"\n",
    "    å„MPã‹ã‚‰1ã¤ãšã¤ãƒŽã‚¤ã‚ºä»˜ãEEMã‚’ã€å€‹åˆ¥ã«ãƒ—ãƒ­ãƒƒãƒˆï¼ˆåŠ±èµ·ï¼šæ¨ªè»¸ã€æ”¾å°„ï¼šç¸¦è»¸ï¼‰ã€‚\n",
    "\n",
    "    Parameters:\n",
    "        augmented_eems: np.ndarray\n",
    "            shape = (num_MP, n_variants, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆæ¨ªè»¸ï¼‰\n",
    "        em_bands: np.ndarray\n",
    "            ç™ºå…‰æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆç¸¦è»¸ï¼‰\n",
    "        sample_names: list or None\n",
    "            MPã”ã¨ã®åå‰ãƒªã‚¹ãƒˆï¼ˆä»»æ„ï¼‰\n",
    "    \"\"\"\n",
    "    num_MP = augmented_eems.shape[0]\n",
    "\n",
    "    for mp_idx in range(num_MP):\n",
    "        eem = augmented_eems[mp_idx, 0]  # å„MPã§æœ€åˆã®ãƒŽã‚¤ã‚ºãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¡¨ç¤º\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.imshow(eem, origin='lower',\n",
    "                   extent=[ex_bands[0], ex_bands[-1], em_bands[0], em_bands[-1]],\n",
    "                   aspect='auto', cmap='viridis')\n",
    "\n",
    "        plt.xlabel('Excitation (nm)')\n",
    "        plt.ylabel('Emission (nm)')\n",
    "        title = sample_names[mp_idx] if sample_names else f'MP {mp_idx}'\n",
    "        plt.title(f'Augmented EEM - {title}')\n",
    "        plt.colorbar(label='Intensity')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=sample_name)\n",
    "# plot_augmented_eems_one_by_one(combined_augmented_eems, ex_bands, em_bands, sample_names=sample_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPã®EEMã‚’åˆæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_eem_with_noise(\n",
    "    eem_array, ex_bands, em_bands,\n",
    "    n_variants=20, noise_level=0.05, seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    å…¨MPã®EEMã‚’åˆæˆã—ã¦ã€ãƒŽã‚¤ã‚ºä»˜ãã®EEMã‚’ç”Ÿæˆï¼ˆæ•£ä¹±é ˜åŸŸé™¤åŽ»ã¤ãï¼‰\n",
    "\n",
    "    Parameters:\n",
    "        eem_array: np.ndarray\n",
    "            shape = (num_MP, n_ex, n_em)\n",
    "        ex_bands: np.ndarray\n",
    "            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_exï¼‰\n",
    "        em_bands: np.ndarray\n",
    "            æ”¾å°„æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_emï¼‰\n",
    "        n_variants: int\n",
    "            ç”Ÿæˆã™ã‚‹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°\n",
    "        noise_level: float\n",
    "            ãƒŽã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆåˆæˆEEMã®æœ€å¤§å€¤ã«å¯¾ã™ã‚‹å‰²åˆï¼‰\n",
    "        seed: int or None\n",
    "            ä¹±æ•°ã‚·ãƒ¼ãƒ‰\n",
    "\n",
    "    Returns:\n",
    "        combined_eems: np.ndarray\n",
    "            shape = (n_variants, n_ex, n_em)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # --- åˆæˆEEMï¼ˆã™ã¹ã¦ã®MPã®å’Œï¼‰\n",
    "    combined_base = np.sum(eem_array, axis=0)  # shape = (n_ex, n_em)\n",
    "\n",
    "    # --- æ•£ä¹±é ˜åŸŸãƒžã‚¹ã‚¯ã‚’ä½œæˆ\n",
    "    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')\n",
    "    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)\n",
    "\n",
    "    # --- ãƒŽã‚¤ã‚ºä»˜ãEEMã®ç”Ÿæˆ\n",
    "    combined_eems = np.zeros((n_variants, *combined_base.shape))\n",
    "    for i in range(n_variants):\n",
    "        noise = np.random.normal(loc=0, scale=noise_level * np.max(combined_base), size=combined_base.shape)\n",
    "        noisy_eem = np.clip(combined_base + noise, 0, None)\n",
    "        noisy_eem[~valid_mask] = 0  # æ•£ä¹±é ˜åŸŸã‚’ã‚¼ãƒ­ã«\n",
    "        combined_eems[i] = noisy_eem\n",
    "\n",
    "    return combined_eems\n",
    "\n",
    "combined_augmented_eems = generate_combined_eem_with_noise(\n",
    "    eem_array,\n",
    "    ex_bands=ex_bands,\n",
    "    em_bands=em_bands,\n",
    "    n_variants=50,\n",
    "    noise_level=0.05,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "\n",
    "# 1æžšç›®ã‚’å–å¾—\n",
    "eem_sample = combined_augmented_eems[0]\n",
    "\n",
    "# ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(\n",
    "    eem_sample,\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    extent=[em_bands.min(), em_bands.max(), ex_bands.min(), ex_bands.max()],\n",
    "    cmap='viridis'\n",
    ")\n",
    "plt.colorbar(label='Fluorescence Intensity')\n",
    "plt.xlabel('Emission Wavelength (nm)')\n",
    "plt.ylabel('Excitation Wavelength (nm)')\n",
    "plt.title('Combined EEM Sample #1')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAFACï¼ŒCore Consistencyï¼ŒSplit half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from scipy.stats import pearsonr\n",
    "from corcondia import corcondia_3d\n",
    "\n",
    "tl.set_backend('numpy')\n",
    "\n",
    "# --- PARAFACçµæžœã‚’ã™ã¹ã¦ä¿å­˜ã™ã‚‹é–¢æ•° ---\n",
    "def compute_parafac_results(eem_tensor, max_components):\n",
    "    results = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        factors = parafac(eem_tensor, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "        results.append(factors)\n",
    "    return results\n",
    "\n",
    "# --- Core Consistency Diagnostic (æ­£å¼ç‰ˆ CORCONDIA)\n",
    "def compute_core_consistency_corcondia(tensor, max_components=7):\n",
    "    cc_list = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        cc = corcondia_3d(tensor, k=r)\n",
    "        cc_list.append(cc)\n",
    "    return cc_list\n",
    "\n",
    "# --- Split-Half é¡žä¼¼åº¦ã®ä¸€æ‹¬è¨ˆç®—ï¼ˆå„ãƒ©ãƒ³ã‚¯ã§åˆ¥ã€…ã«åˆ†å‰²ï¼‹åˆ†è§£ï¼‰\n",
    "def compute_split_half_similarities(tensor, max_components):\n",
    "    sim_list = []\n",
    "    for r in range(1, max_components + 1):\n",
    "        all_idx = np.arange(tensor.shape[2])\n",
    "        np.random.shuffle(all_idx)\n",
    "        half1 = tensor[:, :, all_idx[:tensor.shape[2] // 2]]\n",
    "        half2 = tensor[:, :, all_idx[tensor.shape[2] // 2:]]\n",
    "\n",
    "        f1 = parafac(half1, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "        f2 = parafac(half2, rank=r, init='random', tol=1e-6, n_iter_max=200)\n",
    "\n",
    "        ex1, em1, _ = f1.factors\n",
    "        ex2, em2, _ = f2.factors\n",
    "\n",
    "        sim_total = 0\n",
    "        for i in range(r):\n",
    "            r_ex, _ = pearsonr(ex1[:, i], ex2[:, i])\n",
    "            r_em, _ = pearsonr(em1[:, i], em2[:, i])\n",
    "            sim_total += (r_ex + r_em) / 2\n",
    "        sim_list.append(sim_total / r)\n",
    "    return sim_list\n",
    "\n",
    "# --- å„MPã«å¯¾ã—ã¦ Core Consistencyï¼ˆCORCONDIAï¼‰ã¨ Split-Half é¡žä¼¼åº¦ã‚’è¨ˆç®— ---\n",
    "cc_dict = {}\n",
    "sh_dict = {}\n",
    "factors_dict = {}\n",
    "\n",
    "for idx, eem_tensor in enumerate(augmented_eems):\n",
    "    sample = sample_name[idx]\n",
    "    print(f\"\\nðŸ”ã€{sample}ã€‘ã® Core Consistency / Split-Half è¨ˆç®—ä¸­...\")\n",
    "\n",
    "    tensor = np.transpose(eem_tensor, (1, 2, 0))  # (exc, em, sample)\n",
    "    factors_dict[sample] = compute_parafac_results(tensor, max_components=7)\n",
    "\n",
    "    # æ­£å¼ãª Core Consistency è¨ˆç®—ï¼ˆCORCONDIAï¼‰\n",
    "    cc_dict[sample] = compute_core_consistency_corcondia(tensor, max_components=7)\n",
    "\n",
    "    # Split-Half é¡žä¼¼åº¦\n",
    "    sh_dict[sample] = compute_split_half_similarities(tensor, max_components=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=\"Sample\", start_rank=1):\n",
    "    \"\"\"\n",
    "    Core Consistencyã¨Split-Halfé¡žä¼¼åº¦ã‚’åŒæ™‚ã«ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹é–¢æ•°\n",
    "\n",
    "    Parameters:\n",
    "        cc_list: list of floatï¼ˆCore Consistency, å„æˆåˆ†æ•°ã«å¯¾å¿œï¼‰\n",
    "        sh_list: list of floatï¼ˆSplit-Half é¡žä¼¼åº¦, å„æˆåˆ†æ•°ã«å¯¾å¿œï¼‰\n",
    "        sample_label: strï¼ˆãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒˆãƒ«ç”¨ï¼‰\n",
    "        start_rank: intï¼ˆé€šå¸¸ã¯1, cc_list[0]ãŒrank=1ã®ã¨ãï¼‰\n",
    "    \"\"\"\n",
    "    ranks = list(range(start_rank, start_rank + len(cc_list)))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(7, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax1.plot(ranks, cc_list, 'o-', color='tab:blue', label='Core Consistency')\n",
    "    ax2.plot(ranks, sh_list, 's--', color='tab:red', label='Split-Half Similarity')\n",
    "\n",
    "    ax1.set_xlabel(\"Component Rank\")\n",
    "    ax1.set_ylabel(\"Core Consistency (%)\", color='tab:blue')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    ax2.set_ylabel(\"Similarity(%)\", color='tab:red')\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    ax1.set_title(f\"{sample_label}: Core Consistency & Split-Half Similarity\")\n",
    "\n",
    "    # å‡¡ä¾‹ã®è¨­å®š\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# for sample in sample_name:\n",
    "#     plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)\n",
    "for sample in sample_name:\n",
    "    cc_list = cc_dict.get(sample)\n",
    "    sh_list = sh_dict.get(sample)\n",
    "    if cc_list is not None and sh_list is not None:\n",
    "        plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)\n",
    "    else:\n",
    "        print(f\"{sample} ã®è§£æžçµæžœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "def plot_eem_with_bandpass_box(eem, ex_bands, em_bands,\n",
    "                                excitation_loading, emission_loading,\n",
    "                                rank, band_width=20, sample_label=\"MP\"):\n",
    "    \"\"\"\n",
    "    ãƒŽã‚¤ã‚ºä»˜ãEEMä¸Šã«ã€æŒ‡å®šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒãƒ³ãƒ‰ãƒ‘ã‚¹æ³¢é•·ç¯„å›²ã‚’ç´«ã®å››è§’ã§é‡ã­ã¦è¡¨ç¤º\n",
    "\n",
    "    Parameters:\n",
    "        eem: 2D array (ex Ã— em)\n",
    "        ex_bands: 1D array\n",
    "        em_bands: 1D array\n",
    "        excitation_loading: 2D array (ex, rank)\n",
    "        emission_loading: 2D array (em, rank)\n",
    "        component_idx: intï¼ˆä½•ç•ªç›®ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã€0å§‹ã¾ã‚Šï¼‰\n",
    "        band_width: floatï¼ˆÂ±ä½•nmã§ç¯„å›²ã‚’å–ã‚‹ã‹ï¼‰\n",
    "        sample_label: str\n",
    "    \"\"\"\n",
    "\n",
    "    # EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(eem, origin='lower',\n",
    "                   extent=[em_bands[0], em_bands[-1],\n",
    "                           ex_bands[0], ex_bands[-1]],\n",
    "                   aspect='auto', cmap='viridis')\n",
    "    \n",
    "    for i in range(rank):\n",
    "        # ãƒ”ãƒ¼ã‚¯æ³¢é•·ã‚’ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‹ã‚‰æŠ½å‡º\n",
    "        exc_idx = np.argmax(excitation_loading[:, i])\n",
    "        em_idx = np.argmax(emission_loading[:, i])\n",
    "        exc_peak = ex_bands[exc_idx]\n",
    "        em_peak = em_bands[em_idx]\n",
    "\n",
    "        # å››è§’ã®ç¯„å›²ï¼ˆÂ±band_widthï¼‰\n",
    "        exc_min = exc_peak - band_width\n",
    "        exc_max = exc_peak + band_width\n",
    "        em_min = em_peak - band_width\n",
    "        em_max = em_peak + band_width\n",
    "\n",
    "        # # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "        # exc = excitation_loading[:, i]\n",
    "        # em = emission_loading[:, i]\n",
    "\n",
    "        # # ãƒ”ãƒ¼ã‚¯ä½ç½®ï¼ˆæœ€å¤§å€¤ï¼‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ â†’ æ³¢é•·\n",
    "        # exc_idx = np.argmax(exc)\n",
    "        # em_idx = np.argmax(em)\n",
    "        # exc_peak = ex_bands[exc_idx]\n",
    "        # em_peak = em_bands[em_idx]\n",
    "\n",
    "        # # ðŸŽ¯ åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¨™æº–åå·®ã‚’ä½¿ã£ã¦ band_width ã‚’æ±ºã‚ã‚‹\n",
    "        # # é‡ã¿ä»˜ãå¹³å‡ã¨åˆ†æ•£ï¼ˆä¸­å¿ƒæ³¢é•·Â±å¹…ï¼‰\n",
    "        # exc_mean = np.sum(ex_bands * exc) / np.sum(exc)\n",
    "        # exc_var = np.sum(((ex_bands - exc_mean) ** 2) * exc) / np.sum(exc)\n",
    "        # band_width = np.sqrt(exc_var)   # æ¨™æº–åå·®\n",
    "\n",
    "        # # å››è§’ã®ç¯„å›²ï¼ˆÂ±1Ïƒç¨‹åº¦ï¼‰\n",
    "        # exc_min = exc_peak - band_width\n",
    "        # exc_max = exc_peak + band_width\n",
    "        # em_min = em_peak - band_width\n",
    "        # em_max = em_peak + band_width\n",
    "\n",
    "        # ðŸ”´ èµ¤ã„æ¨ªç·šã§ Excitation peak ã‚’ç¤ºã™  \n",
    "        ax.hlines(y=exc_peak, xmin=em_bands[0], xmax=em_bands[-1], colors='red', linestyles='dashed', linewidth=1.5)\n",
    "\n",
    "        # # â¬… ãƒ©ãƒ™ãƒ«ã‚’å·¦ã«è¡¨ç¤ºï¼ˆx=æœ€å°æ”¾å°„æ³¢é•· - å°‘ã—å·¦ã«ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰\n",
    "        # ax.text(em_bands[0] - 10, exc_peak, f\"Ex = {exc_peak} nm\",\n",
    "        #         color='red', fontsize=10, va='center', ha='right')\n",
    "\n",
    "        print(f\"Loading_{i+1} peak ex_band: {exc_peak}\")\n",
    "        print(f\"Loading_{i+1} peak em_band: {em_peak}\")\n",
    "        \n",
    "        # ç´«ã®å››è§’ã‚’é‡ã­ã‚‹\n",
    "        rect = patches.Rectangle(\n",
    "            (em_min, exc_min),  # å·¦ä¸‹è§’ (x, y)\n",
    "            em_max - em_min,    # å¹…\n",
    "            exc_max - exc_min,  # é«˜ã•\n",
    "            linewidth=2,\n",
    "            edgecolor='white',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_title(f\"{sample_label} - EEM with Bandpass Box (Component {rank})\")\n",
    "        ax.set_xlabel(\"Emission Wavelength (nm)\")\n",
    "        ax.set_ylabel(\"Excitation Wavelength (nm)\")\n",
    "        plt.tight_layout()\n",
    "    plt.colorbar(im, ax=ax, label=\"Fluorescence Intensity\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_selected_loadings(factors, rank, ex_bands, em_bands, sample_label=\"Sample\"):\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã—ãŸrankã®PARAFACçµæžœã‚’ä½¿ã£ã¦ã€åŠ±èµ·ã¨ç™ºå…‰ã®ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "\n",
    "    Parameters:\n",
    "        results: list of parafac resultsï¼ˆcompute_parafac_results()ã®å‡ºåŠ›ï¼‰\n",
    "        rank: intï¼ˆè¡¨ç¤ºã—ãŸã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•°ï¼‰\n",
    "        ex_bands: 1D arrayï¼ˆåŠ±èµ·æ³¢é•·ï¼‰\n",
    "        em_bands: 1D arrayï¼ˆç™ºå…‰æ³¢é•·ï¼‰\n",
    "        sample_label: strï¼ˆMPã®åå‰ãªã©ï¼‰\n",
    "    \"\"\"\n",
    "    factors_rank = factors[rank - 1]  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ³¨æ„ï¼šrank=1 â†’ results[0]\n",
    "    excitation_loading, emission_loading, _ = factors_rank.factors\n",
    "\n",
    "    # --- åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° ---\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(rank):\n",
    "        plt.plot(ex_bands, excitation_loading[:, i], label=f\"Component {i+1}\")\n",
    "    plt.title(f\"{sample_label} - Excitation Loading (Rank {rank})\")\n",
    "    plt.xlabel(\"Excitation Wavelength (nm)\")\n",
    "    plt.ylabel(\"Loading Strength\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- ç™ºå…‰ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° ---\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    for i in range(rank):\n",
    "        plt.plot(em_bands, emission_loading[:, i], label=f\"Component {i+1}\")\n",
    "    plt.title(f\"{sample_label} - Emission Loading (Rank {rank})\")\n",
    "    plt.xlabel(\"Emission Wavelength (nm)\")\n",
    "    plt.ylabel(\"Loading Strength\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¸¯åŸŸå›³ç¤ºåŒ–\n",
    "    plot_eem_with_bandpass_box(eem, ex_bands, em_bands,\n",
    "                            excitation_loading, emission_loading,\n",
    "                            rank, band_width=20, sample_label=sample\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"ABS\"\n",
    "rank = 1\n",
    "factors = factors_dict.get(sample)\n",
    "\n",
    "mp_idx = sample_name.index(sample)  # \"PET\" ã«å¯¾å¿œã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆä¾‹ï¼š0ï¼‰\n",
    "eem = augmented_eems[mp_idx, 0]  # PETã®æœ€åˆã®ãƒŽã‚¤ã‚ºä»˜ãEEMï¼ˆshape: 81x81ï¼‰\n",
    "\n",
    "\n",
    "if factors is not None:\n",
    "    plot_selected_loadings(\n",
    "        factors, \n",
    "        rank,\n",
    "        ex_bands,\n",
    "        em_bands,\n",
    "        sample_label=sample\n",
    "    )\n",
    "else:\n",
    "    print(f\"{sample} ã®è§£æžçµæžœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
