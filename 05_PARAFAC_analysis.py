# %%
import numpy as np
import pandas as pd
from  matplotlib import pyplot as plt
import os 
from pathlib import Path
import re
import PIL
import cv2
import seaborn as sns 
import copy
import importlib

import spectral_util
importlib.reload(spectral_util)
from spectral_util import *

import fluorescence_util
importlib.reload(fluorescence_util)
from fluorescence_util import *


# %%
# 'board.xlsx'
# 'board_noFlux.xlsx'
# 'flux_20240925_184835.xlsx'
# 'flux-onBoard.xlsx'
# 'lead_noFlux.xlsx'

# srcbase = Path("./data/EEM_F-7000_2025-04-11/")
print(Path.cwd())
srcbase = Path("./data/EEM_F-7000_2025-05-29/")
dstdir = Path("./dst/eem/filter")

srcdata = [
    {
        "path": fpath,
        "sample": fpath.stem.split("_")[0],  # 'ABS_20250411' â†’ 'ABS'
        "label": None
    }
    for fpath in srcbase.glob("*.xlsx")
]
srcdata

# %%
for data in srcdata:
    eem = fluorescence_util.EEMF7000(data.get('path'))
    print(eem)

    plt.figure()
    eem.plot_contour(level=100, show_sample_name=True)

# %%
em_bands = eem.em_bands
ex_bands = eem.ex_bands

# %% [markdown]
# # å‰å‡¦ç†

# %% [markdown]
# ## æ•£ä¹±å…‰ã®é™¤åŽ»ã¨æ³¢é•·åŸŸã®èª¿æ•´

# %%
# %% EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ï¼ˆæ•£ä¹±é™¤åŽ» & NaNä¿æŒï¼‰

sample_data_processed = []
sample_name = []

# æ³¢é•·åŸŸã‚’å…ˆã«å®šç¾©ã—ã¦ãŠã
eem_template = fluorescence_util.EEMF7000(srcdata[0]['path'])
ex_bands_full = eem_template.ex_bands
em_bands_full = eem_template.em_bands

# 250nmä»¥ä¸Šã®æ³¢é•·ãƒžã‚¹ã‚¯ã‚’ä½œæˆ
ex_mask = ex_bands_full >= 250
em_mask = em_bands_full >= 250

# ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®æ³¢é•·åŸŸã‚’ä¿å­˜
ex_bands_trimmed = ex_bands_full[ex_mask]
em_bands_trimmed = em_bands_full[em_mask]


print("--- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ ---")
for data in srcdata:
    # EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    eem = fluorescence_util.EEMF7000(data.get('path'))

    # â‘  æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»ï¼ˆNaNã‚’ä»£å…¥ï¼‰
    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,
                                                       remove_first_order=True,
                                                       inplace=True)
    # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»ï¼ˆNaNã‚’ä»£å…¥ï¼‰
    eem.remove_scatter_regions(inplace=True)

    # ç”Ÿã®è¡Œåˆ—ã‚’å–å¾—
    eem_matrix = eem.mat

    # â‘¢ æ³¢é•·åŸŸã‚’ãƒˆãƒªãƒŸãƒ³ã‚°
    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]

    # å‰å‡¦ç†æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
    sample_data_processed.append(eem_matrix_trimmed)
    sample_name.append(eem.sample)
    print(f"  - ã‚µãƒ³ãƒ—ãƒ« '{eem.sample}' ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

print("--- å…¨ã¦ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")

# ãƒªã‚¹ãƒˆã‚’3Dã®numpyé…åˆ—ã«å¤‰æ›
# ã“ã®æ®µéšŽã§ã¯NaNãŒå«ã¾ã‚Œã¦ã„ã‚‹
eem_array_processed = np.array(sample_data_processed)

print("\nå‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:", eem_array_processed.shape)
print("åŠ±èµ·æ³¢é•·ã®æ•°:", len(ex_bands_trimmed))
print("è›å…‰æ³¢é•·ã®æ•°:", len(em_bands_trimmed))

# %%
sample_name

# %% [markdown]
# ## æ­£è¦åŒ–

# %%
# %% ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ï¼ˆè«–æ–‡æº–æ‹ : Unit Norm Scalingï¼‰

# æ­£è¦åŒ–æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹æ–°ã—ã„ãƒªã‚¹ãƒˆã‚’ä½œæˆ
sample_data_normalized = []

print("--- ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆè«–æ–‡æº–æ‹ ï¼‰---")
for i, eem_matrix in enumerate(eem_array_processed):
    # NaNã‚’ç„¡è¦–ã—ã¦ã€äºŒä¹—å’Œã‚’è¨ˆç®—
    sum_of_squares = np.nansum(eem_matrix**2)

    # äºŒä¹—å’ŒãŒ0ã¾ãŸã¯éžå¸¸ã«å°ã•ã„å ´åˆã¯ã€ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
    if sum_of_squares > 1e-8:
        eem_normalized = eem_matrix / sum_of_squares
    else:
        # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦0ã‚„NaNã®å ´åˆã€ãã®ã¾ã¾ï¼ˆå¤‰æ›´ãªã—ï¼‰
        eem_normalized = eem_matrix

    sample_data_normalized.append(eem_normalized)
    print(f"  - ã‚µãƒ³ãƒ—ãƒ« '{sample_name[i]}' ã®æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

print("--- å…¨ã¦ã®æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ ---")

# æ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’3Dã®numpyé…åˆ—ã«å¤‰æ›
# ã“ã®æ®µéšŽã§ã‚‚NaNã¯ä¿æŒã•ã‚Œã¦ã„ã¾ã™
eem_array_normalized = np.array(sample_data_normalized)

print("\næ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:", eem_array_normalized.shape)

# %%
# %% ã‚¹ãƒ†ãƒƒãƒ—A: ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèª

print("--- ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèªã—ã¾ã™ ---")
print(f"åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(sample_name)}")
print("-" * 40)

for i, name in enumerate(sample_name):
    # å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚‚ä¸€ç·’ã«è¡¨ç¤º
    data_shape = eem_array_normalized[i].shape
    print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i}: ã‚µãƒ³ãƒ—ãƒ«å = '{name}', ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ = {data_shape}")

print("-" * 40)
print("ä¸Šè¨˜ã®é †ç•ªã§ãƒ‡ãƒ¼ã‚¿ã¯ä¸¦ã‚“ã§ã„ã¾ã™ã€‚")

# %%
# %% ã‚¹ãƒ†ãƒƒãƒ—A: ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèª

print("--- ã‚µãƒ³ãƒ—ãƒ«åã¨ãƒ‡ãƒ¼ã‚¿ã®å¯¾å¿œã‚’ç¢ºèªã—ã¾ã™ ---")
print(f"åˆè¨ˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(sample_name)}")
print("-" * 40)

for i, name in enumerate(sample_name):
    # å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚‚ä¸€ç·’ã«è¡¨ç¤º
    data_shape = eem_array_normalized[i].shape
    print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i}: ã‚µãƒ³ãƒ—ãƒ«å = '{name}', ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ = {data_shape}")

print("-" * 40)
print("ä¸Šè¨˜ã®é †ç•ªã§ãƒ‡ãƒ¼ã‚¿ã¯ä¸¦ã‚“ã§ã„ã¾ã™ã€‚")

# %% [markdown]
# ---

# %% [markdown]
# # å¦¥å½“æ€§è©•ä¾¡

# %%
# %% ã‚¹ãƒ†ãƒƒãƒ—B: æ¨ªè»¸ã‚’è¦‹ã‚„ã™ãã—ãŸãƒ¬ãƒãƒ¬ãƒƒã‚¸ãƒ—ãƒ­ãƒƒãƒˆï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ç‰ˆï¼‰

import tensorly as tl
from tensorly.decomposition import non_negative_parafac
import numpy as np
import matplotlib.pyplot as plt

# --- ã“ã®éƒ¨åˆ†ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“ ---
eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)
tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))
max_components = 7
component_range = range(2, max_components + 1)
leverage_results = {}
for n_comp in component_range:
    weights, factors = non_negative_parafac(tensor,
                                            rank=n_comp, n_iter_max=200,
                                            tol=1e-6, init='random')
    sample_scores = factors[2]
    try:
        q, _ = np.linalg.qr(sample_scores)
        leverage = np.sum(q**2, axis=1)
        leverage_results[n_comp] = leverage
    except np.linalg.LinAlgError:
        leverage_results[n_comp] = np.full(tensor.shape[2], np.nan)
# --- ã“ã“ã¾ã§å¤‰æ›´ãªã— ---


# --- çµæžœã®å¯è¦–åŒ–ï¼ˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ç‰ˆï¼‰ ---
print("\n--- ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---")

# â–¼â–¼â–¼ ã‚°ãƒ©ãƒ•å…¨ä½“ã®ã‚µã‚¤ã‚ºã‚’ã€ã‚ˆã‚Šç¸¦é•·ã«èª¿æ•´ â–¼â–¼â–¼
fig, axes = plt.subplots(len(component_range), 1, figsize=(12, 5 * len(component_range)), sharex=True)
if len(component_range) == 1:
    axes = [axes]

for i, n_comp in enumerate(component_range):
    ax = axes[i]
    leverage = leverage_results.get(n_comp)
    if leverage is not None and not np.isnan(leverage).all():
        bars = ax.bar(sample_name, leverage)
        ax.set_ylabel("Leverage", fontsize=12)
        ax.set_title(f"Component = {n_comp}", fontsize=14)
        ax.tick_params(axis='x', rotation=45, labelsize=11)
        ax.tick_params(axis='y', labelsize=10) # yè»¸ã®ãƒ©ãƒ™ãƒ«ã‚µã‚¤ã‚ºã‚‚èª¿æ•´

        threshold = 2 * n_comp / tensor.shape[2]
        ax.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.2f})')
        ax.legend()

        for bar, name, lev_val in zip(bars, sample_name, leverage):
            if lev_val > threshold:
                ax.text(bar.get_x() + bar.get_width() / 2, lev_val, name,
                        ha='center', va='bottom', fontsize=10, color='blue', weight='bold')
    else:
        ax.set_title(f"Component = {n_comp} (Calculation Failed)")

plt.xlabel("Sample Name", fontsize=14)

# â–¼â–¼â–¼ å„ãƒ—ãƒ­ãƒƒãƒˆé–“ã®ä½™ç™½ã‚’ã—ã£ã‹ã‚Šç¢ºä¿ã™ã‚‹å‘½ä»¤ã‚’è¿½åŠ  â–¼â–¼â–¼
# pad=3.0 ã§ã€å„ã‚°ãƒ©ãƒ•ã®å‘¨å›²ã«ååˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¢ºä¿ã—ã¾ã™
fig.tight_layout(pad=3.0)

plt.show()

# %% [markdown]
# ## core consistency

# %%
# %% ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®æ‰‹å‹•è¨ˆç®—ã¨ãƒ—ãƒ­ãƒƒãƒˆ

import numpy as np
import matplotlib.pyplot as plt
import tensorly as tl
from tensorly.decomposition import non_negative_parafac
from tensorly.tenalg import multi_mode_dot

# --- äº‹å‰æº–å‚™ï¼ˆã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æº–å‚™ã—ãŸå¤‰æ•°ï¼‰ ---
# eem_array_normalized: æ­£è¦åŒ–æ¸ˆã¿ã§NaNã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿é…åˆ—
# -----------------------------------------------

# NaNã‚’0ã§åŸ‹ã‚ãŸæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)
# ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› (åŠ±èµ·, è›å…‰, ã‚µãƒ³ãƒ—ãƒ«)
tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))

# è©¦è¡Œã™ã‚‹æˆåˆ†æ•°ã®ç¯„å›²
max_components = 7
component_range = range(1, max_components + 1)


print("--- ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™ (æ‰‹å‹•è¨ˆç®—) ---")
core_consistencies = []

for n_comp in component_range:
    print(f"  - æˆåˆ†æ•° = {n_comp} ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
    weights, factors = non_negative_parafac(tensor, rank=n_comp, n_iter_max=200,
                                            tol=1e-6, init='random')
    
    # --- ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã®æ‰‹å‹•è¨ˆç®— ---
    # 1. ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡Œåˆ—ã‹ã‚‰ã€æ“¬ä¼¼é€†è¡Œåˆ—ã‚’è¨ˆç®—
    pseudo_inverses = [np.linalg.pinv(f) for f in factors]
    
    # 2. ç¾å®Ÿã®ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆGï¼‰ã‚’è¨ˆç®—
    # G = X * (A^-1, B^-1, C^-1)
    core_tensor_G = multi_mode_dot(tensor, pseudo_inverses, modes=[0, 1, 2])

    # 3. ç†æƒ³ã®ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆTï¼‰ã‚’ä½œæˆï¼ˆå¯¾è§’æˆåˆ†ãŒ1ã€ä»–ãŒ0ï¼‰
    ideal_core_T = tl.zeros_like(core_tensor_G)
    for i in range(n_comp):
        ideal_core_T[i, i, i] = 1
        
    # 4. ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«Gã®å…¨è¦ç´ ã®äºŒä¹—å’Œ (ssq_G) ã‚’è¨ˆç®—
    ssq_G = tl.sum(core_tensor_G**2)
    
    # 5. Gã¨Tã®å·®ã®äºŒä¹—å’Œ (ssq_diff) ã‚’è¨ˆç®—
    ssq_diff = tl.sum((core_tensor_G - ideal_core_T)**2)
    
    # 6. ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼ã‚’è¨ˆç®—
    # 100 * (1 - (Gã¨Tã®å·®ã®äºŒä¹—å’Œ) / (Gã®å…¨è¦ç´ ã®äºŒä¹—å’Œ))
    if ssq_G > 1e-8: # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
        cc = (1 - (ssq_diff / ssq_G)) * 100
    else:
        cc = 0
        
    core_consistencies.append(cc)
    print(f"  - æˆåˆ†æ•° = {n_comp} ã®ã‚³ã‚¢ã‚³ãƒ³ã‚·ã‚¹ãƒ†ãƒ³ã‚·ãƒ¼: {cc:.1f}%")

print("--- è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸ ---")

# --- çµæžœã®ãƒ—ãƒ­ãƒƒãƒˆ ---
plt.figure(figsize=(8, 5))
plt.plot(component_range, core_consistencies, 'o-', color='b', markersize=8)
plt.xlabel("Number of Components", fontsize=12)
plt.ylabel("Core Consistency (%)", fontsize=12)
plt.title("Core Consistency Diagnostic", fontsize=14)
plt.xticks(component_range)
plt.grid(True, linestyle='--', alpha=0.6)
# 60%ã®ãƒ©ã‚¤ãƒ³ã«è£œåŠ©ç·šã‚’è¿½åŠ 
plt.axhline(y=60, color='r', linestyle='--', label='60% Threshold')
plt.legend()
plt.ylim(-5, 105) # è² ã®å€¤ã‚‚è¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«èª¿æ•´
plt.show()

# %% [markdown]
# ## split-half

# %%
# %% ã‚¹ãƒ—ãƒªãƒƒãƒˆãƒãƒ¼ãƒ•åˆ†æž

import numpy as np
import tensorly as tl
from tensorly.decomposition import non_negative_parafac
from scipy.stats import pearsonr
import matplotlib.pyplot as plt

# --- äº‹å‰æº–å‚™ï¼ˆã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æº–å‚™ã—ãŸå¤‰æ•°ï¼‰ ---
# eem_array_normalized: æ­£è¦åŒ–æ¸ˆã¿ã§NaNã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿é…åˆ—
# -----------------------------------------------

# NaNã‚’0ã§åŸ‹ã‚ãŸæ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
eem_array_imputed = np.nan_to_num(eem_array_normalized, nan=0.0)
# ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› (åŠ±èµ·, è›å…‰, ã‚µãƒ³ãƒ—ãƒ«)
tensor = tl.tensor(np.transpose(eem_array_imputed, (1, 2, 0)))
num_samples = tensor.shape[2]


# è©¦è¡Œã™ã‚‹æˆåˆ†æ•°ã®ç¯„å›²
max_components = 7
component_range = range(2, max_components + 1)

print("--- ã‚¹ãƒ—ãƒªãƒƒãƒˆãƒãƒ¼ãƒ•åˆ†æžã‚’é–‹å§‹ã—ã¾ã™ ---")
similarity_scores = []

for n_comp in component_range:
    print(f"\n--- æˆåˆ†æ•° = {n_comp} ã§åˆ†æžä¸­... ---")
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åŠåˆ†ã«åˆ†å‰²
    indices = np.arange(num_samples)
    np.random.shuffle(indices)
    half1_indices = indices[:num_samples // 2]
    half2_indices = indices[num_samples // 2:]
    
    tensor_half1 = tl.tensor(tensor[:, :, half1_indices])
    tensor_half2 = tl.tensor(tensor[:, :, half2_indices])
    
    # 2. ãã‚Œãžã‚Œã®åŠåˆ†ã§PARAFACã‚’å®Ÿè¡Œ
    _, factors1 = non_negative_parafac(tensor_half1, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')
    _, factors2 = non_negative_parafac(tensor_half2, rank=n_comp, n_iter_max=200, tol=1e-6, init='random')
    
    # 3. ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¯”è¼ƒ
    excitation_loadings1, emission_loadings1, _ = factors1
    excitation_loadings2, emission_loadings2, _ = factors2
    
    # é¡žä¼¼åº¦ã‚’è¨ˆç®— (æœ€é©ãªãƒšã‚¢ã‚’è¦‹ã¤ã‘ã¦ãƒžãƒƒãƒãƒ³ã‚°)
    total_similarity = 0
    matched_indices2 = []
    
    for i in range(n_comp):
        best_match_idx = -1
        max_corr = -1
        for j in range(n_comp):
            if j in matched_indices2:
                continue
            corr_ex, _ = pearsonr(excitation_loadings1[:, i], excitation_loadings2[:, j])
            corr_em, _ = pearsonr(emission_loadings1[:, i], emission_loadings2[:, j])
            avg_corr = (corr_ex + corr_em) / 2
            
            if avg_corr > max_corr:
                max_corr = avg_corr
                best_match_idx = j
        
        total_similarity += max_corr
        matched_indices2.append(best_match_idx)
        
    avg_similarity = total_similarity / n_comp
    similarity_scores.append(avg_similarity * 100) # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã«å¤‰æ›
    print(f"  - æˆåˆ†æ•° = {n_comp} ã®å¹³å‡é¡žä¼¼åº¦: {avg_similarity*100:.1f}%")

print("--- åˆ†æžãŒå®Œäº†ã—ã¾ã—ãŸ ---")

# --- çµæžœã®ãƒ—ãƒ­ãƒƒãƒˆ ---
plt.figure(figsize=(8, 5))
plt.plot(component_range, similarity_scores, 'o-', color='g', markersize=8)
plt.xlabel("Number of Components", fontsize=12)
plt.ylabel("Split-Half Similarity (%)", fontsize=12)
plt.title("Split-Half Analysis", fontsize=14)
plt.xticks(component_range)
plt.grid(True, linestyle='--', alpha=0.6)
# 95%ã®ãƒ©ã‚¤ãƒ³ã«è£œåŠ©ç·šã‚’è¿½åŠ 
plt.axhline(y=95, color='r', linestyle='--', label='95% Threshold')
plt.legend()
plt.ylim(0, 105)
plt.show()

# %% [markdown]
# ## å¯è¦–åŒ–

# %%
# %% æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–ï¼ˆæ­£è¦åŒ–ï¼‹ãƒ”ãƒ¼ã‚¯è¡¨ç¤ºæ”¹è‰¯ç‰ˆï¼‰

# --- äº‹å‰æº–å‚™ã¯å¤‰æ›´ãªã— ---
# (excitation_loadings, emission_loadings, sample_scores ãªã©)
# ---

print("\n--- æŠ½å‡ºã•ã‚ŒãŸæˆåˆ†ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ï¼ˆãƒ”ãƒ¼ã‚¯è¡¨ç¤ºæ”¹è‰¯ç‰ˆï¼‰ ---")

# å„æˆåˆ†ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—
for i in range(OPTIMAL_COMPONENTS):
    # --- 1. ã‚°ãƒ©ãƒ•ã®æº–å‚™ ---
    fig, ax1 = plt.subplots(figsize=(10, 4))
    ax2 = ax1.twinx()

    # --- 2. ã‚¹ãƒšã‚¯ãƒˆãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆ (æ­£è¦åŒ–ã•ã‚ŒãŸãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨) ---
    color1 = 'tab:blue'
    ax1.plot(ex_bands_trimmed, excitation_loadings_norm[:, i], color=color1, lw=2.5)
    ax1.set_xlabel('Wavelength (nm)', fontsize=12)
    ax1.set_ylabel('Ex loading (normalized)', color=color1, fontsize=12)
    ax1.tick_params(axis='y', labelcolor=color1)
    ax1.grid(True, axis='x', linestyle='--', alpha=0.6)

    color2 = 'tab:red'
    ax2.plot(em_bands_trimmed, emission_loadings_norm[:, i], color=color2, lw=2.5)
    ax2.set_ylabel('Em loading (normalized)', color=color2, fontsize=12)
    ax2.tick_params(axis='y', labelcolor=color2)

    # --- 3. ãƒ”ãƒ¼ã‚¯æ³¢é•·ã®æ¤œå‡ºã¨æç”»ï¼ˆè¡¨ç¤ºæ–¹æ³•ã‚’æ”¹è‰¯ï¼‰ ---
    # åŠ±èµ·ãƒ”ãƒ¼ã‚¯
    ex_peak_idx = np.argmax(excitation_loadings_norm[:, i])
    ex_peak_wl = ex_bands_trimmed[ex_peak_idx]
    ax1.axvline(x=ex_peak_wl, color=color1, linestyle='--', alpha=0.8)
    # â–¼â–¼â–¼ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¸¦æ›¸ãã«ã—ã€ä½ç½®ã‚’èª¿æ•´ â–¼â–¼â–¼
    ax1.text(ex_peak_wl - 3, ax1.get_ylim()[1] * 0.5, f'{ex_peak_wl:.0f} nm',
             color=color1, rotation='vertical', ha='right', va='center', fontsize=11)

    # è›å…‰ãƒ”ãƒ¼ã‚¯
    em_peak_idx = np.argmax(emission_loadings_norm[:, i])
    em_peak_wl = em_bands_trimmed[em_peak_idx]
    ax2.axvline(x=em_peak_wl, color=color2, linestyle='--', alpha=0.8)
    # â–¼â–¼â–¼ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¸¦æ›¸ãã«ã—ã€ä½ç½®ã‚’èª¿æ•´ â–¼â–¼â–¼
    ax2.text(em_peak_wl + 3, ax2.get_ylim()[1] * 0.5, f'{em_peak_wl:.0f} nm',
             color=color2, rotation='vertical', ha='left', va='center', fontsize=11)

    # --- 4. ä»•ä¸Šã’ ---
    ax1.set_title(f'Component {i+1}', fontsize=14)
    # Yè»¸ã®ç¯„å›²ã‚’0ã‹ã‚‰ã«å›ºå®šã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
    ax1.set_ylim(bottom=0)
    ax2.set_ylim(bottom=0)
    fig.tight_layout()
    plt.show()

    

# %%
# 2. ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚³ã‚¢ï¼ˆå„MPã®æˆåˆ†å«æœ‰é‡ï¼‰ã®ãƒ—ãƒ­ãƒƒãƒˆ
print("\n--- å„MPã®æˆåˆ†å«æœ‰é‡ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---")
plt.figure(figsize=(10, 6))
# ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ã§å¯è¦–åŒ–
plt.imshow(sample_scores_norm.T, cmap='viridis', aspect='auto')
plt.yticks(ticks=np.arange(OPTIMAL_COMPONENTS), labels=[f'Component {i+1}' for i in range(OPTIMAL_COMPONENTS)])
plt.xticks(ticks=np.arange(len(sample_name)), labels=sample_name, rotation=45, ha='right')
plt.colorbar(label='Relative Concentration (normalized)')
plt.title('Component Scores for Each Microplastic', fontsize=14)
plt.show()

# %%
# %% å„æˆåˆ†ã®EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆ

# --- äº‹å‰æº–å‚™ï¼ˆæœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—çµæžœã‹ã‚‰ï¼‰ ---
# excitation_loadings: åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
# emission_loadings: è›å…‰ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
# ex_bands_trimmed: åŠ±èµ·æ³¢é•·ã®ãƒªã‚¹ãƒˆ
# em_bands_trimmed: è›å…‰æ³¢é•·ã®ãƒªã‚¹ãƒˆ
# OPTIMAL_COMPONENTS: æœ€é©ãªæˆåˆ†æ•°
# ---------------------------------------------

print("\n--- åˆ†é›¢ã•ã‚ŒãŸå„æˆåˆ†ã®EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ ---")

# å„æˆåˆ†ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—
for i in range(OPTIMAL_COMPONENTS):
    # --- 1. å¤–ç©ã‚’è¨ˆç®—ã—ã¦ã€æˆåˆ†ã®EEMã‚’å†æ§‹æˆ ---
    # np.outer() ã§2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰2æ¬¡å…ƒã®è¡Œåˆ—ã‚’ä½œæˆ
    component_eem = np.outer(excitation_loadings[:, i], emission_loadings[:, i])

    # --- 2. ã‚°ãƒ©ãƒ•ã®æº–å‚™ ---
    fig, ax = plt.subplots(figsize=(7, 6))

    # --- 3. ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆ ---
    im = ax.imshow(
        component_eem,  
        origin='lower',
        aspect='auto',
        cmap='viridis',
        extent=[ex_bands_trimmed[0], ex_bands_trimmed[-1], em_bands_trimmed[0], em_bands_trimmed[-1]]
    )

    # --- 4. ä»•ä¸Šã’ ---
    ax.set_title(f'Reconstructed EEM for Component {i+1}', fontsize=14)
    ax.set_xlabel('Excitation Wavelength (nm)', fontsize=12)
    ax.set_ylabel('Emission Wavelength (nm)', fontsize=12)
    fig.colorbar(im, ax=ax, label='Relative Intensity')
    plt.show()

# %% [markdown]
# ---

# %%
# for data in srcdata:
#     eem = fluorescence_util.EEMF7000(data.get('path'))
#     print(eem)

#     plt.figure()

#     # â‘  æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»
#     eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,
#                                                        remove_first_order=True, 
#                                                        inplace=True)

#     # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»
#     eem.remove_scatter_regions(inplace=True)

#     eem.plot_heatmap()
#     plt.title(eem.sample)

sample_data = []
sample_name = []

for data in srcdata:

    # EEMãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    eem = fluorescence_util.EEMF7000(data.get('path'))
    print(eem)

    # â‘ æ•£ä¹±ãƒ”ãƒ¼ã‚¯é™¤åŽ»
    eem.remove_self_reflection_and_scattering_from_eem(margin_steps=6,
                                                       remove_first_order=True,
                                                        inplace=True)
    # â‘¡ è¿½åŠ ã§æ•£ä¹±é ˜åŸŸå…¨ä½“ã‚’é™¤åŽ»
    eem.remove_scatter_regions(inplace=True)

    # 250nmä»¥ä¸Šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    ex_mask = ex_bands >= 250
    em_mask = em_bands >= 250

    eem_matrix = eem.mat  # numpyé…åˆ—ã‚’å–ã‚Šå‡ºã™

    # eem_matrix = np.nan_to_num(eem.mat, nan=0.0)
    eem_matrix_trimmed = eem_matrix[np.ix_(ex_mask, em_mask)]

    sample_data.append(eem_matrix_trimmed)
    sample_name.append(eem.sample)

    # eem.plot_heatmap()
    # plt.title(eem.sample)

# numpyé…åˆ—ã«ä¿å­˜
eem_array = np.array(sample_data)
print(eem_array.shape)

# %% [markdown]
# ## æ³¢é•·åŸŸã®èª¿æ•´

# %%
ex_mask = np.array(ex_bands) >= 250
em_mask = np.array(em_bands) >= 250

# trim
ex_bands = np.array(ex_bands)[ex_mask]
em_bands = np.array(em_bands)[em_mask]

print("Excitation bands â‰¥ 250nm:", ex_bands)
print("Emission bands â‰¥ 250nm:", em_bands)


# %%


# %% [markdown]
# ## ãƒŽã‚¤ã‚ºã‚ã‚Šã‚µãƒ³ãƒ—ãƒ«ã®ç”Ÿæˆ

# %% [markdown]
# ### å„MPã”ã¨ã«ç”Ÿæˆ

# %%
def augment_eem_per_mp_with_scatter_removal(eem_array, ex_bands, em_bands, n_variants=20, noise_level=0.05, seed=None):
    """
    ãƒŽã‚¤ã‚ºä»˜ãEEMã‚’ç”Ÿæˆã—ã€æ•£ä¹±é ˜åŸŸã‚’0ã«ã—ã¦é™¤åŽ»ã™ã‚‹ã€‚

    Parameters:
        eem_array: np.ndarray
            å…¥åŠ›EEMé…åˆ—ã€‚shape = (num_MP, n_ex, n_em)
        ex_bands: np.ndarray
            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_exï¼‰
        em_bands: np.ndarray
            è›å…‰æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_emï¼‰
        n_variants: int
            å„MPã”ã¨ã«ç”Ÿæˆã™ã‚‹ãƒŽã‚¤ã‚ºä»˜ãEEMã®æ•°
        noise_level: float
            ãƒŽã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆæœ€å¤§å€¤ã«å¯¾ã™ã‚‹å‰²åˆï¼‰
        seed: int or None
            ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    Returns:
        augmented_eems: np.ndarray
            shape = (num_MP, n_variants, n_ex, n_em)
    """
    if seed is not None:
        np.random.seed(seed)

    num_MP, n_ex, n_em = eem_array.shape
    augmented_eems = np.zeros((num_MP, n_variants, n_ex, n_em))

    # æ•£ä¹±é ˜åŸŸãƒžã‚¹ã‚¯ï¼ˆTrue: æœ‰åŠ¹é ˜åŸŸ, False: æ•£ä¹± â†’ 0ã«ã™ã‚‹ï¼‰
    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')
    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)

    for i in range(num_MP):
        base_eem = eem_array[i]
        for j in range(n_variants):
            noise = np.random.normal(loc=0, scale=noise_level * np.max(base_eem), size=base_eem.shape)
            noisy_eem = np.clip(base_eem + noise, 0, None)
            noisy_eem[~valid_mask] = 0  # æ•£ä¹±é ˜åŸŸã‚’0ã«
            augmented_eems[i, j] = noisy_eem

    return augmented_eems
# ex_bands, em_bands ã¯ np.array ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
augmented_eems = augment_eem_per_mp_with_scatter_removal(
    eem_array,
    ex_bands=ex_bands,
    em_bands=em_bands,
    n_variants=50,
    noise_level=0,
    seed=42
)


# %%
import matplotlib.pyplot as plt

def plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=None):
    """
    å„MPã‹ã‚‰1ã¤ãšã¤ãƒŽã‚¤ã‚ºä»˜ãEEMã‚’ã€å€‹åˆ¥ã«ãƒ—ãƒ­ãƒƒãƒˆï¼ˆåŠ±èµ·ï¼šæ¨ªè»¸ã€æ”¾å°„ï¼šç¸¦è»¸ï¼‰ã€‚

    Parameters:
        augmented_eems: np.ndarray
            shape = (num_MP, n_variants, n_ex, n_em)
        ex_bands: np.ndarray
            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆæ¨ªè»¸ï¼‰
        em_bands: np.ndarray
            ç™ºå…‰æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆç¸¦è»¸ï¼‰
        sample_names: list or None
            MPã”ã¨ã®åå‰ãƒªã‚¹ãƒˆï¼ˆä»»æ„ï¼‰
    """
    num_MP = augmented_eems.shape[0]

    for mp_idx in range(num_MP):
        eem = augmented_eems[mp_idx, 0]  # å„MPã§æœ€åˆã®ãƒŽã‚¤ã‚ºãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¡¨ç¤º

        plt.figure(figsize=(6, 5))
        plt.imshow(eem, origin='lower',
                   extent=[ex_bands[0], ex_bands[-1], em_bands[0], em_bands[-1]],
                   aspect='auto', cmap='viridis')

        plt.xlabel('Excitation (nm)')
        plt.ylabel('Emission (nm)')
        title = sample_names[mp_idx] if sample_names else f'MP {mp_idx}'
        plt.title(f'Augmented EEM - {title}')
        plt.colorbar(label='Intensity')
        plt.tight_layout()
        plt.show()

plot_augmented_eems_one_by_one(augmented_eems, ex_bands, em_bands, sample_names=sample_name)
# plot_augmented_eems_one_by_one(combined_augmented_eems, ex_bands, em_bands, sample_names=sample_name)


# %% [markdown]
# ## MPã®EEMã‚’åˆæˆ

# %%
def generate_combined_eem_with_noise(
    eem_array, ex_bands, em_bands,
    n_variants=20, noise_level=0.05, seed=None
):
    """
    å…¨MPã®EEMã‚’åˆæˆã—ã¦ã€ãƒŽã‚¤ã‚ºä»˜ãã®EEMã‚’ç”Ÿæˆï¼ˆæ•£ä¹±é ˜åŸŸé™¤åŽ»ã¤ãï¼‰

    Parameters:
        eem_array: np.ndarray
            shape = (num_MP, n_ex, n_em)
        ex_bands: np.ndarray
            åŠ±èµ·æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_exï¼‰
        em_bands: np.ndarray
            æ”¾å°„æ³¢é•·ãƒªã‚¹ãƒˆï¼ˆshape = n_emï¼‰
        n_variants: int
            ç”Ÿæˆã™ã‚‹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ•°
        noise_level: float
            ãƒŽã‚¤ã‚ºã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆåˆæˆEEMã®æœ€å¤§å€¤ã«å¯¾ã™ã‚‹å‰²åˆï¼‰
        seed: int or None
            ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    Returns:
        combined_eems: np.ndarray
            shape = (n_variants, n_ex, n_em)
    """
    if seed is not None:
        np.random.seed(seed)

    # --- åˆæˆEEMï¼ˆã™ã¹ã¦ã®MPã®å’Œï¼‰
    combined_base = np.sum(eem_array, axis=0)  # shape = (n_ex, n_em)

    # --- æ•£ä¹±é ˜åŸŸãƒžã‚¹ã‚¯ã‚’ä½œæˆ
    ex_grid, em_grid = np.meshgrid(ex_bands, em_bands, indexing='ij')
    valid_mask = (em_grid >= ex_grid) & (em_grid <= 2 * ex_grid)

    # --- ãƒŽã‚¤ã‚ºä»˜ãEEMã®ç”Ÿæˆ
    combined_eems = np.zeros((n_variants, *combined_base.shape))
    for i in range(n_variants):
        noise = np.random.normal(loc=0, scale=noise_level * np.max(combined_base), size=combined_base.shape)
        noisy_eem = np.clip(combined_base + noise, 0, None)
        noisy_eem[~valid_mask] = 0  # æ•£ä¹±é ˜åŸŸã‚’ã‚¼ãƒ­ã«
        combined_eems[i] = noisy_eem

    return combined_eems

combined_augmented_eems = generate_combined_eem_with_noise(
    eem_array,
    ex_bands=ex_bands,
    em_bands=em_bands,
    n_variants=50,
    noise_level=0.05,
    seed=123
)


# 1æžšç›®ã‚’å–å¾—
eem_sample = combined_augmented_eems[0]

# ãƒ—ãƒ­ãƒƒãƒˆ
plt.figure(figsize=(6, 5))
plt.imshow(
    eem_sample,
    aspect='auto',
    origin='lower',
    extent=[em_bands.min(), em_bands.max(), ex_bands.min(), ex_bands.max()],
    cmap='viridis'
)
plt.colorbar(label='Fluorescence Intensity')
plt.xlabel('Emission Wavelength (nm)')
plt.ylabel('Excitation Wavelength (nm)')
plt.title('Combined EEM Sample #1')
plt.tight_layout()
plt.show()


# %% [markdown]
# ## PARAFACï¼ŒCore Consistencyï¼ŒSplit half

# %%
import numpy as np
import tensorly as tl
from tensorly.decomposition import parafac
from scipy.stats import pearsonr
from corcondia import corcondia_3d

tl.set_backend('numpy')

# --- PARAFACçµæžœã‚’ã™ã¹ã¦ä¿å­˜ã™ã‚‹é–¢æ•° ---
def compute_parafac_results(eem_tensor, max_components):
    results = []
    for r in range(1, max_components + 1):
        factors = parafac(eem_tensor, rank=r, init='random', tol=1e-6, n_iter_max=200)
        results.append(factors)
    return results

# --- Core Consistency Diagnostic (æ­£å¼ç‰ˆ CORCONDIA)
def compute_core_consistency_corcondia(tensor, max_components=7):
    cc_list = []
    for r in range(1, max_components + 1):
        cc = corcondia_3d(tensor, k=r)
        cc_list.append(cc)
    return cc_list

# --- Split-Half é¡žä¼¼åº¦ã®ä¸€æ‹¬è¨ˆç®—ï¼ˆå„ãƒ©ãƒ³ã‚¯ã§åˆ¥ã€…ã«åˆ†å‰²ï¼‹åˆ†è§£ï¼‰
def compute_split_half_similarities(tensor, max_components):
    sim_list = []
    for r in range(1, max_components + 1):
        all_idx = np.arange(tensor.shape[2])
        np.random.shuffle(all_idx)
        half1 = tensor[:, :, all_idx[:tensor.shape[2] // 2]]
        half2 = tensor[:, :, all_idx[tensor.shape[2] // 2:]]

        f1 = parafac(half1, rank=r, init='random', tol=1e-6, n_iter_max=200)
        f2 = parafac(half2, rank=r, init='random', tol=1e-6, n_iter_max=200)

        ex1, em1, _ = f1.factors
        ex2, em2, _ = f2.factors

        sim_total = 0
        for i in range(r):
            r_ex, _ = pearsonr(ex1[:, i], ex2[:, i])
            r_em, _ = pearsonr(em1[:, i], em2[:, i])
            sim_total += (r_ex + r_em) / 2
        sim_list.append(sim_total / r)
    return sim_list

# --- å„MPã«å¯¾ã—ã¦ Core Consistencyï¼ˆCORCONDIAï¼‰ã¨ Split-Half é¡žä¼¼åº¦ã‚’è¨ˆç®— ---
cc_dict = {}
sh_dict = {}
factors_dict = {}

for idx, eem_tensor in enumerate(augmented_eems):
    sample = sample_name[idx]
    print(f"\nðŸ”ã€{sample}ã€‘ã® Core Consistency / Split-Half è¨ˆç®—ä¸­...")

    tensor = np.transpose(eem_tensor, (1, 2, 0))  # (exc, em, sample)
    factors_dict[sample] = compute_parafac_results(tensor, max_components=7)

    # æ­£å¼ãª Core Consistency è¨ˆç®—ï¼ˆCORCONDIAï¼‰
    cc_dict[sample] = compute_core_consistency_corcondia(tensor, max_components=7)

    # Split-Half é¡žä¼¼åº¦
    sh_dict[sample] = compute_split_half_similarities(tensor, max_components=7)


# %%
import matplotlib.pyplot as plt

def plot_core_consistency_and_similarity(cc_list, sh_list, sample_label="Sample", start_rank=1):
    """
    Core Consistencyã¨Split-Halfé¡žä¼¼åº¦ã‚’åŒæ™‚ã«ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹é–¢æ•°

    Parameters:
        cc_list: list of floatï¼ˆCore Consistency, å„æˆåˆ†æ•°ã«å¯¾å¿œï¼‰
        sh_list: list of floatï¼ˆSplit-Half é¡žä¼¼åº¦, å„æˆåˆ†æ•°ã«å¯¾å¿œï¼‰
        sample_label: strï¼ˆãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒˆãƒ«ç”¨ï¼‰
        start_rank: intï¼ˆé€šå¸¸ã¯1, cc_list[0]ãŒrank=1ã®ã¨ãï¼‰
    """
    ranks = list(range(start_rank, start_rank + len(cc_list)))

    fig, ax1 = plt.subplots(figsize=(7, 4))
    ax2 = ax1.twinx()

    ax1.plot(ranks, cc_list, 'o-', color='tab:blue', label='Core Consistency')
    ax2.plot(ranks, sh_list, 's--', color='tab:red', label='Split-Half Similarity')

    ax1.set_xlabel("Component Rank")
    ax1.set_ylabel("Core Consistency (%)", color='tab:blue')
    ax1.set_ylim(0, 100)
    ax2.set_ylabel("Similarity(%)", color='tab:red')
    ax2.set_ylim(0, 1.0)

    ax1.tick_params(axis='y', labelcolor='tab:blue')
    ax2.tick_params(axis='y', labelcolor='tab:red')

    ax1.set_title(f"{sample_label}: Core Consistency & Split-Half Similarity")

    # å‡¡ä¾‹ã®è¨­å®š
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')

    plt.tight_layout()
    plt.show()

# for sample in sample_name:
#     plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)
for sample in sample_name:
    cc_list = cc_dict.get(sample)
    sh_list = sh_dict.get(sample)
    if cc_list is not None and sh_list is not None:
        plot_core_consistency_and_similarity(cc_list, sh_list, sample_label=sample)
    else:
        print(f"{sample} ã®è§£æžçµæžœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")


# %% [markdown]
# ## ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å¯è¦–åŒ–

# %%
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np

def plot_eem_with_bandpass_box(eem, ex_bands, em_bands,
                                excitation_loading, emission_loading,
                                rank, band_width=20, sample_label="MP"):
    """
    ãƒŽã‚¤ã‚ºä»˜ãEEMä¸Šã«ã€æŒ‡å®šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒãƒ³ãƒ‰ãƒ‘ã‚¹æ³¢é•·ç¯„å›²ã‚’ç´«ã®å››è§’ã§é‡ã­ã¦è¡¨ç¤º

    Parameters:
        eem: 2D array (ex Ã— em)
        ex_bands: 1D array
        em_bands: 1D array
        excitation_loading: 2D array (ex, rank)
        emission_loading: 2D array (em, rank)
        component_idx: intï¼ˆä½•ç•ªç›®ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã€0å§‹ã¾ã‚Šï¼‰
        band_width: floatï¼ˆÂ±ä½•nmã§ç¯„å›²ã‚’å–ã‚‹ã‹ï¼‰
        sample_label: str
    """

    # EEMã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    fig, ax = plt.subplots(figsize=(6, 5))
    im = ax.imshow(eem, origin='lower',
                   extent=[em_bands[0], em_bands[-1],
                           ex_bands[0], ex_bands[-1]],
                   aspect='auto', cmap='viridis')
    
    for i in range(rank):
        # ãƒ”ãƒ¼ã‚¯æ³¢é•·ã‚’ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‹ã‚‰æŠ½å‡º
        exc_idx = np.argmax(excitation_loading[:, i])
        em_idx = np.argmax(emission_loading[:, i])
        exc_peak = ex_bands[exc_idx]
        em_peak = em_bands[em_idx]

        # å››è§’ã®ç¯„å›²ï¼ˆÂ±band_widthï¼‰
        exc_min = exc_peak - band_width
        exc_max = exc_peak + band_width
        em_min = em_peak - band_width
        em_max = em_peak + band_width

        # # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        # exc = excitation_loading[:, i]
        # em = emission_loading[:, i]

        # # ãƒ”ãƒ¼ã‚¯ä½ç½®ï¼ˆæœ€å¤§å€¤ï¼‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ â†’ æ³¢é•·
        # exc_idx = np.argmax(exc)
        # em_idx = np.argmax(em)
        # exc_peak = ex_bands[exc_idx]
        # em_peak = em_bands[em_idx]

        # # ðŸŽ¯ åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¨™æº–åå·®ã‚’ä½¿ã£ã¦ band_width ã‚’æ±ºã‚ã‚‹
        # # é‡ã¿ä»˜ãå¹³å‡ã¨åˆ†æ•£ï¼ˆä¸­å¿ƒæ³¢é•·Â±å¹…ï¼‰
        # exc_mean = np.sum(ex_bands * exc) / np.sum(exc)
        # exc_var = np.sum(((ex_bands - exc_mean) ** 2) * exc) / np.sum(exc)
        # band_width = np.sqrt(exc_var)   # æ¨™æº–åå·®

        # # å››è§’ã®ç¯„å›²ï¼ˆÂ±1Ïƒç¨‹åº¦ï¼‰
        # exc_min = exc_peak - band_width
        # exc_max = exc_peak + band_width
        # em_min = em_peak - band_width
        # em_max = em_peak + band_width

        # ðŸ”´ èµ¤ã„æ¨ªç·šã§ Excitation peak ã‚’ç¤ºã™  
        ax.hlines(y=exc_peak, xmin=em_bands[0], xmax=em_bands[-1], colors='red', linestyles='dashed', linewidth=1.5)

        # # â¬… ãƒ©ãƒ™ãƒ«ã‚’å·¦ã«è¡¨ç¤ºï¼ˆx=æœ€å°æ”¾å°„æ³¢é•· - å°‘ã—å·¦ã«ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰
        # ax.text(em_bands[0] - 10, exc_peak, f"Ex = {exc_peak} nm",
        #         color='red', fontsize=10, va='center', ha='right')

        print(f"Loading_{i+1} peak ex_band: {exc_peak}")
        print(f"Loading_{i+1} peak em_band: {em_peak}")
        
        # ç´«ã®å››è§’ã‚’é‡ã­ã‚‹
        rect = patches.Rectangle(
            (em_min, exc_min),  # å·¦ä¸‹è§’ (x, y)
            em_max - em_min,    # å¹…
            exc_max - exc_min,  # é«˜ã•
            linewidth=2,
            edgecolor='white',
            facecolor='none'
        )
        ax.add_patch(rect)
        ax.set_title(f"{sample_label} - EEM with Bandpass Box (Component {rank})")
        ax.set_xlabel("Emission Wavelength (nm)")
        ax.set_ylabel("Excitation Wavelength (nm)")
        plt.tight_layout()
    plt.colorbar(im, ax=ax, label="Fluorescence Intensity")
    plt.show()


# %%
import matplotlib.pyplot as plt

def plot_selected_loadings(factors, rank, ex_bands, em_bands, sample_label="Sample"):
    """
    æŒ‡å®šã—ãŸrankã®PARAFACçµæžœã‚’ä½¿ã£ã¦ã€åŠ±èµ·ã¨ç™ºå…‰ã®ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
        results: list of parafac resultsï¼ˆcompute_parafac_results()ã®å‡ºåŠ›ï¼‰
        rank: intï¼ˆè¡¨ç¤ºã—ãŸã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•°ï¼‰
        ex_bands: 1D arrayï¼ˆåŠ±èµ·æ³¢é•·ï¼‰
        em_bands: 1D arrayï¼ˆç™ºå…‰æ³¢é•·ï¼‰
        sample_label: strï¼ˆMPã®åå‰ãªã©ï¼‰
    """
    factors_rank = factors[rank - 1]  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ³¨æ„ï¼šrank=1 â†’ results[0]
    excitation_loading, emission_loading, _ = factors_rank.factors

    # --- åŠ±èµ·ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° ---
    plt.figure(figsize=(6, 3))
    for i in range(rank):
        plt.plot(ex_bands, excitation_loading[:, i], label=f"Component {i+1}")
    plt.title(f"{sample_label} - Excitation Loading (Rank {rank})")
    plt.xlabel("Excitation Wavelength (nm)")
    plt.ylabel("Loading Strength")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # --- ç™ºå…‰ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° ---
    plt.figure(figsize=(6, 3))
    for i in range(rank):
        plt.plot(em_bands, emission_loading[:, i], label=f"Component {i+1}")
    plt.title(f"{sample_label} - Emission Loading (Rank {rank})")
    plt.xlabel("Emission Wavelength (nm)")
    plt.ylabel("Loading Strength")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¸¯åŸŸå›³ç¤ºåŒ–
    plot_eem_with_bandpass_box(eem, ex_bands, em_bands,
                            excitation_loading, emission_loading,
                            rank, band_width=20, sample_label=sample
                            )


# %%
sample = "ABS"
rank = 1
factors = factors_dict.get(sample)

mp_idx = sample_name.index(sample)  # "PET" ã«å¯¾å¿œã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆä¾‹ï¼š0ï¼‰
eem = augmented_eems[mp_idx, 0]  # PETã®æœ€åˆã®ãƒŽã‚¤ã‚ºä»˜ãEEMï¼ˆshape: 81x81ï¼‰


if factors is not None:
    plot_selected_loadings(
        factors, 
        rank,
        ex_bands,
        em_bands,
        sample_label=sample
    )
else:
    print(f"{sample} ã®è§£æžçµæžœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")



# %% [markdown]
# ---

# %% [markdown]
# 

# %% [markdown]
# 


